[
  {
    "path": "statistik/Statistik1_01_Demo/",
    "title": "Demo Statistik 1",
    "description": {},
    "author": [],
    "date": "2021-11-02",
    "categories": [
      "Statistik1"
    ],
    "contents": "\n\n\n\nDemoskript als Download\nBinomialtest\n\n\n# In Klammern übergibt man die Anzahl der Erfolge und die Stichprobengrösse\nbinom.test(43, 100)\n\n\n\n    Exact binomial test\n\ndata:  43 and 100\nnumber of successes = 43, number of trials = 100, p-value =\n0.1933\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.3313910 0.5328663\nsample estimates:\nprobability of success \n                  0.43 \n\nbinom.test(57, 100)\n\n\n\n    Exact binomial test\n\ndata:  57 and 100\nnumber of successes = 57, number of trials = 100, p-value =\n0.1933\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.4671337 0.6686090\nsample estimates:\nprobability of success \n                  0.57 \n\nChi-Quadrat-Test & Fishers Test\nErmitteln des kritischen Wertes\n\n\nqchisq(0.95, 1)\n\n\n[1] 3.841459\n\nDirekter Test in R (dazu Werte als Matrix nötig)\n\n\ncount <- matrix(c(38, 14, 11, 51), nrow = 2)\ncount\n\n\n     [,1] [,2]\n[1,]   38   11\n[2,]   14   51\n\nchisq.test(count)\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  count\nX-squared = 33.112, df = 1, p-value = 8.7e-09\n\nfisher.test(count)\n\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  count\np-value = 2.099e-09\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n  4.746351 34.118920\nsample estimates:\nodds ratio \n  12.22697 \n\nt-Test\n\n\na <- c(20, 19, 25, 10, 8, 15, 13, 18, 11, 14)\nb <- c(12, 15, 16, 7, 8, 10, 12, 11, 13, 10)\nblume <- data.frame(a,b)\nblume\n\n\n    a  b\n1  20 12\n2  19 15\n3  25 16\n4  10  7\n5   8  8\n6  15 10\n7  13 12\n8  18 11\n9  11 13\n10 14 10\n\nsummary(blume)\n\n\n       a               b        \n Min.   : 8.00   Min.   : 7.00  \n 1st Qu.:11.50   1st Qu.:10.00  \n Median :14.50   Median :11.50  \n Mean   :15.30   Mean   :11.40  \n 3rd Qu.:18.75   3rd Qu.:12.75  \n Max.   :25.00   Max.   :16.00  \n\nboxplot(blume$a, blume$b)\n\n\n\nboxplot(blume)\n\n\n\nhist(blume$a)\n\n\n\nhist(blume$b)\n\n\n\n\nzweiseitiger t-Test\n\n\nt.test(blume$a, blume$b)\n\n\n\n    Welch Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 13.907, p-value = 0.05654\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.1245926  7.9245926\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\neinseitiger t-Test\n\n\nt.test(blume$a, blume$b, alternative = \"greater\") #einseitig\n\n\n\n    Welch Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 13.907, p-value = 0.02827\nalternative hypothesis: true difference in means is greater than 0\n95 percent confidence interval:\n 0.5954947       Inf\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\nt.test(blume$a, blume$b, alternative = \"less\") #einseitig\n\n\n\n    Welch Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 13.907, p-value = 0.9717\nalternative hypothesis: true difference in means is less than 0\n95 percent confidence interval:\n     -Inf 7.204505\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\nklassischer t-Test vs. Welch Test\n\n\n# Varianzen gleich, klassischer t-Test\nt.test(blume$a, blume$b, var.equal = T) \n\n\n\n    Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 18, p-value = 0.05212\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.03981237  7.83981237\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\n# Varianzen ungleich, Welch's t-Test, ist auch default, d.h. wenn var.equal \n# nicht  definiert wird, wird ein Welch's t-Test ausgeführt. \nt.test(blume$a, blume$b, var.equal = F) \n\n\n\n    Welch Two Sample t-test\n\ndata:  blume$a and blume$b\nt = 2.0797, df = 13.907, p-value = 0.05654\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.1245926  7.9245926\nsample estimates:\nmean of x mean of y \n     15.3      11.4 \n\ngepaarter t-Test\n\n\nt.test(blume$a, blume$b, paired = T)\n\n\n\n    Paired t-test\n\ndata:  blume$a and blume$b\nt = 3.4821, df = 9, p-value = 0.006916\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 1.366339 6.433661\nsample estimates:\nmean of the differences \n                    3.9 \n\nt.test(blume$a, blume$b, paired = T, alternative = \"greater\")\n\n\n\n    Paired t-test\n\ndata:  blume$a and blume$b\nt = 3.4821, df = 9, p-value = 0.003458\nalternative hypothesis: true difference in means is greater than 0\n95 percent confidence interval:\n 1.846877      Inf\nsample estimates:\nmean of the differences \n                    3.9 \n\nDas gleiche mit einem “long table”\n\n\ncultivar <- c(rep(\"a\", 10), rep(\"b\", 10))\nsize <- c(a, b)\nblume.long <- data.frame(cultivar, size)\n\nrm(size) #Befehl rm entfernt die nicht mehr benötitgten Objekte aus dem Workspace\nrm(cultivar)\n\n\n\nDas gleiche in einer Zeile\n\n\nblume.long <- data.frame(cultivar = c(rep(\"a\", 10), rep(\"b\", 10)), size = c(a, b))\nsummary(blume.long)             \n\n\n   cultivar              size      \n Length:20          Min.   : 7.00  \n Class :character   1st Qu.:10.00  \n Mode  :character   Median :12.50  \n                    Mean   :13.35  \n                    3rd Qu.:15.25  \n                    Max.   :25.00  \n\nhead(blume.long)\n\n\n  cultivar size\n1        a   20\n2        a   19\n3        a   25\n4        a   10\n5        a    8\n6        a   15\n\nboxplot(size~cultivar, data = blume.long)\n\n\n\nt.test(size~cultivar, blume.long, var.equal = T)\n\n\n\n    Two Sample t-test\n\ndata:  size by cultivar\nt = 2.0797, df = 18, p-value = 0.05212\nalternative hypothesis: true difference in means between group a and group b is not equal to 0\n95 percent confidence interval:\n -0.03981237  7.83981237\nsample estimates:\nmean in group a mean in group b \n           15.3            11.4 \n\n# gepaarter t-Test erster Wert von Cultivar a wird mit erstem Wert von Cultivar\n# b gepaart, zweiter Wert von a mit zweitem von b ect.\nt.test(size~cultivar, blume.long, paired = T)\n\n\n\n    Paired t-test\n\ndata:  size by cultivar\nt = 3.4821, df = 9, p-value = 0.006916\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 1.366339 6.433661\nsample estimates:\nmean of the differences \n                    3.9 \n\nBase R vs. ggplot2\n\n\nlibrary(tidyverse)\nggplot(blume.long, aes(cultivar, size)) + geom_boxplot()\n\n\n\nggplot(blume.long, aes(cultivar, size)) + geom_boxplot() + theme_classic()\n\n\n\nggplot(blume.long, aes(cultivar, size)) + geom_boxplot(size = 1) + theme_classic()+\ntheme(axis.line = element_line(size = 1)) + theme(axis.title = element_text(size = 14))+\ntheme(axis.text = element_text(size = 14))\n\n\n\nggplot(blume.long, aes(cultivar, size)) + geom_boxplot(size=1) + theme_classic()+\n  theme(axis.line = element_line(size = 1), axis.ticks = element_line(size = 1), \n       axis.text = element_text(size = 20), axis.title = element_text(size = 20))\n\n\n\n\nDefinieren von mytheme mit allen gewünschten Settings, das man zu Beginn einer Sitzung einmal laden und dann immer wieder ausführen kann (statt des langen Codes)\n\n\nmytheme <- theme_classic() + \n  theme(axis.line = element_line(color = \"black\", size=1), \n        axis.text = element_text(size = 20, color = \"black\"), \n        axis.title = element_text(size = 20, color = \"black\"), \n        axis.ticks = element_line(size = 1, color = \"black\"), \n        axis.ticks.length = unit(.5, \"cm\"))\n\n\n\n\n\nggplot(blume.long, aes(cultivar, size)) + \n  geom_boxplot(size = 1) +\n  mytheme\n\n\n\nt_test <- t.test(size~cultivar, blume.long)\n\nggplot(blume.long, aes(cultivar, size)) + \n  geom_boxplot(size = 1) + \n  mytheme +\n  annotate(\"text\", x = \"b\", y = 24, \n  label = paste0(\"italic(p) == \", round(t_test$p.value, 3)), parse = TRUE, size = 8)\n\n\n\nggplot (blume.long, aes(cultivar,size)) + \n  geom_boxplot(size = 1) + \n  mytheme +\n  labs(x=\"Cultivar\",y=\"Size (cm)\")\n\n\n\n\n\n\n\n",
    "preview": "statistik/Statistik1_01_Demo/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik1_02_Intro_Daten_egel/",
    "title": "Beschreibung Forschungsprojekt NOVANIMAL (NFP69)",
    "description": {},
    "author": [
      {
        "name": "Gian-Andrea Egeler",
        "url": {}
      }
    ],
    "date": "2021-10-28",
    "categories": [
      "Statistik1"
    ],
    "contents": "\nIm Forschungsprojekt NOVANIMAL wird u.a. der Frage nachgegangen, was es braucht, damit Menschen freiwillig weniger tierische Produkte konsumieren? Ein interessanter Ansatzpunkt ist die Ausser-Haus-Verpflegung. Gemäss der ersten in den Jahren 2014/2015 durchgeführten nationalen Ernährungserhebung menuCH essen 70 % der Bevölkerung zwischen 18 und 75 Jahren am Mittag auswärts (Bochud et al. 2017). Daher rückt die Gastronomie als zentraler Akteur einer innovativen und nachhaltigen Ernährungswirtschaft ins Blickfeld. Welche Innovationen in der Gastronomie könnten dazu beitragen, den Pro-Kopf-Verbrauch an tierischen Nahrungsmitteln zu senken?\nDazu wurde u.a. ein Experiment in zwei Hochschulmensen durchgeführt. Forschungsleitend war die Frage, wie die Gäste dazu bewogen werden können, häufiger vegetarische oder vegane Gerichte zu wählen. Konkret wurde untersucht, wie die Gäste auf ein verändertes Menü-Angebot mit einem höheren Anteil an vegetarischen und veganen Gerichten reagieren. Das Experiment fand während 12 Wochen statt und bestand aus zwei Mensazyklen à 6 Wochen. Über den gesamten Untersuchungszeitraum werden insgesamt 90 verschiedene Gerichte angeboten. In den 6 Referenz- bzw. Basiswochen wurden zwei fleisch- oder fischhaltige Menüs und ein vegetarisches Menü angeboten. In den 6 Interventionswochen wurde das Verhältnis umgekehrt und es wurden ein veganes, ein vegetarisches und ein fleisch- oder fischhaltiges Gericht angeboten. Basis- und Interventionsangebote wechselten wöchentlich ab. Während der gesamten 12 Wochen konnten die Gäste jeweils auf ein Buffet ausweichen und ihre Mahlzeit aus warmen und kalten Komponenten selber zusammenstellen. Die Gerichte wurden über drei vorgegebene Menülinien (F, K, W) randomisiert angeboten.\nDie Abbildung zeigt das Versuchsdesign der ersten 6 Experimentwochen (Kalenderwoche 40 bis 45).Mehr Informationen über das Forschungsprojekt NOVANIMAL findet ihr auf der Webpage\n\n\n\n",
    "preview": {},
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik1_03_Assigment/",
    "title": "Übungen Statistik 1",
    "description": {},
    "author": [],
    "date": "2021-10-28",
    "categories": [
      "Statistik1"
    ],
    "contents": "\nAufgabe 1.1: Assoziationstest\nBitte führt einen Assoziationstest zweier kategorialer Variablen (mit je zwei Ausprägungen) mit Chi-Quadrat und Fishers exaktem Test durch. Ihr habt zwei Möglichkeiten: (1) Ihr erhebt dazu selbst die Daten (wozu ihr euch auch in Teams zusammenschliessen könnt). Dabei könnt ihr sowohl Befragungen/Datenerhebung unter Mitstudierenden durchführen (etwa Nutzung Mac/Windows vs. männlich/weiblich) oder Daten zu anderen Objekten erheben. (2) Ihr nehmt zwei kategoriale Variablen aus einem der Novanimal-Datensätze (Feldexperiment oder Gästebefragung).  Bitte formuliert in beiden Fällen vor der Datenerhebung/Datenextraktion eine Hypothese, d.h. eine Erwartungshaltung, ob und welche Assoziation vorliegt und wenn ja warum. Bitte beachtet, dass ihr für die Form des Assoziationstests aus dem Kurs zwei binäre Variablen benötigt; wenn ihr also kategoriale Variablen mit mehr als zwei Ausprägungen habt, könnt ihr entweder Ausprägungen sinnvoll zusammenfassen oder seltene Ausprägungen im Test unberücksichtigt lassen.\nAufgabe 1.2: t-Test\nWerden in den Basis- und Interventionswochen unterschiedlich viele Gerichte verkauft?\nDefiniere die Null- (\\(H_0\\)) und die Alternativhypothese (\\(H_1\\)).\nFühre einen t-Test durch.\nWelche Form von t-Test musst Du anwenden: einseitig/zweiseitig resp. gepaart/ungepaart?\nWie gut sind die Voraussetzungen für einen t-Test erfüllt (z.B. Normalverteilung der Residuen und Varianzhomogenität)?\nStelle deine Ergebnisse angemessen dar, d.h. Text mit Abbildung und/oder Tabelle\n\n\n\n",
    "preview": {},
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik1_04_Solution/",
    "title": "Musterlösung Übung 1",
    "description": {},
    "author": [
      {
        "name": "Gian-Andrea Egeler",
        "url": {}
      }
    ],
    "date": "2021-11-22",
    "categories": [
      "Statistik1"
    ],
    "contents": "\n\nContents\nMusterlösung Übung 1.1\nkommentierter Weg\nErgebnisse\n\nMusterlösung Übung 1.2: t-Test\nMethoden\nErgebnisse\n\n\n\n\n\nMusterlösung Übung 1.1\n\nDownload R-Skript\n\nkommentierter Weg\n\n\n# Als eine Möglichkeit, die Aufgabe 1.1 zu bearbeiten, nehmen wir hier den \n# Datensatz  der Gästebefragung NOVANIMAL und gehen der folgenden Frage nach: \n# Gibt es einen Zusammenhang zwischen Geschlecht und dem wahrgenommenen \n# Milchkonsum (viel vs. wenig Milch/-produkte)\n\n# die Variable wahrgenommener Milchkonsum muss \n# noch in 2 Kategorien zusammengefasst werden: geringer vs. hoher Milchkonsum\n\n\n# Variable  milk == wahrgenommener Milchkonsum \n# alles kleiner als 4 (3 inklusive) == geringer wahrgenommener Milchkonsum, \n#alles grösser als 3 (4 inklusive) == hoher wahrgenommener Milchkonsum\nnova2 <- nova_survey %>% \n  filter(gender != \"x\") %>% # x aus der Variable Geschlecht entfernen \n  mutate(milkcon = if_else(milk <= 3, \"wenig\", \"viel\")) %>% \n  select(gender, milkcon) %>% \n  drop_na() # alle Missings können gestrichen werden\n \n    \n# mal anschauen\ntable(nova2)\n\n\n      milkcon\ngender viel wenig\n  Frau  428    64\n  Mann  580    68\n\n#achtung chi_squre erwartet matrix\nnova_mtx <- xtabs(~ gender + milkcon ,data = nova2) \n# da es in diesem fall keine kriteriumsvariable gibt, fehlt das y sozusagen\n\n\n\n#Chi-squared Test\nchi_sq <- chisq.test(nova_mtx)\nchi_sq\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  nova_mtx\nX-squared = 1.49, df = 1, p-value = 0.2222\n\n#visualisierung\nOP <- par(mfrow=c(1,2), \"mar\"=c(1,1,3,1))\nmosaicplot(chi_sq$observed, cex.axis =1 , main = \"Observed counts\")\nmosaicplot(chi_sq$expected, cex.axis =1 , main = \"Expected counts\\n(wenn geschlecht keinen einfluss hat)\")\n\n\n\npar(OP)\n\n#Fisher's Test nur mit 2X2 Kontingenztabelle möglich\nfisher.test(nova_mtx)\n\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  nova_mtx\np-value = 0.1922\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.536215 1.147939\nsample estimates:\nodds ratio \n 0.7842283 \n\nErgebnisse\nDer \\(\\chi^2\\)-Test sagt uns, dass das Geschlecht und der wahrgenommene Milchkonsum nicht zusammenhängen. Es gibt keine signifikante Unterscheide zwischen dem Geschlecht und dem wahrgenommenen Milchkonsum (\\(\\chi^2\\)(1) = 1.49, p = 0.222. Es sieht so aus, dass Männer leicht mehr angeben weniger Milch zu konsumieren (Tabelle 1). Die Ergebnisse müssen jedoch mit Vorsicht interpretiert werden, denn der \\(\\chi^2\\)-Test gibt uns nur an, dass ein signifikanter Unterschied zwischen Geschlecht und wahrgenommener Milchkonsum vorliegt. Um die Unterschiede innerhalb einer Gruppen (z.B. Geschlecht nach Alter) festzustellen bedarf es weiterer Analysen z. B. mit einer mehrfaktorieller ANOVA mit anschliessenden Post-hoc Tests (siehe Statistik 3).\n\nTable 1: Wahrgenommener Milchkonsum nach Geschlecht\nGeschlecht\nwahr. Milchkonsum\nabsolute Werte\nwahr. Milchkonsum (%)\nFrau\nviel\n428\n87.0\nFrau\nwenig\n64\n13.0\nMann\nviel\n580\n89.5\nMann\nwenig\n68\n10.5\n\nMusterlösung Übung 1.2: t-Test\n\nLeseempfehlung Kapitel 2 von Manny Gimond\n\nNull- und Alternativhypothese\n\\(H_0\\): Es gibt keine Unterschiede in den Verkaufszahlen zwischen Basis- und Interventionswochen.\n\\(H_1\\): Es gibt Unterschiede in den Verkaufszahlen zwischen Basis- und Interventionswochen.\n\n\n# Gemäss Aufgabenstellung müsset die Daten zuerst nach Kalenderwochen \"week\" \n# und Bedingungen \"condition\" zusammengefasst werden\n\ndf <- nova %>%\n    group_by(week, condit) %>%  \n    summarise(tot_sold = n()) \n\n# überprüft die Voraussetzungen für einen t-Test\nggplot2::ggplot(df, aes(x = condit, y= tot_sold)) + # achtung 0 Punkt fehlt\n    geom_boxplot(fill = \"white\", color = \"black\", size = 1) + \n    labs(x=\"\\nBedingungen\", y=\"Durchschnittlich verkaufte Gerichte pro Woche\\n\") + \n    mytheme\n\n\n\n# Auf den ersten Blick scheint es keine starken Abweichungen zu einer \n#Normalverteilung zu geben resp. es sind keine extremen schiefen Verteilungen\n# ersichtlich (vgl. Skript Statistik 2)\n\n\n\n\n\n# führt einen t-Tests durch; \n# es wird angenommen, dass die Verkaufszahlen zwischen den Bedingungen \n# unabhängig sind\n\nt_test <- t.test(tot_sold ~ condit, data=df, var.equl = T)\n\n#alternative Formulierung\nt.test(df[df$condit == \"Basis\", ]$tot_sold, \n                 df[df$condit == \"Intervention\", ]$tot_sold) \n\n\n\n    Welch Two Sample t-test\n\ndata:  df[df$condit == \"Basis\", ]$tot_sold and df[df$condit == \"Intervention\", ]$tot_sold\nt = 0.27168, df = 9.9707, p-value = 0.7914\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -115.2743  147.2743\nsample estimates:\nmean of x mean of y \n     2203      2187 \n\nMethoden\nZiel war es die aggregierten Verkaufszahlen zwischen den Interventions- und Basiswochen zu vergleichen. Die Annahme ist, dass die wöchentlichen Verkaufszahlen unabhängig sind. Daher können die Unterschiede zwischen den Verkaufszahlen pro Woche zwischen den beiden Bedingungen mittels t-Test geprüft werden. Obwohl die visuelle Inspektion keine schwerwiegenden Verletzungen der Modelvoraussetzung zeigte, wurde einen Welch t-Test gerechnet. Zudem muss gesagt werden, dass die Gruppengrösse hier jeweils mit n = 6 (Anzahl Wochen) eher klein ist. T-test liefern dennoch relativ reliable Resultate. Für mehr Infos dazu hier eine Studie.\nErgebnisse\nIn den Basiswochen werden mehr Gerichte pro Woche verkauft als in den Interventionsowochen (siehe Abbildung 1). Die wöchentlichen Verkaufszahlen zwischen den Bedigungen (Basis oder Intervention) unterscheiden sich gemäss Welch t-Test jedoch nicht signifikant (t(10) = 0.272 , p = 0.791). Die Ergebnisse könnten mit einem \\(\\chi^2\\)-Test nochmals validiert werden, da die Gruppengrösse mit n = 6 doch eher klein ist.\n\n\n\nFigure 1: Die wöchentlichen Verkaufszahlen für die Interventions- und Basiswochen unterscheiden sich nicht signifikant.\n\n\n\n\n\n\n",
    "preview": "statistik/Statistik1_04_Solution/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik2_01_Demo/",
    "title": "Demo Statistik 2",
    "description": {},
    "author": [],
    "date": "2021-11-02",
    "categories": [
      "Statistik2"
    ],
    "contents": "\n\nContents\nt-test als ANOVA\nEchte ANOVA\nTukeys Posthoc-Test\nBeispiel Posthoc-Labels in Plot\nKlassische Tests der Modellannahmen (NICHT EMPFOHLEN!!!)\nNicht-parametrische Alternativen, wenn Modellannahmen der ANVOA massiv verletzt sind\nZum Vergleich normale ANOVA noch mal\nBei starken Abweichungen von der Normalverteilung, aber ähnlichen Varianzen\nKruskal-Wallis-Test\nBei erheblicher Heteroskedastizität, aber relative normal/symmetrisch verteilten Residuen\nWelch-Test\n2-faktorielle ANOVA\nKorrelationen\nBeispiele Modelldiagnostik\n\n\n\n\nDemoscript als Download\nt-test als ANOVA\n\n\na <- c(20, 19, 25, 10, 8, 15, 13 ,18, 11, 14)\nb <- c(12, 15, 16, 7, 8, 10, 12, 11, 13, 10)\n\nblume <- data.frame(cultivar = c(rep(\"a\", 10), rep(\"b\" , 10)), size = c(a, b))\n\npar(mfrow=c(1,1))\nboxplot(size~cultivar, xlab = \"Sorte\", ylab = \"Bluetengroesse [cm]\", data = blume)\n\n\n\nt.test(size~cultivar, blume, var.equal = T)\n\n\n\n    Two Sample t-test\n\ndata:  size by cultivar\nt = 2.0797, df = 18, p-value = 0.05212\nalternative hypothesis: true difference in means between group a and group b is not equal to 0\n95 percent confidence interval:\n -0.03981237  7.83981237\nsample estimates:\nmean in group a mean in group b \n           15.3            11.4 \n\naov(size~cultivar, data = blume)\n\n\nCall:\n   aov(formula = size ~ cultivar, data = blume)\n\nTerms:\n                cultivar Residuals\nSum of Squares     76.05    316.50\nDeg. of Freedom        1        18\n\nResidual standard error: 4.193249\nEstimated effects may be unbalanced\n\nsummary(aov(size~cultivar, data = blume))\n\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \ncultivar     1   76.0   76.05   4.325 0.0521 .\nResiduals   18  316.5   17.58                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(aov(size~cultivar, data = blume))\n\n\n\nCall:\naov(formula = size ~ cultivar, data = blume)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-7.300 -2.575 -0.350  2.925  9.700 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   15.300      1.326   11.54 9.47e-10 ***\ncultivarb     -3.900      1.875   -2.08   0.0521 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.193 on 18 degrees of freedom\nMultiple R-squared:  0.1937,    Adjusted R-squared:  0.1489 \nF-statistic: 4.325 on 1 and 18 DF,  p-value: 0.05212\n\nEchte ANOVA\n\n\nc <- c(30, 19, 31, 23, 18, 25, 26, 24, 17, 20)\n\nblume2 <- data.frame(cultivar = c(rep(\"a\", 10), rep(\"b\", 10), rep(\"c\", 10)), size = c(a, b, c))\nblume2$cultivar <- as.factor(blume2$cultivar)\n\nsummary(blume2)             \n\n\n cultivar      size      \n a:10     Min.   : 7.00  \n b:10     1st Qu.:11.25  \n c:10     Median :15.50  \n          Mean   :16.67  \n          3rd Qu.:20.00  \n          Max.   :31.00  \n\nhead(blume2)\n\n\n  cultivar size\n1        a   20\n2        a   19\n3        a   25\n4        a   10\n5        a    8\n6        a   15\n\npar(mfrow=c(1,1))\nboxplot(size~cultivar, xlab = \"Sorte\", ylab = \"Blütengrösse [cm]\", data = blume2)\n\n\n\naov(size~cultivar, data = blume2)\n\n\nCall:\n   aov(formula = size ~ cultivar, data = blume2)\n\nTerms:\n                cultivar Residuals\nSum of Squares  736.0667  528.6000\nDeg. of Freedom        2        27\n\nResidual standard error: 4.424678\nEstimated effects may be unbalanced\n\nsummary(aov(size~cultivar, data = blume2))\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar     2  736.1   368.0    18.8 7.68e-06 ***\nResiduals   27  528.6    19.6                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(aov(size~cultivar, data=blume2))\n\n\n\nCall:\naov(formula = size ~ cultivar, data = blume2)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-7.300 -3.375 -0.300  2.700  9.700 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   15.300      1.399  10.935 2.02e-11 ***\ncultivarb     -3.900      1.979  -1.971 0.059065 .  \ncultivarc      8.000      1.979   4.043 0.000395 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.425 on 27 degrees of freedom\nMultiple R-squared:  0.582, Adjusted R-squared:  0.5511 \nF-statistic:  18.8 on 2 and 27 DF,  p-value: 7.683e-06\n\naov.1 <- aov(size~cultivar, data = blume2)\nsummary(aov.1)\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar     2  736.1   368.0    18.8 7.68e-06 ***\nResiduals   27  528.6    19.6                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(aov.1)\n\n\n\nCall:\naov(formula = size ~ cultivar, data = blume2)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-7.300 -3.375 -0.300  2.700  9.700 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   15.300      1.399  10.935 2.02e-11 ***\ncultivarb     -3.900      1.979  -1.971 0.059065 .  \ncultivarc      8.000      1.979   4.043 0.000395 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.425 on 27 degrees of freedom\nMultiple R-squared:  0.582, Adjusted R-squared:  0.5511 \nF-statistic:  18.8 on 2 and 27 DF,  p-value: 7.683e-06\n\n#Berechnung Mittelwerte usw. zur Charakterisierung der Gruppen\naggregate(size~cultivar, blume2, function(x) c(Mean = mean(x), SD = sd(x), Min = min(x), Max = max(x)))\n\n\n  cultivar size.Mean   size.SD  size.Min  size.Max\n1        a 15.300000  5.207900  8.000000 25.000000\n2        b 11.400000  2.836273  7.000000 16.000000\n3        c 23.300000  4.854551 17.000000 31.000000\n\nlm.1 <- lm(size~cultivar, data = blume2)\nsummary(lm.1)\n\n\n\nCall:\nlm(formula = size ~ cultivar, data = blume2)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-7.300 -3.375 -0.300  2.700  9.700 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   15.300      1.399  10.935 2.02e-11 ***\ncultivarb     -3.900      1.979  -1.971 0.059065 .  \ncultivarc      8.000      1.979   4.043 0.000395 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.425 on 27 degrees of freedom\nMultiple R-squared:  0.582, Adjusted R-squared:  0.5511 \nF-statistic:  18.8 on 2 and 27 DF,  p-value: 7.683e-06\n\nTukeys Posthoc-Test\n\n\nif(!require(agricolae)){install.packages(\"agricolae\")}\nlibrary(agricolae)\n\nHSD.test(aov.1, \"cultivar\", group = FALSE, console = T)\n\n\n\nStudy: aov.1 ~ \"cultivar\"\n\nHSD Test for size \n\nMean Square Error:  19.57778 \n\ncultivar,  means\n\n  size      std  r Min Max\na 15.3 5.207900 10   8  25\nb 11.4 2.836273 10   7  16\nc 23.3 4.854551 10  17  31\n\nAlpha: 0.05 ; DF Error: 27 \nCritical Value of Studentized Range: 3.506426 \n\nComparison between treatments means\n\n      difference pvalue signif.        LCL       UCL\na - b        3.9 0.1388          -1.006213  8.806213\na - c       -8.0 0.0011      ** -12.906213 -3.093787\nb - c      -11.9 0.0000     *** -16.806213 -6.993787\n\nBeispiel Posthoc-Labels in Plot\n\n\naov.2 <- aov(Sepal.Width ~ Species, data = iris)\nHSD.test(aov.2, \"Species\", console = T)\n\n\n\nStudy: aov.2 ~ \"Species\"\n\nHSD Test for Sepal.Width \n\nMean Square Error:  0.1153878 \n\nSpecies,  means\n\n           Sepal.Width       std  r Min Max\nsetosa           3.428 0.3790644 50 2.3 4.4\nversicolor       2.770 0.3137983 50 2.0 3.4\nvirginica        2.974 0.3224966 50 2.2 3.8\n\nAlpha: 0.05 ; DF Error: 147 \nCritical Value of Studentized Range: 3.348424 \n\nMinimun Significant Difference: 0.1608553 \n\nTreatments with the same letter are not significantly different.\n\n           Sepal.Width groups\nsetosa           3.428      a\nvirginica        2.974      b\nversicolor       2.770      c\n\nboxplot(Sepal.Width ~ Species, data = iris)\n\n\n\nboxplot(Sepal.Width ~ Species, ylim = c(2, 5), data = iris)\ntext(1, 4.8, \"a\")\ntext(2, 4.8, \"c\")\ntext(3, 4.8, \"b\")\n\n\n\nlibrary(tidyverse)\nggplot(iris, aes(Species, Sepal.Width)) + geom_boxplot(size = 1) +\n  annotate(\"text\", y = 5, x = 1:3, label = c(\"a\", \"c\", \"b\"))\n\n\n\n\nKlassische Tests der Modellannahmen (NICHT EMPFOHLEN!!!)\n\n\nshapiro.test(blume2$size[blume2$cultivar == \"a\"])\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  blume2$size[blume2$cultivar == \"a\"]\nW = 0.97304, p-value = 0.9175\n\nvar.test(blume2$size[blume2$cultivar == \"a\"], blume2$size[blume2$cultivar == \"b\"])\n\n\n\n    F test to compare two variances\n\ndata:  blume2$size[blume2$cultivar == \"a\"] and blume2$size[blume2$cultivar == \"b\"]\nF = 3.3715, num df = 9, denom df = 9, p-value = 0.08467\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n  0.8374446 13.5738284\nsample estimates:\nratio of variances \n          3.371547 \n\nif(!require(car)){install.packages(\"car\")}\nlibrary(car)\nleveneTest(blume2$size[blume2$cultivar == \"a\"], blume2$size[blume2$cultivar == \"b\"], center=mean)\n\n\nLevene's Test for Homogeneity of Variance (center = mean)\n      Df    F value    Pr(>F)    \ngroup  7 2.2598e+30 < 2.2e-16 ***\n       2                         \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nwilcox.test(blume2$size[blume2$cultivar == \"a\"], blume2$size[blume2$cultivar == \"b\"])\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  blume2$size[blume2$cultivar == \"a\"] and blume2$size[blume2$cultivar == \"b\"]\nW = 73, p-value = 0.08789\nalternative hypothesis: true location shift is not equal to 0\n\nNicht-parametrische Alternativen, wenn Modellannahmen der ANVOA massiv verletzt sind\nZum Vergleich normale ANOVA noch mal\n\n\nsummary(aov(size~cultivar, data = blume2))\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar     2  736.1   368.0    18.8 7.68e-06 ***\nResiduals   27  528.6    19.6                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nBei starken Abweichungen von der Normalverteilung, aber ähnlichen Varianzen\nKruskal-Wallis-Test\n\n\nkruskal.test(size~cultivar, data = blume2)\n\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  size by cultivar\nKruskal-Wallis chi-squared = 16.686, df = 2, p-value =\n0.0002381\n\nif(!require(FSA)){install.packages(\"FSA\")} \nlibrary(FSA)\n#korrigierte p-Werte nach Bejamini-Hochberg\ndunnTest(size~cultivar, method = \"bh\", data = blume2) \n\n\n  Comparison         Z      P.unadj        P.adj\n1      a - b  1.526210 1.269575e-01 0.1269575490\n2      a - c -2.518247 1.179407e-02 0.0176911039\n3      b - c -4.044457 5.244459e-05 0.0001573338\n\nBei erheblicher Heteroskedastizität, aber relative normal/symmetrisch verteilten Residuen\nWelch-Test\n\n\noneway.test(size~cultivar, var.equal = F, data = blume2)\n\n\n\n    One-way analysis of means (not assuming equal variances)\n\ndata:  size and cultivar\nF = 21.642, num df = 2.000, denom df = 16.564, p-value =\n2.397e-05\n\n2-faktorielle ANOVA\n\n\nd <- c(10, 12, 11, 13, 10, 25, 12, 30, 26, 13)\ne <- c(15, 13, 18, 11, 14, 25, 39, 38, 28, 24)\nf <- c(10, 12, 11, 13, 10, 9, 2, 4, 7, 13)\n\nblume3 <- data.frame(cultivar=c(rep(\"a\", 20), rep(\"b\", 20), rep(\"c\", 20)),\n                   house = c(rep(c(rep(\"yes\", 10), rep(\"no\", 10)), 3)),\n                  size = c(a, b, c, d, e, f))\n\n\n\n\n\nblume3\n\n\n\n\n\nboxplot(size~cultivar + house, data = blume3)\n\n\n\nsummary(aov(size~cultivar + house, data = blume3))\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar     2  417.1   208.5   5.005     0.01 *  \nhouse        1  992.3   992.3  23.815 9.19e-06 ***\nResiduals   56 2333.2    41.7                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(aov(size~cultivar + house + cultivar:house, data = blume3)) \n\n\n               Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar        2  417.1   208.5   5.364   0.0075 ** \nhouse           1  992.3   992.3  25.520 5.33e-06 ***\ncultivar:house  2  233.6   116.8   3.004   0.0579 .  \nResiduals      54 2099.6    38.9                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#Kurzschreibweise: \"*\" bedeutet, dass Interaktion zwischen cultivar und house eingeschlossen wird\nsummary(aov(size~cultivar * house, data = blume3)) \n\n\n               Df Sum Sq Mean Sq F value   Pr(>F)    \ncultivar        2  417.1   208.5   5.364   0.0075 ** \nhouse           1  992.3   992.3  25.520 5.33e-06 ***\ncultivar:house  2  233.6   116.8   3.004   0.0579 .  \nResiduals      54 2099.6    38.9                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(aov(size~cultivar+house, data = blume3))\n\n\n\nCall:\naov(formula = size ~ cultivar + house, data = blume3)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.733 -4.696 -1.050  2.717 19.133 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    9.283      1.667   5.570 7.52e-07 ***\ncultivarb      6.400      2.041   3.135  0.00273 ** \ncultivarc      2.450      2.041   1.200  0.23509    \nhouseyes       8.133      1.667   4.880 9.19e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.455 on 56 degrees of freedom\nMultiple R-squared:  0.3766,    Adjusted R-squared:  0.3432 \nF-statistic: 11.28 on 3 and 56 DF,  p-value: 6.848e-06\n\ninteraction.plot(blume3$cultivar, blume3$house, blume3$size)\n\n\n\ninteraction.plot(blume3$house, blume3$cultivar, blume3$size)\n\n\n\nanova(lm(blume3$size~blume3$cultivar*blume3$house), lm(blume3$size~blume3$cultivar+blume3$house))\n\n\nAnalysis of Variance Table\n\nModel 1: blume3$size ~ blume3$cultivar * blume3$house\nModel 2: blume3$size ~ blume3$cultivar + blume3$house\n  Res.Df    RSS Df Sum of Sq      F  Pr(>F)  \n1     54 2099.6                              \n2     56 2333.2 -2   -233.63 3.0044 0.05792 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(lm(blume3$size~blume3$house), lm(blume3$size~blume3$cultivar * blume3$house))\n\n\nAnalysis of Variance Table\n\nModel 1: blume3$size ~ blume3$house\nModel 2: blume3$size ~ blume3$cultivar * blume3$house\n  Res.Df    RSS Df Sum of Sq      F   Pr(>F)   \n1     58 2750.3                                \n2     54 2099.6  4    650.73 4.1841 0.005045 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nKorrelationen\n\n\nlibrary(car)\n\nblume <- data.frame(a, b)\nscatterplot(a~b, blume)\n\n\n\ncor.test(a, b, method = \"pearson\", data = blume)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  a and b\nt = 3.3678, df = 8, p-value = 0.009818\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2628864 0.9414665\nsample estimates:\n      cor \n0.7657634 \n\ncor.test(a, b, method = \"spearman\", data = blume)\n\n\n\n    Spearman's rank correlation rho\n\ndata:  a and b\nS = 53.321, p-value = 0.03159\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6768419 \n\ncor.test(a, b, method = \"kendall\", data = blume) \n\n\n\n    Kendall's rank correlation tau\n\ndata:  a and b\nz = 2.0738, p-value = 0.03809\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.5228623 \n\n#Jetzt als Regression\nlm.2 <- lm(b~a)\nanova(lm.2)\n\n\nAnalysis of Variance Table\n\nResponse: b\n          Df Sum Sq Mean Sq F value   Pr(>F)   \na          1 42.455  42.455  11.342 0.009818 **\nResiduals  8 29.945   3.743                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(lm.2)\n\n\n\nCall:\nlm(formula = b ~ a)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.1897 -1.3388 -0.6067  1.3081  3.3933 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)   5.0193     1.9910   2.521  0.03575 * \na             0.4170     0.1238   3.368  0.00982 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.935 on 8 degrees of freedom\nMultiple R-squared:  0.5864,    Adjusted R-squared:  0.5347 \nF-statistic: 11.34 on 1 and 8 DF,  p-value: 0.009818\n\n#Model II-Regression\nif(!require(lmodel2)){install.packages(\"lmodel2\")} \nlibrary(lmodel2)\nlmodel2(b~a)\n\n\n\nModel II regression\n\nCall: lmodel2(formula = b ~ a)\n\nn = 10   r = 0.7657634   r-square = 0.5863936 \nParametric P-values:   2-tailed = 0.009817588    1-tailed = 0.004908794 \nAngle between the two OLS regression lines = 12.78218 degrees\n\nRegression results\n  Method Intercept     Slope Angle (degrees) P-perm (1-tailed)\n1    OLS  5.019254 0.4170422        22.63820                NA\n2     MA  4.288499 0.4648040        24.92919                NA\n3    SMA  3.067471 0.5446097        28.57314                NA\n\nConfidence intervals\n  Method 2.5%-Intercept 97.5%-Intercept 2.5%-Slope 97.5%-Slope\n1    OLS      0.4280737        9.610435  0.1314843   0.7026001\n2     MA     -1.4843783        8.769024  0.1719592   0.8421162\n3    SMA     -2.3775157        6.360555  0.3293755   0.9004912\n\nEigenvalues: 32.37967 2.786995 \n\nH statistic used for computing C.I. of MA: 0.0684968 \n\nBeispiele Modelldiagnostik\n\n\npar(mfrow=c(2, 2)) #4 Plots in einem Fenster\nplot(lm(b~a))\n\n\n\nif(!require(ggfortify)){install.packages(\"ggfortify\")}\nlibrary(ggfortify)\nautoplot(lm(b~a))\n\n\n\n# Modellstatistik nicht OK\ng <- c(20, 19, 25, 10, 8, 15, 13, 18, 11, 14, 25, 39, 38, 28, 24)\nh <- c(12, 15, 10, 7, 8, 10, 12, 11, 13, 10, 25, 12, 30, 26, 13)\npar(mfrow = c(1, 1))\n\nplot(h~g,xlim = c(0, 40), ylim = c(0, 30))\nabline(lm(h~g))\n\n\n\npar(mfrow = c(2, 2))\nplot(lm(h~g))\n\n\n\n# Modelldiagnostik mit ggplot\ndf <- data.frame(g, h)\nggplot(df, aes(x = g, y = h)) + \n    # scale_x_continuous(limits = c(0,25)) +\n    # scale_y_continuous(limits = c(0,25)) +\n    geom_point() +\n    geom_smooth( method = \"lm\", color = \"black\", size = .5, se = F) + \n    theme_classic()\n\n\n\npar(mfrow=c(2, 2))\nautoplot(lm(h~g))\n\n\n\n\n\n\n\n",
    "preview": "statistik/Statistik2_01_Demo/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik2_02_Assigment/",
    "title": "Übungen Statistik 2",
    "description": {},
    "author": [],
    "date": "2021-11-09",
    "categories": [
      "Statistik2"
    ],
    "contents": "\nAbzugeben sind am Ende\na. lauffähiges R-Skript\nb. begründeter Lösungsweg (Kombination aus R-Code, R Output \n   und dessen Interpretation)\nc. ausformulierter Methoden- und Ergebnisteil (für eine wiss.Arbeit).\nBitte erklärt und begründet die einzelnen Schritte, die ihr unternehmt, um zu eurem Ergebnis zu kommen. Dazu erstellt bitte ein Word-Dokument, in dem ihr Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, eure Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere Vorgehen dokumentiert.\nDieser Ablauf sollte insbesondere beinhalten:\nÜberprüfen der Datenstruktur nach dem Einlesen, welches sind die abhängige(n) und welches die unabängige(n) Variablen etc.\nExplorative Datenanalyse, um zu sehen, ob evtl. Dateneingabefehler vorliegen oder Datentransformationen vorgenommen werden sollten\nAuswahl und Begründung eines statistischen Verfahrens\nBestimmung des vollständigen/maximalen Models\nSelektion des/der besten Models/Modelle\nDurchführen der Modelldiagnostik für dieses\nGenerieren aller Zahlen, Statistiken und Tabellen, die für eine wiss. Ergebnisdarstellung benötigt werden\n\nFormuliert abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen/Tabellen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (je einen ausformulierten Absatz von ca. 60-100 Worten bzw. 3-8 Sätzen). Alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden.\nAufgabe 2.1: Regression\nRegressionsanalyse mit SAR.csv\nDer Datensatz beschreibt die Zunahme der Artenzahlen (richness) von Pflanzen in Trockenrasen der Schweiz in Abhängigkeit von der Probeflächengrösse (area, hier in m²). Diese Beziehung bezeichnet man als Artenzahl-Areal-Kurve (Species-area relationship = SAR).\nLadet den Datensatz in R und macht eine explorative Datenanalyse.\nWählt unter den schon gelernten Methoden der Regressionsanalyse ein adäquates Vorgehen zur Analyse dieser Daten und führt diese dann durch.\nPrüft anhand der Residuen, ob die Modellvoraussetzungen erfüllt waren\nFalls die Modelldiagnostik negativ ausfällt, überlegt, welche Datentransformation helfen könnte, und rechnet neue Modelle mit einer oder ggf. mehreren Datentransformationen, bis ihr eine statistisch zufriedenstellende Lösung gefunden habt.\nStellt die erhaltenen Ergebnisse angemessen dar (Text, Abbildung und/oder Tabelle).\nKennt ihr ggf. noch eine andere geeignete Herangehensweise?\nAufgabe 2.2: Einfaktorielle ANOVA\nANOVA mit novanimal_agg.csv\nFührt mit dem Datensatz novanimal.csv eine einfaktorielle ANOVA durch. Gibt es Unterschiede zwischen der Anzahl verkaufter Gerichte (Buffet, Fleisch oder Vegetarisch) pro Woche?\nHinweise für die Analysen:\nFasst die vier Inhalte der Gerichte zu drei Inhalten zusammen. Das heisst, dass die pflanzlichen Gerichte neu zu den vegetarischen Gerichten gezählt werden. Konkret könnt ihr das in R mit einer Umbenennung der Inhalte durchführen (z. B. mit stringr::str_replace()).\nDanach muss der Datensatz gruppiert und zusammengefasst werden.\nUnbekannte Menüinhalte können vernachlässigt werden.\nWie gut sind die Voraussetzungen für eine ANOVA erfüllt? Wären allenfalls auch nicht-parametrische Analysen zulässig?\nFührt anschliessend Post-hoc-Vergleiche durch.\nFasst die Ergebnisse in wenigen Sätzen zusammen und stellst die angemessen dar (Text mit Abbildung und/oder Tabelle)\nAufgabe 2.3N: Mehrfaktorielle ANOVA (NatWis)\nANOVA mit kormoran.csv\nDer Datensatz enthält 40 Beobachtungen zu Tauchzeiten zweier Kormoranunterarten (C = Phalocrocorax carbo carbo und S = Phalacrocorax carbo sinensis) aus vier Jahreszeiten (F = Frühling, S = Sommer, H = Herbst, W = Winter).\nLest den Datensatz nach R ein und führt eine adäquate Analyse durch, um beantworten zu können, wie Unterart und Jahreszeit die Tauchzeit beeinflussen.\nStellt eure Ergebnisse dann angemessen dar (Text mit Abbildung und/oder Tabelle).\nGibt es eine Interaktion?\nUebung 2.3S: Mehrfaktorielle ANOVA mit Interaktion (SozWis)\nANOVA mit novanimal_indiv.csv\nIn der Mensa gibt es zwei unterschiedliche Preisniveaus bzgl. den Gerichten: eine preisgünstigere Menülinie (“World” & “Favorite”) und eine teuere Menülinie (“Kitchen”). Gibt es Unterschiede zwischen dem Kauf von preisgünstigeren resp. teureren Menülinien betreffend Menüinhalt & Hochschulzugehörigkeit?\nHinweise für die Analysen:\nFasst die zwei günstigeren Menülinien “Favorite” & “World” zu einer Menülinie zusammen. Konkret könnt ihr das in R mit einer Umbenennung der Inhalte durchführen (z. B. mit stringr::str_replace() oder base::sub()).\nKleiner Hinweis: “Local” Gerichte könnt ihr zu den anderen Gerichten dazu zählen z.B. Local Favorite -> Favorite\nDanach muss der Datensatz gruppiert (nach Menülinie & Hochschulzugehörigkeit) und zusammengefasst werden.\nUnbekannte Menüinhalte können vernachlässigt werden.\nWie gut sind die Voraussetzungen für eine ANOVA erfüllt? Wären allenfalls auch nicht-parametrische Analysen zulässig?\nFührt anschliessend Post-hoc-Vergleiche durch.\nStellt eure Ergebnisse dann angemessen dar (Text mit Abbildung und/oder Tabelle).\n\n\n\n",
    "preview": {},
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik2_03_Solution_Stat_Beispiel/",
    "title": "Musterloesung Beispiel",
    "description": {},
    "author": [],
    "date": "2021-11-09",
    "categories": [
      "Statistik2"
    ],
    "contents": "\n\n\n\nMusterloesung Beispiel\nDatensatz decay.csv\nRCode als Download\nLoesungstext Beispiel\nÜbungsaufgabe (hier so ausführlich formuliert, wie dies auch in der Klausur der Fall sein wird)\nLaden Sie den Datensatz decay.csv. Dieser enthält die Zahl radioaktiver Zerfälle pro Zeiteinheit (amount) für Zeitpunkte (time) nach dem Start des Experimentes.\nErmitteln Sie ein statistisches Modell, dass die Zerfallshäufigkeit in Abhängigkeit von der Zeit beschreibt.\nBitte erklären und begründen Sie die einzelnen Schritte, die Sie unternehmen, um zu diesem Ergebnis zu kommen. Dazu erstellen Sie bitte ein Word-Dokument, in das Sie Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, Ihre Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere Vorgehen dokumentieren.\nDieser Ablauf sollte insbesondere beinhalten:\nÜberprüfen der Datenstruktur nach dem Einlesen, welches sind die abhängige(n) und welches die unabängige(n) Variablen\nExplorative Datenanalyse, um zu sehen, ob evtl. Dateneingabefehler vorliegen oder Datentransformationen vorgenommen werden sollten\nAuswahl und Begründung eines statistischen Verfahrens (es gibt hier mehrere statistisch korrekte Möglichkeiten!)\nErmittlung eines Modells\nDurchführen der Modelldiagnostik für das gewählte Modell\nGenerieren aller Zahlen, Statistiken und Tabellen, die für eine wiss. Ergebnisdarstellung benötigt werden\nFormulieren Sie abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (ausformulierte schriftliche Zusammenfassung, mit je einem Absatz von ca. 60-100 Worten, resp. 3-8 Sätzen für den Methoden- und Ergebnisteil). D. h. alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden.\nAbzugeben sind am Ende (a) Ein lauffähiges R-Skript; (b) begründeter Lösungsweg (Kombination aus R-Code, R Output und dessen Interpretation) und (c) ausformulierter Methoden- und Ergebnisteil (für eine wiss. Arbeit).\n\nkommentierter Loesungsweg\n\n\nsummary(decay)\n\n\n      time          amount       \n Min.   : 0.0   Min.   :  8.196  \n 1st Qu.: 7.5   1st Qu.: 21.522  \n Median :15.0   Median : 35.015  \n Mean   :15.0   Mean   : 42.146  \n 3rd Qu.:22.5   3rd Qu.: 57.460  \n Max.   :30.0   Max.   :125.000  \n\nstr(decay)\n\n\n'data.frame':   31 obs. of  2 variables:\n $ time  : int  0 1 2 3 4 5 6 7 8 9 ...\n $ amount: num  125 100.2 70 83.5 100 ...\n\nMan erkennt, dass es 31 Beobachtungen für die Zeit als Integer von Zerfällen gibt, die als rationale Zahlen angegeben werden (dass die Zahl der Zerfälle nicht ganzzahlig ist, deutet darauf hin, dass sie möglicherweise nur in einem Teil des Zeitintervalls oder für einen Teil des betrachteten Raumes gemessen und dann hochgerechnet wurde.\nExplorative Datenanalyse\n\n\nboxplot(decay$time)\n\n\n\nboxplot(decay$amount)\n\n\n\nplot(amount~time, data=decay)\n\n\n\n\nWährend der Boxplot für time wunderbar symmetrisch ohne Ausreisser ist, zeigt amount eine stark rechtsschiefe (linkssteile) Verteilung mit einem Ausreiser. Das deutet schon an, dass ein einfaches lineares Modell vermutlich die Modellannahmen verletzen wird. Auch der einfache Scatterplot zeigt, dass ein lineares Modell wohl nicht adäquat ist. Wir rechnen aber erst einmal weiter.\nEinfaches lineares Modell\n\n\nlm.1 <- lm(amount~time, data = decay)\nsummary(lm.1)\n\n\n\nCall:\nlm(formula = amount ~ time, data = decay)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.065 -10.029  -2.058   5.107  40.447 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  84.5534     5.0277   16.82  < 2e-16 ***\ntime         -2.8272     0.2879   -9.82 9.94e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.34 on 29 degrees of freedom\nMultiple R-squared:  0.7688,    Adjusted R-squared:  0.7608 \nF-statistic: 96.44 on 1 and 29 DF,  p-value: 9.939e-11\n\nDas sieht erst einmal nach einem Supermodell aus, höchstsignifikant und mit einem hohen R² von fast 77%. ABER: wir müssen uns noch die Modelldiagnostik ansehen…\nModelldiagnostik\n\n\npar(mfrow = c(2, 2))\nplot(lm.1)\n\n\n\n\nHier zeigen die wichtigen oberen Plots beide massive Abweichungen vom „Soll“. Der Plot oben links zeigt eine „Banane“ und beim Q-Q-Plot oben rechts weichen die Punkte rechts der Mitte alle stark nach oben von der Solllinie ab. Wir haben unser Modell also offensichtlich falsch spezifiziert. Um eine Idee zu bekommen, was falsch ist, plotten wir noch, wie das Ergebnis dieses Modells aussähe:\nErgebnisplot\n\n\npar(mfrow = c(1, 1))\nplot(decay$time, decay$amount)\nabline(lm.1, col = \"red\")\n\n\n\n\nDie Punkte links liegen alle über der Regressionslinie, die in der Mitte darunter und die ganz rechts wieder systematisch darüber (darum im Diagnostikplot oben die „Banane“). Es liegt also offensichtlich keine lineare Beziehung vor, sondern eine curvilineare.\nUm diese korrekt zu analysieren, gibt es im Prinzip drei Möglichkeiten, wovon am zweiten Kurstag nur eine hatten, während die zweite und dritte in Statistik 3 und 4 folgten. Im Folgenden sind alle drei nacheinander dargestellt (in der Klausur würde es aber genügen, eine davon darzustellen, wenn die Aufgabenstellung wie oben lautet).\nVariante (1): Lineares Modell nach Transformation der abhängigen Variablen\nDass die Verteilung der abhängigen Variable nicht normal ist, haben wir ja schon bei der explorativen Datenanalyse am Anfang gesehen. Da sie stark linkssteil ist, zugleich aber keine Nullwerte enthält, bietet sich eine Logarithmustransformation an, hier z. B. mit dem natürlichen Logarithmus.\nLoesung 1: log-Transformation der abhaengigen Variablen\n\n\npar(mfrow = c(1, 2))\nboxplot(decay$amount)\nboxplot(log(decay$amount))\n\n\n\nhist(decay$amount)\nhist(log(decay$amount))\n\n\n\n\nDie log-transformierte Variante rechts sieht sowohl im Boxplot als auch im #Histogramm viel symmetrischer/besser normalverteilt aus. Damit ergibt sich #dann folgendes lineares Modell\n\n\nlm.2 <- lm(log(amount)~time, data = decay)\nsummary(lm.2)\n\n\n\nCall:\nlm(formula = log(amount) ~ time, data = decay)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5935 -0.2043  0.0067  0.2198  0.6297 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  4.547386   0.100295   45.34  < 2e-16 ***\ntime        -0.068528   0.005743  -11.93 1.04e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.286 on 29 degrees of freedom\nMultiple R-squared:  0.8308,    Adjusted R-squared:  0.825 \nF-statistic: 142.4 on 1 and 29 DF,  p-value: 1.038e-12\n\nJetzt ist der R²-Wert noch höher und der p-Wert noch niedriger als im ursprünglichen linearen Modell ohne Transformation. Das erlaubt aber keine Aussage, da wir Äpfel mit Birnen vergleichen, da die abhängige Variable einmal untransformiert und einmal log-transformiert ist. Entscheidend ist die Modelldiagnostik.\nModelldiagnostik\n\n\npar(mfrow = c(2, 2))\nplot(lm.2)\n\n\n\n\nDer Q-Q-Plot sieht jetzt exzellent aus, der Plot rechts oben hat kaum noch eine Banane, nur noch einen leichten Keil. Insgesamt deutlich besser und auf jeden Fall ein statistisch korrektes Modell.\nLösungen 2 und 3 greifen auf Methoden von Statistik 3 und 4 zurück, sie sind hier nur zum Vergleich angeführt\nLoesung 2: quadratische Regression (kam erst in Statistik 3; koente fuer die Datenverteilung passen, entspricht aber nicht der physikalischen\nGesetzmaessigkeit\n\n\nmodel.quad <- lm(amount~time + I(time^2), data=  decay)\nsummary(model.quad)\n\n\n\nCall:\nlm(formula = amount ~ time + I(time^2), data = decay)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-22.302  -6.044  -1.603   4.224  20.581 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 106.38880    4.65627  22.849  < 2e-16 ***\ntime         -7.34485    0.71844 -10.223 5.90e-11 ***\nI(time^2)     0.15059    0.02314   6.507 4.73e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.205 on 28 degrees of freedom\nMultiple R-squared:  0.908, Adjusted R-squared:  0.9014 \nF-statistic: 138.1 on 2 and 28 DF,  p-value: 3.122e-15\n\nHier können wir R² mit dem ursprünglichen Modell vergleichen (beide haben amount als abhängige Grösse) und es sieht viel besser aus. Sowohl der lineare als auch der quadratische Term sind hochsignifikant. Sicherheitshalber vergleichen wir die beiden Modelle aber noch mittels ANOVA.\nVergleich mit dem einfachen Modell mittels ANOVA (es ginge auch AICc)\n\n\nanova(lm.1, model.quad)\n\n\nAnalysis of Variance Table\n\nModel 1: amount ~ time\nModel 2: amount ~ time + I(time^2)\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1     29 5960.6                                  \n2     28 2372.6  1    3588.1 42.344 4.727e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nIn der Tat ist das komplexere Modell (jenes mit dem quadratischen Term) höchstsignifikant besser. Jetzt brauchen wir noch die Modelldiagnostik.\nModelldiagnostik\n\n\npar(mfrow = c(2, 2))\nplot(model.quad)\n\n\n\n\nLoesung 3 (die beste, hatten wir aber am 2. Tag noch nicht; mit Startwerten muss man ggf. ausprobieren)\nmit Startwerten muss man ggf. ausprobieren)\n\n\nmodel.nls <- nls(amount~a*exp(-b*time), start=(list(a = 100, b = 1)),data = decay)\nsummary(model.nls)\n\n\n\nFormula: amount ~ a * exp(-b * time)\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)    \na 1.081e+02  4.993e+00   21.66  < 2e-16 ***\nb 8.019e-02  5.833e-03   13.75 3.12e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.243 on 29 degrees of freedom\n\nNumber of iterations to convergence: 8 \nAchieved convergence tolerance: 7.966e-06\n\nModelldiagnostik\n\n\nif(!require(nlstools)){install.packages(\"nlstools\")}\nlibrary(nlstools)\nresiduals.nls <- nlsResiduals(model.nls)\nplot(residuals.nls)\n\n\n\n\nFür nls kann man nicht den normalen Plotbefehl für die Residualdiagnostik nehmen, sondern verwendet das Äquivalent aus nlstools. Die beiden entscheidenden Plots sind jetzt links oben und rechts unten. Der QQ-Plot hat im unteren Bereich einen kleinen Schönheitsfehler, aber ansonsten ist alles OK.\nDa alle drei Lösungen zumindest statistisch OK waren, sollen jetzt noch die zugehörigen Ergebnisplots erstellt werden.\nErgebnisplots\n\n\npar(mfrow = c(1, 1))\nxv <- seq(0, 30, 0.1)\n\n\n\nlineares Modell mit log-transformierter Abhaengiger\n\n\nplot(decay$time, decay$amount)\nyv1 <- exp(predict(lm.2, list(time = xv)))\nlines(xv, yv1, col = \"red\")\n\n\n\n\nquadratisches Modell\n\n\nplot(decay$time, decay$amount)\nyv2 <- predict(model.quad, list(time = xv))\nlines(xv, yv2, col=  \"blue\")\n\n\n\n\nnicht-lineares Modell\n\n\nplot(decay$time, decay$amount)\nyv3 <- predict(model.nls, list(time = xv))\nlines(xv, yv3, col = \"green\")\n\n\n\n\nOptisch betrachtet, geben (2) und (3) den empirischen Zusammenhang etwas besser wieder als (1), da sie im linken Bereich die hohen Werte besser treffen. Man könnte sogar meinen, bei Betrachtung der Daten, dass die Werte ab time = 28 wieder leicht ansteigen, was die quadratische Funktion wiedergibt. Wer sich aber mit Physik etwas auskennt, weiss, dass Version (2) physikalisch nicht zutrifft, da die Zerfallsrate mit der Zeit immer weiter abfällt. Aufgrund der kurzen Messreihe wäre eine quadratische Funktion trotzdem eine statistisch korrekte Interpretation. Mit längeren Messreihen würde sich jedoch schnell zeigen, dass sie nicht zutrifft.\n\n\n\n",
    "preview": "statistik/Statistik2_03_Solution_Stat_Beispiel/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik2_04_solution_2.1/",
    "title": "Musterlösung Übung 2.1 Regression",
    "description": {},
    "author": [],
    "date": "2021-11-05",
    "categories": [
      "Statistik2"
    ],
    "contents": "\n\nContents\nLösungsweg\n\n\n\n\nRCode als Download\nLösungstext als Download\nLösungsweg\n\n\nSAR <- read.delim(\"SAR.csv\", sep = \";\")\n\n\n\n\n\nSAR\n\n\n\nExplorative Datenanalyse\n\n\nsummary(SAR)\n\n\n      area             richness    \n Min.   :  0.0001   Min.   : 1.00  \n 1st Qu.:  0.0010   1st Qu.: 4.00  \n Median :  0.1000   Median : 9.00  \n Mean   :  9.4017   Mean   :16.37  \n 3rd Qu.:  1.0000   3rd Qu.:24.00  \n Max.   :100.0000   Max.   :85.00  \n\nboxplot(SAR$area) # extrem rechtsschief\n\n\n\nboxplot(SAR$richness) # extrem rechtsschief\n\n\n\nplot(richness~area, data = SAR) # sieht nicht linear aus\n\n\n\n\nEinfaches lineares Modell\n\n\nlm.1 <- lm(richness~area, data = SAR)\nsummary(lm.1)\n\n\n\nCall:\nlm(formula = richness ~ area, data = SAR)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.567  -8.474  -3.503   6.112  35.317 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  11.4742     0.9582   11.97   <2e-16 ***\narea          0.5209     0.0342   15.23   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.27 on 154 degrees of freedom\nMultiple R-squared:  0.601, Adjusted R-squared:  0.5984 \nF-statistic: 231.9 on 1 and 154 DF,  p-value: < 2.2e-16\n\nModelldiagnostik\n\n\npar(mfrow = c(2, 2))\nplot(lm.1)\n\n\n\n\nErgebnisplot\n\n\npar(mfrow = c(1, 1))\nplot(SAR$area, SAR$richness, xlab = \"Area [m²]\", ylab = \"Species richness\")\nabline(lm(richness~area, data = SAR), col = \"red\") #Alternative 1\nabline(lm.1, col = \"red\") #Alternative 2\n\n\n\n\nLösung A: log-Transformation der abhängigen Variablen\n\n\npar(mfrow=c(1,2))\nboxplot(SAR$richness)\nboxplot(log10(SAR$richness))\n\n\n\nhist(SAR$richness)\nhist(log10(SAR$richness))\n\n\n\nSAR$log_richness <- log10(SAR$richness)\nlm.2 <- lm(log_richness~area, data = SAR)\nsummary(lm.2)\n\n\n\nCall:\nlm(formula = log_richness ~ area, data = SAR)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.85613 -0.34114 -0.01204  0.36365  0.75729 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 0.856116   0.036657   23.36  < 2e-16 ***\narea        0.010259   0.001309    7.84 6.94e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4313 on 154 degrees of freedom\nMultiple R-squared:  0.2853,    Adjusted R-squared:  0.2806 \nF-statistic: 61.47 on 1 and 154 DF,  p-value: 6.939e-13\n\nModelldiagnostik\n\n\npar(mfrow = c(2, 2))\nplot(lm.2)\n\n\n\n\n#sieht noch schlechter aus\nLösung B: log-Transformation beider Variablen\n\n\npar(mfrow=c(1,2))\nboxplot(SAR$area)\nboxplot(log10(SAR$area))\n\n\n\nhist(SAR$area)\nhist(log10(SAR$area))\n\n\n\nSAR$log_area <- log10(SAR$area)\nlm.3 <- lm(log_richness~log_area, data = SAR)\nsummary(lm.3)\n\n\n\nCall:\nlm(formula = log_richness ~ log_area, data = SAR)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.50241 -0.09353  0.02130  0.09965  0.40068 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 1.265730   0.015607   81.10   <2e-16 ***\nlog_area    0.254440   0.006926   36.73   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1633 on 154 degrees of freedom\nMultiple R-squared:  0.8976,    Adjusted R-squared:  0.8969 \nF-statistic:  1349 on 1 and 154 DF,  p-value: < 2.2e-16\n\nModelldiagnostik\n\n\npar(mfrow = c(2, 2))\nplot(lm.3)\n\n\n\n\ndas sieht jetzt sehr gut aus, bis auf zwei Ausreisser im QQ-Plot\nErgebnisplots C \n\n\npar(mfrow = c(1, 1))\nxv <- seq(0, 100, 0.1)\n\n\n\nErgebnisplots\n\n\npar(mfrow = c(1,1))\nxv <- seq(0,100,0.1)\n\n\n\nA. lineares Modell mit log-transformierter Abhaengiger\n\n\nplot(SAR$area, SAR$richness)\nyv1a <- 10^predict(lm.2, list(area = xv))\nlines(xv, yv1a, col = \"blue\")\n\n\n\n\nB. lineares Modell mit log-Transformation beider Variablen\n\n\nxvlog <- seq(-4,2,0.1)\nplot(SAR$log_area, SAR$log_richness, xlab = \"log10 (Fläche [m²])\", ylab = \"log10 (Artenreichtum)\")\nyv1b <- predict(lm.3, list(log_area = xvlog))\nlines(xvlog, yv1b, col = \"green\")\n\n\n\n\nB. lineares Modell mit log-Transformation beider Variablen (zurücktransformiert)\n\n\nplot(SAR$area, SAR$richness, xlab = \"Fläche [m²]\", ylab = \"Artenreichtum\")\nyv1b <- predict(lm.3, list(log_area = xv))\nlines(10^xv, 10^yv1b, col = \"green\")\n\n\n\n\nModelle im Vergleich\n\n\n#Modelle im Vergleich\nplot(SAR$area, SAR$richness)\nabline(lm.1, col=\"red\")\nlines(xv, yv1a, col=\"blue\")\nlines(10^xv, 10^yv1b, col=\"green\")\n\n\n\n\n\n\n\n",
    "preview": "statistik/Statistik2_04_solution_2.1/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik2_05_Solution/",
    "title": "Musterlösung Übung 2.2 & 2.3s",
    "description": {},
    "author": [
      {
        "name": "Gian-Andrea Egeler",
        "url": {}
      }
    ],
    "date": "2021-11-09",
    "categories": [
      "Statistik2"
    ],
    "contents": "\n\nContents\nMusterlösung Übung 2.2\nkommentierter Lösungsweg\nMethoden\nErgebnisse\n\nMusterlösung Übung 2.3S (SozWis)\nkommentierter Lösungsweg\nMethode\nErgebnisse\n\n\n\n\n\n\nDownload R-Skript\n\nMusterlösung Übung 2.2\nkommentierter Lösungsweg\n\n\n\n\n\ndf <- nova # klone den originaler Datensatz\n\n# fasst die vier Inhalte der Gerichte zu drei Inhalten zusammen.\ndf %<>%\n  # Geflügel & Fisch zu fleischgerichte zählen\n  mutate(label_content = str_replace(label_content, \"Geflügel|Fisch\", \"Fleisch\")) %>% \n  # achtung reihenfolge spielt eine rolle, wegen des + (plus)\n  mutate(label_content = str_replace(label_content, \"Pflanzlich[+]|Pflanzlich\", \"Vegetarisch\"))\n\n# gruppiert Daten nach Menü-Inhalt und Woche\ndf %<>%\n    group_by(label_content, week) %>% \n    summarise(tot_sold = n()) %>%\n    drop_na() %>% \n    ungroup() # lasst die unbekannten Menü-Inhalte weg\n\n# überprüft die Voraussetzungen für eine ANOVA\n# Schaut euch die Verteilungen der Mittelwerte an (plus Standardabweichungen)\n# Sind Mittelwerte nahe bei Null? \n# Gäbe uns einen weiteren Hinweis auf eine spezielle Binomail-Verteilung \ndf %>% \n  split(.$label_content) %>% # teilt den Datensatz in 3 verschiedene Datensätze auf\n  purrr::map(~ psych::describe(.$tot_sold)) # mit map können andere Funktionen \n\n\n$Fleisch\n   vars  n    mean     sd median trimmed    mad min  max range skew\nX1    1 12 1135.58 200.03   1088  1129.2 223.13 917 1418   501 0.19\n   kurtosis    se\nX1    -1.89 57.74\n\n$`Hot and Cold`\n   vars  n   mean    sd median trimmed   mad min max range skew\nX1    1 12 308.33 23.53    310   307.3 30.39 276 351    75 0.32\n   kurtosis   se\nX1    -1.25 6.79\n\n$Vegetarisch\n   vars  n   mean     sd median trimmed    mad min  max range  skew\nX1    1 12 739.25 213.54    710   741.8 323.95 449 1004   555 -0.01\n   kurtosis    se\nX1    -1.85 61.64\n\n# auf den Datensatz angewendet werden (alternative Funktionen sind aggregate oder apply)\n\n\n# Boxplot\nggplot(df, aes(x = label_content, y= tot_sold)) +\n  # Achtung: Reihenfolge spielt hier eine Rolle!\n  stat_boxplot(geom = \"errorbar\", width = 0.25) +\n  geom_boxplot(fill=\"white\", color = \"black\", size = 1, width = .5) +\n  labs(x = \"\\nMenü-Inhalt\", y = \"Anzahl verkaufte Gerichte pro Woche\\n\") +\n  # achtung erster Hinweis einer Varianzheterogenität, wegen den Hot&Cold Gerichten\n  mytheme\n\n\n\n#alternative mit base\nboxplot(df$tot_sold~df$label_content)\n\n\n\n# definiert das Modell (vgl. Skript Statistik 2)\nmodel <- aov(tot_sold ~ label_content, data = df)\n\nsummary.lm(model)\n\n\n\nCall:\naov(formula = tot_sold ~ label_content, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-290.250 -135.083    1.667  125.500  282.417 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                1135.58      48.92  23.211  < 2e-16 ***\nlabel_contentHot and Cold  -827.25      69.19 -11.956 1.54e-13 ***\nlabel_contentVegetarisch   -396.33      69.19  -5.728 2.15e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 169.5 on 33 degrees of freedom\nMultiple R-squared:  0.8125,    Adjusted R-squared:  0.8012 \nF-statistic: 71.52 on 2 and 33 DF,  p-value: 1.007e-12\n\n# überprüft die Modelvoraussetzungen\npar(mfrow = c(2,2))\nplot(model)\n\n\n\n\nFazit: Inspektion der Modellvoraussetzung zeigt klare Verletzungen des Residualplots (zeigt einen “Trichter”, siehe Skript Statistik 2), D.h. die Voraussetzung der Homoskedastizität sind verletzt. Mögliche nächste Schritte:\nMenüinhalt “Buffet” aus der Analyse ausschliessen, da sowieso kein richtiger Menüinhalt (aber Informationsverlust)\nDatentransformation z.B. log-Transformation\nnicht-parametrischer Test (Achtung, auch dieser setzt Voraussetzungen voraus)\nein glm Model (general linear model) mit einer poisson/quasipoisson link Funktion (vgl. Skript Statistik 4), weitere Infos dazu Link \n\n\n# überprüft die Voraussetzungen des Welch-Tests:\n# Gibt es eine hohe Varianzheterogenität und ist die relative Verteilung der \n# Residuen gegeben? (siehe Statistik 2)\n# Ja Varianzheterogenität ist gegeben, aber die Verteilung der Residuen folgt \n# einem \"Trichter\", also keiner \"normalen/symmetrischen\" Verteilung um 0\n# Daher ziehe ich eine Transformation der AV einem nicht-parametrischen Test vor\n# für weitere Infos: \n# https://data.library.virginia.edu/interpreting-log-transformations-in-a-linear-model/\n\n# achtung hier log10, bei Rücktransformation achten\nmodel_log <- aov(log10(tot_sold) ~ label_content, data = df) \npar(mfrow = c(2,2))\nplot(model_log) # scheint ok zu sein\n\n\n\nsummary.lm(model_log) # Referenzkategorie ist Fleisch\n\n\n\nCall:\naov(formula = log10(tot_sold) ~ label_content, data = df)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.198920 -0.059343  0.003477  0.062579  0.150567 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                3.04908    0.02585 117.942  < 2e-16 ***\nlabel_contentHot and Cold -0.56121    0.03656 -15.350  < 2e-16 ***\nlabel_contentVegetarisch  -0.19792    0.03656  -5.413 5.45e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.08956 on 33 degrees of freedom\nMultiple R-squared:  0.8802,    Adjusted R-squared:  0.8729 \nF-statistic: 121.2 on 2 and 33 DF,  p-value: 6.238e-16\n\nTukeyHSD(model_log) # (vgl. Statistik 2)\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = log10(tot_sold) ~ label_content, data = df)\n\n$label_content\n                               diff        lwr        upr   p adj\nHot and Cold-Fleisch     -0.5612085 -0.6509215 -0.4714955 0.0e+00\nVegetarisch-Fleisch      -0.1979175 -0.2876305 -0.1082044 1.6e-05\nVegetarisch-Hot and Cold  0.3632910  0.2735780  0.4530041 0.0e+00\n\n# Achtung Beta-Werte resp. Koeffinzienten sind nicht direkt interpretierbar\n# sie müssten zuerst wieder zurück transformiert werden, hier ein Beispiel dafür:\n# für Fleisch\n10^model_log$coefficients[1]\n\n\n(Intercept) \n   1119.655 \n\n# für Hot & Cold,\n10^(model_log$coefficients[1] + model_log$coefficients[2])\n\n\n(Intercept) \n   307.5216 \n\n# ist equivalent zu\n10^(model_log$coefficients[1]) * 10^(model_log$coefficients[2])\n\n\n(Intercept) \n   307.5216 \n\n# für Vegi\n10^(model_log$coefficients[1] + model_log$coefficients[3])\n\n\n(Intercept) \n   709.8501 \n\nMethoden\nZiel war es, die Unterschiede in den wöchentlichen Verkaufszahlen pro Menüinhalt aufzuzeigen. Da die Responsevariable (Verkaufszahlen) “metrisch” und die Prädiktorvariable kategorial sind, wurde eine einfaktorielle ANOVA gerechnet. Die visuelle Inspektion des Modells zeigte insbesondere schwere Verletzungen der Homoskedastizität. Der Boxplot bestätigt dieser Befund. Weil die Voraussetzungen schwer verletzt sind, wurde eine log-Transformation der Responsevariable vorgenommen. Anschliessend wurde erneut eine ANOVA gerechnet und die Modelvoraussetzungen visuell inspiziert: Homoskedastizität und Normalverteilung der Residuen sind gegeben. Für mehr Informatinen zu log-Transformationen und Darstellung der Ergebnisse findet ihr hier\nErgebnisse\nDie Menüinhalte (Fleisch, Vegetarisch und Buffet) unterscheiden sich in den wöchentlichen Verkaufszahlen signifikant (F(2,15) = 121.22, p < .001). Die Abbildung 1 zeigt die wöchentlichen Verkaufszahlen pro Menüinhalt.\n\n\n\nFigure 1: Die wöchentlichen Verkaufzahlen unterscheiden sich je nach Menüinhalt stark. Das Modell wurde mit den log-tranformierten Daten gerechnet.\n\n\n\nMusterlösung Übung 2.3S (SozWis)\nLese-Empfehlung Kapitel 7 von Manny Gimond\nkommentierter Lösungsweg\n\n\n\n\n\n# klone den originaler Datensatz\ndf <- nova \n\n# Daten vorbereiten\ndf %<>% # schaut euch das Package \"magrittr\" an\n  # ersetze Local mit einem leeren String\n  mutate(article_description = str_replace(article_description, \"Local \", \"\")) %>% \n  filter(article_description != \"Hot and Cold\") %>% # lasse Buffet Gerichte weg\n  filter(member != \"Spezialkarten\") %>% # Spezialkarten können vernachlässigt werden\n  #  fasse die zwei Menülinien \"World & Favorite\" zusammen\n  mutate(article_description = str_replace_all(article_description, \"Favorite|World\",\n                                               \"Fav_World\"))  \n\n# gruppiere Daten nach Menülinie, Geschlecht und Hochschulzugehörigkeit\ndf %<>%\n    group_by(article_description, member, week) %>% \n    summarise(tot_sold = n()) %>%\n    ungroup() %>% \n    drop_na()  # lasst die unbekannten Menü-Inhalte weg\n\n# überprüft die Voraussetzungen für eine ANOVA\n# Schaut euch die Verteilungen der Mittelwerte der Responsevariable an\n# Sind Mittelwerte nahe bei Null? Gäbe uns einen weiteren Hinweis auf \n# eine spezielle Binomial-Verteilung (vgl. Statistik 4)\ndf %>% \n  split(.$article_description) %>% # teilt den Datensatz in 3 verschiedene Datensätze auf\n  # mit map können andere Funktionen auf den Datensatz angewendet werden \n  # (alternative Funktionen sind aggregate oder apply)\n  purrr::map(~ psych::describe(.$tot_sold)) \n\n\n$Fav_World\n   vars  n   mean     sd median trimmed    mad min max range skew\nX1    1 24 622.67 178.79  599.5   620.8 253.52 378 876   498 0.04\n   kurtosis   se\nX1    -1.88 36.5\n\n$Kitchen\n   vars  n  mean    sd median trimmed   mad min max range skew\nX1    1 24 128.5 22.21  124.5   128.2 23.72  79 187   108 0.27\n   kurtosis   se\nX1     0.43 4.53\n\n# visualisiere dir dein Model, was siehst du? \n# sind möglicherweise gewiesse Voraussetzungen verletzt?\n# Boxplot\nggplot(df, aes(x = interaction(article_description, member), y= tot_sold)) + \n   # Achtung: Reihenfolge spielt hier eine Rolle!\n  stat_boxplot(geom = \"errorbar\", width = 0.25) +\n  geom_boxplot(fill=\"white\", color = \"black\", size = 1, width = .5) +\n  labs(x = \"\\nMenülinie nach Hochschulzugehörigkeit\", y = \"Anzahl verkaufte Gerichte\\n\") + \n  # ändere Gruppennamen händisch\n  scale_x_discrete(limits = c(\"Fav_World.Mitarbeitende\", \"Kitchen.Mitarbeitende\",\n                              \"Fav_World.Studierende\", \"Kitchen.Studierende\"),\n                   breaks = c(\"Fav_World.Mitarbeitende\", \"Fav_World.Studierende\",\n                              \"Kitchen.Mitarbeitende\",  \"Kitchen.Studierende\"),\n                   labels = c(\"Fav_World\\nMitarbeitende\", \"Fav_World\\nStudierende\",\n                              \"Kitchen\\nMitarbeitende\",  \"Kitchen\\nStudierende\")) +\n  mytheme # wie sind die Voraussetzungen erfüllt?\n\n\n\n\n\n\n# definiert das Modell (Skript Statistik 2)\nmodel <- aov(tot_sold ~ article_description * member, data = df)\n\nsummary.lm(model)\n\n\n\nCall:\naov(formula = tot_sold ~ article_description * member, data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-91.00 -17.33   0.50  14.83  83.00 \n\nCoefficients:\n                                             Estimate Std. Error\n(Intercept)                                   452.333      9.734\narticle_descriptionKitchen                   -327.000     13.766\nmemberStudierende                             340.667     13.766\narticle_descriptionKitchen:memberStudierende -334.333     19.469\n                                             t value Pr(>|t|)    \n(Intercept)                                    46.47   <2e-16 ***\narticle_descriptionKitchen                    -23.75   <2e-16 ***\nmemberStudierende                              24.75   <2e-16 ***\narticle_descriptionKitchen:memberStudierende  -17.17   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 33.72 on 44 degrees of freedom\nMultiple R-squared:  0.9864,    Adjusted R-squared:  0.9855 \nF-statistic:  1063 on 3 and 44 DF,  p-value: < 2.2e-16\n\n# überprüft die Modelvoraussetzungen (Statistik 2)\npar(mfrow = c(2,2)) # alternativ gäbe es die ggfortify::autoplot(model) funktion\nplot(model)\n\n\n\n\nFazit: Die Inspektion des Modells zeigt kleinere Verletzungen bei der Normalverteilung der Residuen (Q-Q Plot). Aufgrund keiner starken Verbesserung durch eine Transformation der Responsevariable, entscheide ich mich für eine ANOVA ohne log-tranformierten Responsevariablen (AV).\n\n\n# sieht aus, als ob die Voraussetzungen für eine Anova nur geringfügig verletzt sind\n# mögliche alternativen: \n# 0. keine Tranformation der AV (machen wir hier)\n# 1. log-transformation um die grossen werte zu minimieren (nur möglich, wenn \n# keine 0 enthalten sind und die Mittelwerte weit von 0 entfernt sind (bei uns wäre dieser Fall erfüllt)\n# => bei Zähldaten ist dies leider nicht immer gegeben)\n# 2. nicht parametrische Test z.B. Welch-Test, wenn hohe Varianzheterogenität \n# zwischen den Residuen\n\n#0) keine Tranformation\n# post-hov Vergleiche\nTukeyHSD(model)\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = tot_sold ~ article_description * member, data = df)\n\n$article_description\n                       diff      lwr       upr p adj\nKitchen-Fav_World -494.1667 -513.785 -474.5484     0\n\n$member\n                           diff      lwr      upr p adj\nStudierende-Mitarbeitende 173.5 153.8817 193.1183     0\n\n$`article_description:member`\n                                                     diff        lwr\nKitchen:Mitarbeitende-Fav_World:Mitarbeitende -327.000000 -363.75650\nFav_World:Studierende-Fav_World:Mitarbeitende  340.666667  303.91017\nKitchen:Studierende-Fav_World:Mitarbeitende   -320.666667 -357.42317\nFav_World:Studierende-Kitchen:Mitarbeitende    667.666667  630.91017\nKitchen:Studierende-Kitchen:Mitarbeitende        6.333333  -30.42317\nKitchen:Studierende-Fav_World:Studierende     -661.333333 -698.08983\n                                                     upr     p adj\nKitchen:Mitarbeitende-Fav_World:Mitarbeitende -290.24350 0.0000000\nFav_World:Studierende-Fav_World:Mitarbeitende  377.42317 0.0000000\nKitchen:Studierende-Fav_World:Mitarbeitende   -283.91017 0.0000000\nFav_World:Studierende-Kitchen:Mitarbeitende    704.42317 0.0000000\nKitchen:Studierende-Kitchen:Mitarbeitende       43.08983 0.9672944\nKitchen:Studierende-Fav_World:Studierende     -624.57683 0.0000000\n\n#1) Alterativ: log-transformation\nmodel_log <- aov(log10(tot_sold) ~ article_description * member, data = df)\n\nsummary.lm(model_log) # interaktion ist nun nicht mehr signifikant: vgl. \n\n\n\nCall:\naov(formula = log10(tot_sold) ~ article_description * member, \n    data = df)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.191372 -0.025043  0.003191  0.037604  0.182842 \n\nCoefficients:\n                                             Estimate Std. Error\n(Intercept)                                   2.65417    0.01696\narticle_descriptionKitchen                   -0.56517    0.02398\nmemberStudierende                             0.24438    0.02398\narticle_descriptionKitchen:memberStudierende -0.21726    0.03391\n                                             t value Pr(>|t|)    \n(Intercept)                                  156.533  < 2e-16 ***\narticle_descriptionKitchen                   -23.569  < 2e-16 ***\nmemberStudierende                             10.191 3.71e-13 ***\narticle_descriptionKitchen:memberStudierende  -6.407 8.51e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.05874 on 44 degrees of freedom\nMultiple R-squared:  0.9745,    Adjusted R-squared:  0.9728 \nF-statistic: 561.4 on 3 and 44 DF,  p-value: < 2.2e-16\n\n# nochmals euren Boxplot zu beginn, machen diese Koeffizienten sinn?\n\n# überprüft die Modelvoraussetzungen (vgl. Skript Statistik 2)\n# bringt aber keine wesentliche Verbesserung, daher bleibe ich bei den \n# untranfromierten Daten\npar(mfrow = c(2,2))\nplot(model_log)\n\n\n\n# post-hov Vergleiche\nTukeyHSD(model_log) # gibt sehr ähnliche Resultate im Vergleich zum nicht-transformierten Model\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = log10(tot_sold) ~ article_description * member, data = df)\n\n$article_description\n                        diff        lwr        upr p adj\nKitchen-Fav_World -0.6738029 -0.7079755 -0.6396302     0\n\n$member\n                               diff       lwr       upr p adj\nStudierende-Mitarbeitende 0.1357518 0.1015791 0.1699244     0\n\n$`article_description:member`\n                                                     diff         lwr\nKitchen:Mitarbeitende-Fav_World:Mitarbeitende -0.56517128 -0.62919652\nFav_World:Studierende-Fav_World:Mitarbeitende  0.24438333  0.18035809\nKitchen:Studierende-Fav_World:Mitarbeitende   -0.53805110 -0.60207634\nFav_World:Studierende-Kitchen:Mitarbeitende    0.80955461  0.74552937\nKitchen:Studierende-Kitchen:Mitarbeitende      0.02712017 -0.03690507\nKitchen:Studierende-Fav_World:Studierende     -0.78243444 -0.84645968\n                                                      upr     p adj\nKitchen:Mitarbeitende-Fav_World:Mitarbeitende -0.50114604 0.0000000\nFav_World:Studierende-Fav_World:Mitarbeitende  0.30840857 0.0000000\nKitchen:Studierende-Fav_World:Mitarbeitende   -0.47402586 0.0000000\nFav_World:Studierende-Kitchen:Mitarbeitende    0.87357985 0.0000000\nKitchen:Studierende-Kitchen:Mitarbeitende      0.09114541 0.6726112\nKitchen:Studierende-Fav_World:Studierende     -0.71840920 0.0000000\n\nMethode\nZiel war es die Unterschiede zwischen den preisgünstigeren und teureren Menülinien und der Hochschulzugehörigkeit herauszufinden: Hierfür wurde eine ANOVA mit Interaktion gerechnet, da wir eine (quasi)-metrische Responsevariable und zwei Prädiktorvariablen (Menülinie und Hochschulzugehörigkeit) haben.\nDie Voraussetzungen für eine ANOVA waren im ersten Model nicht stark verletzt, lediglich die Normalverteilung der Residuen: Deshalb habe wurde auf eine log-Transformation der Responsevariable verzichtet. Anschliessend wurden noch post-hoc Einzelvergleiche nach Tukey durchgeführt.\nKleiner Exkurs: Verkaufsdaten sind Zähldaten und perse binomial-Verteilt, da es keine negativen Werte geben kann. Ich versuche immer folgende Fragen zu beantworten:\nWie weit ist der Mittelwert von “Null entfernt”? -> Wenn ja uns keine Voraussetzungen zur Normalverteilung gibt, kann auch eine Normalverteilung angenommen werden\nBeinhalten die Daten viele “Null’s”? -> Wenn ja muss eine spezielle binomial Verteilung angenommen werden, z.B. negative binomiale Transformation mit GLM (see Skript XY)\nErgebnisse\nDie wöchentlichen Verkaufszahlen der Menülinien unterscheiden sich nach Hochschulzugehörigkeit signifikant (F(3,44) = 561.42, p < .001). Inhaltich bedeutet dies, dass Studierende signifikant häufiger die preisgünstigere Menülinie “Favorite & World” als Mitarbeitende kaufen. Entgegen der Annahme gibt es aber keine signifikanten Unterschiede zwischen Studierende und Mitarbeitende bei dem Kauf der teureren Menülinie “Kitchen”. Über die möglichen Gründe können nur spekuliert werden, hierfür bedarf es weiteren Analysen z.B. mit dem Prädiktor “Menüinhalt”.\n\n\n\nFigure 2: Box-Whisker-Plots der wöchentlichen Verkaufszahlen pro Menü-Inhalte. Kleinbuchstaben bezeichnen homogene Gruppen auf p < .05 nach Tukeys post-hoc-Test.\n\n\n\n\n\n\n",
    "preview": "statistik/Statistik2_05_Solution/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik2_06_solution_2.3n/",
    "title": "Musterlösung Übung 2.3n Mehrfaktorielle ANOVA",
    "description": {},
    "author": [],
    "date": "2021-11-09",
    "categories": [
      "Statistik2"
    ],
    "contents": "\n\n\n\nRCode als Download\nLoesungstext 2.3\nÜbungsaufgabe (hier so ausführlich formuliert, wie dies auch in der Klausur der Fall sein wird) - Laden Sie den Datensatz kormoran.csv mit ein Dieser enthält Tauchzeiten (hier ohne Einheit) von Kormoranen in Abhängigkeit von Jahreszeit und Unterart. Unterarten: Phalacrocorax carbo carbo (C) und Phalacrocorax carbo sinensis (S); Jahreszeiten: F = Frühling, S = Sommer, H = Herbst, W = Winter. - Ihre Gesamtaufgabe ist es, aus diesen Daten ein minimal adäquates Modell zu ermitteln, das diese Abhängigkeit beschreibt. - Bitte erklären und begründen Sie die einzelnen Schritte, die Sie unternehmen, um zu diesem Ergebnis zu kommen. Dazu erstellen Sie bitte ein Word-Dokument, in das Sie Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, Ihre Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere Vorgehen dokumentieren. - Dieser Ablauf sollte insbesondere beinhalten: - Überprüfen der Datenstruktur nach dem Einlesen, welches sind die abhängige(n) und welches die unabängige(n) Variablen, welches statistische Verfahren wenden Sie an? - Explorative Datenanalyse, um zu sehen, ob schon vor dem Start der Analysen Transformationen o.ä. vorgenommen werden sollten - Definition eines vollen Modelles, das nach statistischen Kritierien zum minimal adäquaten Modell reduziert wird - Durchführen der Modelldiagnostik, um zu entscheiden, ob das gewählte Vorgehen korrekt war oder ggf. angepasst werden muss - Generieren aller Zahlen, Statistiken und Tabellen, die für eine wiss. Ergebnisdarstellung benötigt werden - Formulieren Sie abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (ausformulierte schriftliche Zusammenfassung, mit je einem Absatz von ca. 60-100 Worten, resp. 3-8 Sätzen für den Methoden- und Ergebnisteil). D. h. alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden. - Abzugeben sind am Ende (a) Ein lauffähiges R-Skript; (b) begründeter Lösungsweg (Kombination aus R-Code, R Output und dessen Interpretation) und (c) ausformulierter Methoden- und Ergebnisteil (für eine wiss. Arbeit).\nkommentierter Lösungsweg\n\n\n# Working directory muss angepasst werden\nkormoran <- read.delim(\"kormoran.csv\", sep = \";\", stringsAsFactors = T)  # \n\n# Ueberpruefen, ob Einlesen richtig funktioniert hat und welche Datenstruktur vorliegt\nstr(kormoran)\n\n\n'data.frame':   40 obs. of  4 variables:\n $ ï..Obs    : int  1 2 3 4 5 6 7 8 9 10 ...\n $ Tauchzeit : num  9.5 11.9 13.4 13.8 15.3 15.5 15.6 16.7 16.8 18.7 ...\n $ Unterart  : Factor w/ 2 levels \"C\",\"S\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Jahreszeit: Factor w/ 4 levels \"F\",\"H\",\"S\",\"W\": 1 1 1 1 1 3 3 3 3 3 ...\n\nsummary(kormoran)\n\n\n     ï..Obs        Tauchzeit     Unterart Jahreszeit\n Min.   : 1.00   Min.   : 9.50   C:20     F:10      \n 1st Qu.:10.75   1st Qu.:13.38   S:20     H:10      \n Median :20.50   Median :16.75            S:10      \n Mean   :20.50   Mean   :17.40            W:10      \n 3rd Qu.:30.25   3rd Qu.:20.77                      \n Max.   :40.00   Max.   :30.40                      \n\nMan erkennt, dass es sich um einen Dataframe mit einer metrischen (Tauchzeit) und zwei kategorialen (Unterart, Jahreszeit) Variablen handelt. Die adäquate Analyse (1 metrische Abhängige vs. 2 kategoriale Unabhängige) ist damit eine zweifaktorielle ANOVA Die Sortierung der Jahreszeiten (default: alphabetisch) ist inhaltlich aber nicht sinnvoll und sollte angepasst werden.\n\n\n# Umsortieren der Faktoren, damit sie in den Boxplots eine sinnvolle Reihung haben\nkormoran$Jahreszeit <- ordered(kormoran$Jahreszeit, levels = c(\"F\", \"S\", \"H\", \"W\"))\nkormoran$Jahreszeit\n\n\n [1] F F F F F S S S S S H H H H H W W W W W F F F F F S S S S S H H H\n[34] H H W W W W W\nLevels: F < S < H < W\n\n# Explorative Datenanalyse (zeigt uns die Gesamtverteilung)\nboxplot(kormoran$Tauchzeit)\n\n\n\n\nDas ist noch OK für parametrische Verfahren (Box ziemlich symmetrisch um Median, Whisker etwas asymmetrisch aber nicht kritisch). Wegen der leichten Asymmetrie (Linksschiefe) könnte man eine log-Transformation ausprobieren.\n\n\nboxplot(log10(kormoran$Tauchzeit))\n\n\n\n\nDer Gesamtboxplot für log10 sieht perfekt symmetrisch aus, das spräche also für eine log10-Transformation. De facto kommt es aber nicht auf den Gesamtboxplot an, sondern auf die einzelnen.\n\n\n# Explorative Datenanalyse \n# (Check auf Normalverteilung der Residuen und Varianzhomogenitaet)\nboxplot(Tauchzeit~Jahreszeit * Unterart, data = kormoran)\n\n\n\nboxplot(log10(Tauchzeit)~Jahreszeit * Unterart, data = kormoran)\n\n\n\n\nHier sieht mal die Verteilung für die untransformierten Daten, mal für die transformierten besser aus. Da die Transformation keine klare Verbesserung bringt, bleiben wir im Folgenden bei den untransformierten Daten, da diese leichter (direkter) interpretiert werden können\n\n\n# Vollständiges Modell mit Interaktion\naov.1 <- aov(Tauchzeit~Unterart * Jahreszeit, data = kormoran)\naov.1\n\n\nCall:\n   aov(formula = Tauchzeit ~ Unterart * Jahreszeit, data = kormoran)\n\nTerms:\n                Unterart Jahreszeit Unterart:Jahreszeit Residuals\nSum of Squares   106.929    756.170              11.009    84.992\nDeg. of Freedom        1          3                   3        32\n\nResidual standard error: 1.629724\nEstimated effects may be unbalanced\n\nsummary(aov.1)\n\n\n                    Df Sum Sq Mean Sq F value   Pr(>F)    \nUnterart             1  106.9  106.93  40.259 4.01e-07 ***\nJahreszeit           3  756.2  252.06  94.901 5.19e-16 ***\nUnterart:Jahreszeit  3   11.0    3.67   1.382    0.266    \nResiduals           32   85.0    2.66                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# p-Wert der Interaktion ist 0.266\n\n\n\nDas volle (maximale) Modell zeigt, dass es keine signifikante Interaktion zwischen Jahreszeit und Unterart gibt. Wir können das Modell also vereinfachen, indem wir die Interaktion herausnehmen (+ statt * in der Modellspezifikation)\n\n\n# Modellvereinfachung\naov.2 <- aov(Tauchzeit~Unterart + Jahreszeit, data = kormoran)\naov.2\n\n\nCall:\n   aov(formula = Tauchzeit ~ Unterart + Jahreszeit, data = kormoran)\n\nTerms:\n                Unterart Jahreszeit Residuals\nSum of Squares   106.929    756.170    96.001\nDeg. of Freedom        1          3        35\n\nResidual standard error: 1.656166\nEstimated effects may be unbalanced\n\nsummary(aov.2)\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nUnterart     1  106.9  106.93   38.98 3.69e-07 ***\nJahreszeit   3  756.2  252.06   91.89  < 2e-16 ***\nResiduals   35   96.0    2.74                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nIm so vereinfachten Modell sind alle verbleibenden Terme signifikant, wir sind also beim „minimal adäquaten Modell“ angelangt\n\n\n# Anderer Weg, um zu pruefen, ob man das komplexere Modell mit Interaktion behalten soll\nanova(aov.1, aov.2)\n\n\nAnalysis of Variance Table\n\nModel 1: Tauchzeit ~ Unterart * Jahreszeit\nModel 2: Tauchzeit ~ Unterart + Jahreszeit\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1     32 84.992                           \n2     35 96.001 -3   -11.009 1.3817 0.2661\n\n# In diesem Fall bekommen wir den gleichen p-Wert wie oben (0.266)\n\n# Modelldiagnostik\npar(mfrow = c(2, 2)) #alle vier Abbildungen in einem 2 x 2 Raster\nplot(aov.2)\n\n\n\n\n\n\ninfluence.measures(aov.2) # \n# kann man sich zusätzlich zum \"plot\" ansehen, um herauszufinden, \n# ob es evtl. sehr einflussreiche Werte mit Cook's D von 1 oder grösser gibt\n\n\n\nLinks oben ist alles bestens, d. h. keine Hinweise auf Varianzheterogenität („Keil“) oder Nichtlinearität („Banane“) Rechts oben ganz gut, allerdings weichen Punkte 1 und 20 deutlich von der optimalen Gerade ab -> aus diesem Grund können wir es doch noch mal mit der log10-Transformation versuchen (s.u.) Rechts unten: kein Punkt hat einen problematischen Einfluss (die roten Linien für Cook’s D > 0.5 und > 1 sind noch nicht einmal im Bildausschnitt.\n\n\n# Alternative mit log10\naov.3 <-aov(log10(Tauchzeit)~Unterart + Jahreszeit, data=kormoran)\naov.3\n\n\nCall:\n   aov(formula = log10(Tauchzeit) ~ Unterart + Jahreszeit, data = kormoran)\n\nTerms:\n                 Unterart Jahreszeit Residuals\nSum of Squares  0.0627004  0.4958434 0.0562031\nDeg. of Freedom         1          3        35\n\nResidual standard error: 0.04007247\nEstimated effects may be unbalanced\n\nsummary(aov.3)\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \nUnterart     1 0.0627 0.06270   39.05 3.64e-07 ***\nJahreszeit   3 0.4958 0.16528  102.93  < 2e-16 ***\nResiduals   35 0.0562 0.00161                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(aov.3)\n\n\n\n\nRechts oben: Punkt 20 jetzt auf der Linie, aber Punkt 1 weicht umso deutlicher ab -> keine Verbesserung -> wir bleiben bei den untransformierten Daten.\n\n\n# Ergebnisdarstellung\n\n\n\nDa wir keine Interaktion zwischen Unterart und Jahreszeit festgestellt haben, brauchen wir auch keinen Interaktionsplot (unnötig kompliziert), statt dessen können wir die Ergebnisse am besten mit zwei getrennten Plots für die beiden Faktoren darstellen. Bitte die Achsenbeschriftungen und den Tukey post-hoc-Test nicht vergessen.\n\n\npar(mfrow = c(1, 1)) #Zurückschalten auf Einzelplots\nif(!require(multcomp)){install.packages(\"multcomp\")} \nlibrary(multcomp)\n\nboxplot(Tauchzeit~Unterart, data = kormoran)\n\n\n\nletters <- cld(glht(aov.2, linfct = mcp(Jahreszeit = \"Tukey\")))\nboxplot(Tauchzeit~Jahreszeit, data = kormoran)\nmtext(letters$mcletters$Letters, at = 1:4)\n\n\n\n\nJetzt brauchen wir noch die Mittelwerte bzw. Effektgroessen\nFür den Ergebnistext brauchen wir auch noch Angaben zu den Effektgrössen. Hier sind zwei Möglichkeiten, um an sie zu gelangen.\n\n\naggregate(Tauchzeit~Jahreszeit, FUN = mean, data = kormoran)\n\n\n  Jahreszeit Tauchzeit\n1          F     11.86\n2          S     15.09\n3          H     19.23\n4          W     23.42\n\naggregate(Tauchzeit~Unterart, FUN = mean, data = kormoran)\n\n\n  Unterart Tauchzeit\n1        C    19.035\n2        S    15.765\n\nsummary(lm(Tauchzeit~Jahreszeit, data = kormoran))\n\n\n\nCall:\nlm(formula = Tauchzeit ~ Jahreszeit, data = kormoran)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-3.820 -1.617 -0.145  1.587  6.980 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   17.4000     0.3754  46.351  < 2e-16 ***\nJahreszeit.L   8.6804     0.7508  11.562 1.12e-13 ***\nJahreszeit.Q   0.4800     0.7508   0.639    0.527    \nJahreszeit.C  -0.1923     0.7508  -0.256    0.799    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.374 on 36 degrees of freedom\nMultiple R-squared:  0.7884,    Adjusted R-squared:  0.7708 \nF-statistic: 44.72 on 3 and 36 DF,  p-value: 3.156e-12\n\nsummary(lm(Tauchzeit~Unterart, data = kormoran))\n\n\n\nCall:\nlm(formula = Tauchzeit ~ Unterart, data = kormoran)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.535 -3.585 -0.335  3.760 11.365 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   19.035      1.059  17.976   <2e-16 ***\nUnterartS     -3.270      1.498  -2.184   0.0352 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.736 on 38 degrees of freedom\nMultiple R-squared:  0.1115,    Adjusted R-squared:  0.08811 \nF-statistic: 4.768 on 1 and 38 DF,  p-value: 0.03523\n\n\n\n\n",
    "preview": "statistik/Statistik2_06_solution_2.3n/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik3_01_Demo/",
    "title": "Demo Statistik 3",
    "description": {},
    "author": [],
    "date": "2021-11-09",
    "categories": [
      "Statistik3"
    ],
    "contents": "\n\nContents\nANCOVA\n\nMultiple lineare Regression\nSimulation Overfitting\nMultiple lineare Regression basierend auf Logan, Beispiel 9A\nKorrelation zwischen den Prädiktoren\nModellvereinfachung\nHierarchical partitioning\nPartial regressions\n\nMultimodel inference\n\n\n\n\nDemoscript als Download\nDatensatz ipomopsis.csv\nDatensatz loyn.csv\nANCOVA\nExperiment zur Fruchtproduktion (“Fruit”) von Ipomopsis sp. (“Fruit”) in Abhängigkeit Ungrazedvon der Beweidung (Grazing mit 2 Levels: Grazed, Ungrazed) und korrigiert für die Pflanzengrösse vor der Beweidung (hier ausgedrückt als Durchmesser an der Spitze des Wurzelstock: “Root”)\n\n\ncompensation <- read.delim(\"ipomopsis.csv\", sep = \",\", stringsAsFactors = T)\n\n\n\n\n\nsummary(compensation)\n\n\n      Root            Fruit            Grazing  \n Min.   : 4.426   Min.   : 14.73   Grazed  :20  \n 1st Qu.: 6.083   1st Qu.: 41.15   Ungrazed:20  \n Median : 7.123   Median : 60.88                \n Mean   : 7.181   Mean   : 59.41                \n 3rd Qu.: 8.510   3rd Qu.: 76.19                \n Max.   :10.253   Max.   :116.05                \n\nplot(Fruit~Root, data = compensation)\n\n\n\nboxplot(Fruit~Grazing, data = compensation)\n\ntapply(compensation$Fruit, compensation$Grazing, mean)\n\n\n  Grazed Ungrazed \n 67.9405  50.8805 \n\naoc.1 <- lm(Fruit~Root * Grazing, data = compensation)\nsummary.aov(aoc.1)\n\n\n             Df Sum Sq Mean Sq F value   Pr(>F)    \nRoot          1  16795   16795 359.968  < 2e-16 ***\nGrazing       1   5264    5264 112.832 1.21e-12 ***\nRoot:Grazing  1      5       5   0.103     0.75    \nResiduals    36   1680      47                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\naoc.2 <- lm(Fruit~Grazing * Root, data = compensation)\nsummary.aov(aoc.2)\n\n\n             Df Sum Sq Mean Sq F value   Pr(>F)    \nGrazing       1   2910    2910  62.380 2.26e-09 ***\nRoot          1  19149   19149 410.420  < 2e-16 ***\nGrazing:Root  1      5       5   0.103     0.75    \nResiduals    36   1680      47                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\naoc.3 <- lm(Fruit~Grazing + Root, data = compensation)\nsummary.lm(aoc.3)\n\n\n\nCall:\nlm(formula = Fruit ~ Grazing + Root, data = compensation)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-17.1920  -2.8224   0.3223   3.9144  17.3290 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     -127.829      9.664  -13.23 1.35e-15 ***\nGrazingUngrazed   36.103      3.357   10.75 6.11e-13 ***\nRoot              23.560      1.149   20.51  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.747 on 37 degrees of freedom\nMultiple R-squared:  0.9291,    Adjusted R-squared:  0.9252 \nF-statistic: 242.3 on 2 and 37 DF,  p-value: < 2.2e-16\n\n# Plotten der Ergebnisse\nlibrary(tidyverse)\n\n\n\nggplot(compensation, aes(Root, Fruit, color = Grazing)) +\n  geom_point() + theme_classic()\n\n\n\n# Ploten mit base R\nplot(Fruit~Root, pch = 16, col = Grazing, data = compensation)\nlegend(\"topleft\", c(\"grazed\", \"ungrazed\"), col = c(\"black\",\"red\"), pch = 16) \n\n\n\n\n\n\n\ne <- c(20, 19, 25, 10, 8, 15, 13, 18, 11, 14, 25, 39, 38, 28, 24)\nf <- c(12, 15, 10, 7, 2, 10, 12, 11, 13, 10, 9, 2, 4, 7, 13)\n\nlm.1 <- lm(f~e)\nlm.quad <- lm(f~e + I(e^2))\n\nsummary(lm.1)\n\n\n\nCall:\nlm(formula = f ~ e)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.0549 -1.7015  0.5654  2.0617  5.6406 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  12.2879     2.4472   5.021 0.000234 ***\ne            -0.1541     0.1092  -1.412 0.181538    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.863 on 13 degrees of freedom\nMultiple R-squared:  0.1329,    Adjusted R-squared:  0.06622 \nF-statistic: 1.993 on 1 and 13 DF,  p-value: 0.1815\n\nsummary(lm.quad)\n\n\n\nCall:\nlm(formula = f ~ e + I(e^2))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.3866 -1.1018 -0.2027  1.3831  4.4211 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)   \n(Intercept) -2.239308   3.811746  -0.587  0.56777   \ne            1.330933   0.360105   3.696  0.00306 **\nI(e^2)      -0.031587   0.007504  -4.209  0.00121 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.555 on 12 degrees of freedom\nMultiple R-squared:  0.6499,    Adjusted R-squared:  0.5915 \nF-statistic: 11.14 on 2 and 12 DF,  p-value: 0.001842\n\npar(mfrow = c(1, 1))\n\n# 1. lineares Modell\nplot(f~e, xlim = c(0, 40), ylim = c(0, 20))\nabline(lm(f~e), col = \"blue\")\n\n\n\n# 2. quadratisches Modell\nxv <- seq(0, 40, 0.1)\nplot(f~e, xlim = c(0, 40), ylim = c(0, 20))\nyv2 <- predict(lm.quad, list(e = xv))\nlines(xv, yv2, col = \"red\")\n\n\n\n# Residualplots\npar(mfrow = c(2, 2))\nplot(lm.1)\n\n\n\nplot(lm.quad)\n\n\n\n\nMultiple lineare Regression\nSimulation Overfitting\n\n\ntest <- data.frame(\"x\" = c(1, 2, 3, 4, 5, 6), \"y\" = c(34, 21, 70, 47, 23, 45))\n\npar(mfrow=c(1,1))\nplot(y~x, data = test)\n\nlm.0 <- lm(y~1, data = test)\nlm.1 <- lm(y~x, data = test)\nlm.2 <- lm(y~x+ I(x^2), data = test)\nlm.3 <- lm(y~x+ I(x^2) + I(x^3), data = test)\nlm.4 <- lm(y~x+ I(x^2) + I(x^3) + I(x^4), data = test)\nlm.5 <- lm(y~x+ I(x^2) + I(x^3) + I(x^4) + I(x^5), data = test)\nlm.6 <- lm(y~x+ I(x^2) + I(x^3) + I(x^4) + I(x^5) + I(x^6), data = test)\nsummary(lm.0)\nsummary(lm.1)\nsummary(lm.2)\nsummary(lm.3)\nsummary(lm.4)\nsummary(lm.5)\n\nxv <- seq(from = 0, to = 10, by = 0.1)\n\nplot(y~x, cex = 2, col = \"black\", lwd = 3, data = test)\nyv <- predict(lm.1, list(x = xv))\nlines(xv, yv, col = \"red\", lwd = 3)\nyv <- predict(lm.2, list(x = xv))\nlines(xv, yv, col = \"blue\", lwd = 3)\nyv<-predict(lm.3, list(x = xv))\nlines(xv, yv, col = \"green\", lwd =3)\nyv <- predict(lm.4, list(x = xv))\nlines(xv, yv, col = \"orange\", lwd = 3)\nyv <- predict(lm.5, list(x = xv))\nlines(xv, yv, col = \"black\", lwd = 3)\n\n\n\nMultiple lineare Regression basierend auf Logan, Beispiel 9A\n\n\nloyn <- read.delim(\"loyn.csv\", sep = \",\")\nsummary(loyn)\n\n\n     ABUND            AREA            YR.ISOL          DIST       \n Min.   : 1.50   Min.   :   0.10   Min.   :1890   Min.   :  26.0  \n 1st Qu.:12.40   1st Qu.:   2.00   1st Qu.:1928   1st Qu.:  93.0  \n Median :21.05   Median :   7.50   Median :1962   Median : 234.0  \n Mean   :19.51   Mean   :  69.27   Mean   :1950   Mean   : 240.4  \n 3rd Qu.:28.30   3rd Qu.:  29.75   3rd Qu.:1966   3rd Qu.: 333.2  \n Max.   :39.60   Max.   :1771.00   Max.   :1976   Max.   :1427.0  \n     LDIST            GRAZE            ALT       \n Min.   :  26.0   Min.   :1.000   Min.   : 60.0  \n 1st Qu.: 158.2   1st Qu.:2.000   1st Qu.:120.0  \n Median : 338.5   Median :3.000   Median :140.0  \n Mean   : 733.3   Mean   :2.982   Mean   :146.2  \n 3rd Qu.: 913.8   3rd Qu.:4.000   3rd Qu.:182.5  \n Max.   :4426.0   Max.   :5.000   Max.   :260.0  \n\nKorrelation zwischen den Prädiktoren\n\n\ncor <- cor(loyn[, 2:7])\nprint(cor, digits = 2)\n\n\n           AREA YR.ISOL  DIST  LDIST  GRAZE   ALT\nAREA     1.0000 -0.0015  0.11  0.035 -0.310  0.39\nYR.ISOL -0.0015  1.0000  0.11 -0.083 -0.636  0.23\nDIST     0.1083  0.1132  1.00  0.317 -0.256 -0.11\nLDIST    0.0346 -0.0833  0.32  1.000 -0.028 -0.31\nGRAZE   -0.3104 -0.6356 -0.26 -0.028  1.000 -0.41\nALT      0.3878  0.2327 -0.11 -0.306 -0.407  1.00\n\ncor[abs(cor)<0.6] <- 0\ncor\n\n\n        AREA    YR.ISOL DIST LDIST      GRAZE ALT\nAREA       1  0.0000000    0     0  0.0000000   0\nYR.ISOL    0  1.0000000    0     0 -0.6355671   0\nDIST       0  0.0000000    1     0  0.0000000   0\nLDIST      0  0.0000000    0     1  0.0000000   0\nGRAZE      0 -0.6355671    0     0  1.0000000   0\nALT        0  0.0000000    0     0  0.0000000   1\n\nprint(cor, digits = 3)\n\n\n        AREA YR.ISOL DIST LDIST  GRAZE ALT\nAREA       1   0.000    0     0  0.000   0\nYR.ISOL    0   1.000    0     0 -0.636   0\nDIST       0   0.000    1     0  0.000   0\nLDIST      0   0.000    0     1  0.000   0\nGRAZE      0  -0.636    0     0  1.000   0\nALT        0   0.000    0     0  0.000   1\n\nlm.1 <- lm (ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn)\nif(!require(car)){install.packages(\"car\")} \nlibrary(car)\nvif(lm.1)\n\n\n YR.ISOL      ALT    GRAZE \n1.679995 1.200372 1.904799 \n\ninfluence.measures(lm.1)\n\n\nInfluence measures of\n     lm(formula = ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn) :\n\n      dfb.1_  dfb.YR.I   dfb.ALT  dfb.GRAZ     dffit cov.r   cook.d\n1   0.128900 -0.136701 -2.25e-02  8.68e-02 -0.455383 0.663 4.64e-02\n2  -0.046388  0.041396  1.50e-01 -2.15e-02 -0.222873 1.159 1.26e-02\n3  -0.178685  0.184085 -5.40e-02 -4.08e-02 -0.298379 1.108 2.23e-02\n4   0.054207 -0.053864 -2.43e-02 -4.06e-02 -0.085906 1.099 1.87e-03\n5   0.032249 -0.035235  3.34e-02  6.56e-02  0.138294 1.123 4.85e-03\n6   0.072550 -0.075381  3.68e-02 -3.40e-02 -0.129304 1.072 4.22e-03\n7   0.153153 -0.155477  8.56e-02 -1.78e-01 -0.263831 1.139 1.75e-02\n8  -0.044533  0.039741  1.44e-01 -2.07e-02 -0.213965 1.162 1.16e-02\n9   0.305330 -0.305810  1.16e-02 -2.93e-01 -0.412610 0.935 4.12e-02\n10 -0.134119  0.136978 -1.50e-02 -2.15e-02 -0.217402 1.140 1.19e-02\n11  0.145761 -0.154644  2.14e-01 -2.21e-02  0.300565 1.103 2.26e-02\n12 -0.246939  0.255702 -1.22e-01 -2.33e-02 -0.369735 1.161 3.42e-02\n13  0.071832 -0.068266 -1.34e-01 -3.53e-02 -0.191283 1.110 9.23e-03\n14  0.019281 -0.016626 -3.08e-01  1.90e-01 -0.597735 0.810 8.32e-02\n15  0.000311 -0.000315 -2.26e-05  2.96e-05  0.000496 1.184 6.27e-08\n16 -0.131537  0.136111 -5.26e-02 -3.46e-02 -0.223973 1.146 1.27e-02\n17 -0.098856  0.108184 -1.60e-01  1.44e-02  0.266285 0.984 1.75e-02\n18  0.238014 -0.243468  3.85e-02 -1.36e-01 -0.397451 0.753 3.65e-02\n19 -0.031350  0.029292  5.78e-02  3.66e-02  0.081711 1.121 1.70e-03\n20 -0.024122  0.019709  7.59e-02  5.75e-02 -0.093805 1.170 2.24e-03\n21  0.036050 -0.033748 -7.79e-02 -2.15e-02 -0.102357 1.162 2.66e-03\n22 -0.015768  0.016959  4.26e-03 -6.28e-02 -0.127636 1.116 4.13e-03\n23  0.050368 -0.052333  2.55e-02 -2.36e-02 -0.089769 1.095 2.04e-03\n24 -0.012264  0.008841  5.20e-02  5.07e-02 -0.071851 1.209 1.31e-03\n25  0.145637 -0.146703  2.41e-02 -7.94e-02  0.157322 1.319 6.30e-03\n26 -0.007372  0.007451  1.67e-03  5.11e-03  0.015793 1.106 6.36e-05\n27  0.043873 -0.045585  2.22e-02 -2.05e-02 -0.078194 1.100 1.55e-03\n28 -0.018037  0.016743  2.82e-02  2.63e-02  0.036688 1.224 3.43e-04\n29 -0.131935  0.133012 -2.20e-02  1.11e-01  0.164334 1.152 6.84e-03\n30  0.094249 -0.092478 -8.47e-02  1.81e-02  0.210983 1.127 1.12e-02\n31  0.118899 -0.130120  1.93e-01 -1.73e-02 -0.320276 0.928 2.49e-02\n32 -0.103130  0.098781  9.40e-02  1.33e-01  0.170699 1.126 7.37e-03\n33 -0.284839  0.290760 -1.33e-01  2.50e-01  0.433995 0.919 4.54e-02\n34 -0.213008  0.199453  2.95e-01  3.01e-01  0.408017 1.071 4.12e-02\n35  0.068874 -0.066760 -1.35e-01 -3.57e-03 -0.246916 1.008 1.51e-02\n36 -0.151383  0.159324 -1.23e-01  5.71e-02  0.283014 0.959 1.96e-02\n37  0.022901 -0.022520 -3.21e-02  3.25e-02  0.103312 1.136 2.71e-03\n38 -0.001488  0.001427  3.83e-03 -1.89e-04  0.006929 1.125 1.22e-05\n39 -0.299662  0.296262  7.86e-02  2.86e-01  0.365529 1.060 3.31e-02\n40  0.045779 -0.044212 -7.15e-02  3.70e-02  0.168859 1.126 7.21e-03\n41 -0.043463  0.037744  6.26e-02  1.22e-01 -0.153196 1.126 5.94e-03\n42 -0.067499  0.070133 -3.42e-02  3.16e-02  0.120302 1.078 3.66e-03\n43  0.002552 -0.002850 -1.05e-02  1.52e-02 -0.036428 1.143 3.38e-04\n44  0.011473 -0.009053 -3.51e-02 -3.92e-02  0.052676 1.192 7.07e-04\n45  0.002848  0.003165 -8.61e-02 -6.95e-02  0.137899 1.092 4.81e-03\n46 -0.116776  0.109111  2.15e-01  1.36e-01  0.304366 0.977 2.28e-02\n47  0.445830 -0.431209 -2.69e-01 -3.41e-01  0.629701 0.642 8.76e-02\n48 -0.000133  0.004718  4.46e-02 -1.58e-01  0.302736 1.002 2.26e-02\n49  0.008724 -0.006876 -2.00e-02 -3.60e-02  0.048292 1.150 5.94e-04\n50  0.019369 -0.017688 -5.80e-03 -5.14e-02  0.069197 1.136 1.22e-03\n51 -0.122055  0.122805  7.02e-02  2.13e-02  0.231107 1.022 1.33e-02\n52  0.020580 -0.015671 -8.25e-02 -6.78e-02  0.099679 1.298 2.53e-03\n53  0.014674 -0.013095 -8.87e-03 -4.28e-02  0.057249 1.139 8.35e-04\n54  0.138452 -0.137403  3.82e-02 -1.54e-01  0.204365 1.168 1.06e-02\n55 -0.000650  0.000535 -4.05e-03  6.97e-03 -0.014242 1.144 5.17e-05\n56  0.021139 -0.021938  2.56e-02 -1.62e-02  0.039541 1.363 3.98e-04\n      hat inf\n1  0.0286   *\n2  0.0996    \n3  0.0901    \n4  0.0331    \n5  0.0597    \n6  0.0315    \n7  0.0978    \n8  0.0996    \n9  0.0593    \n10 0.0876    \n11 0.0883    \n12 0.1318    \n13 0.0653    \n14 0.0692    \n15 0.0874    \n16 0.0923    \n17 0.0393    \n18 0.0293   *\n19 0.0460    \n20 0.0829    \n21 0.0786    \n22 0.0531    \n23 0.0315    \n24 0.1091    \n25 0.1876   *\n26 0.0232    \n27 0.0315    \n28 0.1175    \n29 0.0836    \n30 0.0790    \n31 0.0393    \n32 0.0690    \n33 0.0602    \n34 0.1008    \n35 0.0407    \n36 0.0376    \n37 0.0605    \n38 0.0393    \n39 0.0860    \n40 0.0685    \n41 0.0653    \n42 0.0315    \n43 0.0558    \n44 0.0953    \n45 0.0427    \n46 0.0460    \n47 0.0483   *\n48 0.0520    \n49 0.0626    \n50 0.0548    \n51 0.0408    \n52 0.1704   *\n53 0.0549    \n54 0.1011    \n55 0.0555    \n56 0.2077   *\n\nModellvereinfachung\n\n\nlm.1 <- lm(ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn)\nsummary(lm.1)\n\n\n\nCall:\nlm(formula = ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-19.5498  -4.8951   0.6504   4.7798  20.2384 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -73.58185  107.24995  -0.686 0.495712    \nYR.ISOL       0.05143    0.05393   0.954 0.344719    \nALT           0.03285    0.02679   1.226 0.225618    \nGRAZE        -4.01692    0.99881  -4.022 0.000188 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.894 on 52 degrees of freedom\nMultiple R-squared:  0.4887,    Adjusted R-squared:  0.4592 \nF-statistic: 16.57 on 3 and 52 DF,  p-value: 1.106e-07\n\nlm.2 <- update(lm.1,~.-YR.ISOL)\nanova(lm.1, lm.2)\n\n\nAnalysis of Variance Table\n\nModel 1: ABUND ~ YR.ISOL + ALT + GRAZE\nModel 2: ABUND ~ ALT + GRAZE\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1     52 3240.4                           \n2     53 3297.1 -1   -56.662 0.9093 0.3447\n\nsummary(lm.2)\n\n\n\nCall:\nlm(formula = ABUND ~ ALT + GRAZE, data = loyn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-19.1677  -4.8261   0.0266   4.6944  19.1054 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 28.55582    5.43245   5.257 2.67e-06 ***\nALT          0.03191    0.02675   1.193    0.238    \nGRAZE       -4.59679    0.79167  -5.806 3.67e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.887 on 53 degrees of freedom\nMultiple R-squared:  0.4798,    Adjusted R-squared:  0.4602 \nF-statistic: 24.44 on 2 and 53 DF,  p-value: 3.011e-08\n\nlm.3 <- update(lm.2,~.-ALT)\nanova(lm.2, lm.3)\n\n\nAnalysis of Variance Table\n\nModel 1: ABUND ~ ALT + GRAZE\nModel 2: ABUND ~ GRAZE\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1     53 3297.1                           \n2     54 3385.6 -1   -88.519 1.4229 0.2382\n\nsummary(lm.3)\n\n\n\nCall:\nlm(formula = ABUND ~ GRAZE, data = loyn)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-19.1066  -5.4097   0.0934   4.4856  18.2747 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  34.3692     2.4095  14.264  < 2e-16 ***\nGRAZE        -4.9813     0.7259  -6.862  6.9e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.918 on 54 degrees of freedom\nMultiple R-squared:  0.4658,    Adjusted R-squared:  0.4559 \nF-statistic: 47.09 on 1 and 54 DF,  p-value: 6.897e-09\n\npar(mfrow = c(2, 2))\nplot(lm.1)\n\n\n\n\nHierarchical partitioning\n\n\nif(!require(hier.part)){install.packages(\"hier.part\")}\nlibrary(hier.part)\n\nloyn.preds <-with(loyn, data.frame(YR.ISOL, ALT, GRAZE))\nhier.part(loyn$ABUND, loyn.preds, gof = \"Rsqu\")\n\n\n\n$gfs\n[1] 0.0000000 0.2533690 0.1488696 0.4658218 0.3297010 0.4739432\n[7] 0.4797883 0.4887284\n\n$IJ\n                 I          J     Total\nYR.ISOL 0.11892853 0.13444049 0.2533690\nALT     0.06960132 0.07926823 0.1488696\nGRAZE   0.30019854 0.16562324 0.4658218\n\n$I.perc\n        ind.exp.var\nYR.ISOL    24.33428\nALT        14.24131\nGRAZE      61.42441\n\n$params\n$params$full.model\n[1] \"y ~ YR.ISOL + ALT + GRAZE\"\n\n$params$family\n[1] \"gaussian\"\n\n$params$link\n[1] \"default\"\n\n$params$gof\n[1] \"Rsqu\"\n\nPartial regressions\n\n\navPlots(lm.1, ask = F)\n\n\n\n\nMultimodel inference\n\n\nif(!require(MuMIn)){install.packages(\"MuMIn\")}\nlibrary(MuMIn)\n\nglobal.model <- lm(ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn)\noptions(na.action = \"na.fail\")\n\nallmodels <- dredge(global.model)\nallmodels\n\n\nGlobal model call: lm(formula = ABUND ~ YR.ISOL + ALT + GRAZE, data = loyn)\n---\nModel selection table \n     (Int)     ALT    GRA  YR.ISO df   logLik  AICc delta weight\n3   34.370         -4.981          3 -194.315 395.1  0.00  0.407\n4   28.560 0.03191 -4.597          4 -193.573 395.9  0.84  0.267\n7  -62.750         -4.440 0.04898  4 -193.886 396.6  1.46  0.196\n8  -73.580 0.03285 -4.017 0.05143  5 -193.087 397.4  2.28  0.130\n6 -348.500 0.07006        0.18350  4 -200.670 410.1 15.03  0.000\n5 -392.300                0.21120  3 -203.690 413.8 18.75  0.000\n2    5.598 0.09515                 3 -207.358 421.2 26.09  0.000\n1   19.510                         2 -211.871 428.0 32.88  0.000\nModels ranked by AICc(x) \n\nimportance(allmodels)\n\n\n                     GRAZE ALT  YR.ISOL\nSum of weights:      1.00  0.40 0.33   \nN containing models:    4     4    4   \n\navgmodel <- model.avg(allmodels, subset = TRUE)\nsummary(avgmodel)\n\n\n\nCall:\nmodel.avg(object = allmodels, subset = TRUE)\n\nComponent model call: \nlm(formula = ABUND ~ <8 unique rhs>, data = loyn)\n\nComponent models: \n       df  logLik   AICc delta weight\n2       3 -194.31 395.09  0.00   0.41\n12      4 -193.57 395.93  0.84   0.27\n23      4 -193.89 396.56  1.46   0.20\n123     5 -193.09 397.37  2.28   0.13\n13      4 -200.67 410.13 15.03   0.00\n3       3 -203.69 413.84 18.75   0.00\n1       3 -207.36 421.18 26.09   0.00\n(Null)  2 -211.87 427.97 32.88   0.00\n\nTerm codes: \n    ALT   GRAZE YR.ISOL \n      1       2       3 \n\nModel-averaged coefficients:  \n(full average) \n            Estimate Std. Error Adjusted SE z value Pr(>|z|)    \n(Intercept) -0.29874   77.23966    78.39113   0.004    0.997    \nGRAZE       -4.64605    0.89257     0.91048   5.103    3e-07 ***\nALT          0.01282    0.02311     0.02340   0.548    0.584    \nYR.ISOL      0.01631    0.03883     0.03941   0.414    0.679    \n \n(conditional average) \n            Estimate Std. Error Adjusted SE z value Pr(>|z|)    \n(Intercept) -0.29874   77.23966    78.39113   0.004    0.997    \nGRAZE       -4.64724    0.88957     0.90755   5.121    3e-07 ***\nALT          0.03224    0.02678     0.02741   1.176    0.240    \nYR.ISOL      0.05007    0.05421     0.05548   0.902    0.367    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n",
    "preview": "statistik/Statistik3_01_Demo/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik3_02_assigment/",
    "title": "Übung Statistik 3",
    "description": {},
    "author": [],
    "date": "2021-11-08",
    "categories": [
      "Statistik3"
    ],
    "contents": "\nDatensatz Ukraine_bearbeitet.xlsx Ukraine_bearbeitet.xlsx Datensatz Ukraine_bearbeitet.csv Ukraine_bearbeitet.csv\nAufgabe 3: Multiple Regression\nBereiten Sie den Datensatz Ukraine.xlsx für das Einlesen in R vor und lesen Sie ihn dann ein. Dieser enthält Pflanzenartenzahlen (Species.richness) von 199 10 m² grossen Plots (Vegetationsaufnahmen) von Steppenrasen in der Ukraine sowie zahlreiche Umweltvariablen, deren Bedeutung und Einheiten im Kopf der ExcelTabelle angegeben sind.\nErmitteln Sie ein minimal adäquates Modell, das den Artenreichtum in den Plots durch die Umweltvariablen erklärt.\nBitte erklären und begründen Sie die einzelnen Schritte, die Sie unternehmen, um zu diesem Ergebnis zu kommen. Dazu erstellen Sie bitte ein Word-Dokument, in das Sie Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, Ihre Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere Vorgehen dokumentieren.\nDieser Ablauf sollte insbesondere beinhalten:\nÜberprüfen der Datenstruktur nach dem Einlesen: welches sind die abhängige(n) und welches die unabängige(n) Variablen, sind alle Variablen für die Analyse geeignet?\nExplorative Datenanalyse, um zu sehen, ob die abhängige Variable in der vorliegenden Form für die Analyse geeignet ist\nDefinition eines globalen Modelles und dessen Reduktion zu einem minimal adäquaten Modell\nDurchführen der Modelldiagnostik für dieses\nGenerieren aller Zahlen, Statistiken und Tabellen, die für eine wiss. Ergebnisdarstellung benötigt werden\nFormulieren Sie abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (ausformulierte schriftliche Zusammenfassung, mit je einem Absatz von ca. 60-100 Worten, resp. 3-8 Sätzen für den Methoden- und Ergebnisteil). D. h. alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden.\nAbzugeben sind am Ende (a) Ein lauffähiges R-Skript; (b) begründeter Lösungsweg (Kombination aus R-Code, R Output und dessen Interpretation) und (c) ausformulierter Methoden- und Ergebnisteil (für eine wiss. Arbeit).\n\n",
    "preview": {},
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik3_03_Solution/",
    "title": "Loesung Aufgabe 3",
    "description": {},
    "author": [],
    "date": "2021-11-15",
    "categories": [
      "Statistik3"
    ],
    "contents": "\n\nContents\nLoesung Aufgabe 3.1\n\n\n\n\nDownload R-Skript\nLösungstext als Download\nLoesung Aufgabe 3.1\nSchon vor dem Einlesen kürzt man am besten bereits in Excel die Variablennamen so ab, dass sie noch eindeutig, aber nicht unnötig lang sind, etwa indem man die Einheiten wegstreicht\n\n\n# Aus der Excel-Tabelle wurde das relevante Arbeitsblatt als csv gespeichert\nukraine <- read.delim(\"Ukraine_bearbeitet.csv\", sep=\";\")\n\n\n\n\n\nukraine\n\n\n\n\n\nstr(ukraine)\n\n\n'data.frame':   199 obs. of  23 variables:\n $ PlotID           : chr  \"UA01NW\" \"UA01SE\" \"UA02NW\" \"UA02SE\" ...\n $ Species_richness : int  44 53 48 50 53 40 46 56 30 35 ...\n $ Altitude         : int  179 178 188 183 162 165 153 158 192 197 ...\n $ Inclination      : int  24 17 27 33 7 33 30 32 25 18 ...\n $ Heat_index       : num  -0.42 -0.3 -0.51 -0.65 -0.09 -0.42 0 -0.59 0.46 0.32 ...\n $ Microrelief      : num  5 2.5 2 2 3 4 16 15 5 3 ...\n $ Grazing_intensity: int  0 0 0 0 0 0 1 1 0 0 ...\n $ Litter           : int  12 10 0 4 15 30 5 6 10 20 ...\n $ Stones_and_rocks : num  0 0 0 0 0 0 40 10 0 0 ...\n $ Gravel           : num  0 0 0 0 0 0 0 0 0 0 ...\n $ Fine_soil        : num  2 5 0 7 0 0 2 5 5 2 ...\n $ Sand             : int  45 30 20 20 55 30 10 30 10 5 ...\n $ Silt             : int  40 35 60 60 10 35 60 35 60 90 ...\n $ Clay             : int  15 35 20 20 35 35 30 35 30 5 ...\n $ pH               : num  7.32 6.91 6.72 6.44 6.1 6.23 6.79 6.43 7.19 7 ...\n $ Conductivity     : int  90 115 126 90 73 76 163 119 151 69 ...\n $ CaCO3            : num  0.0754 0.1271 0.0723 0.0771 0.0829 ...\n $ N_total          : num  0.14 0.17 0.24 0.26 0.29 0.2 0.34 0.29 0.18 0.2 ...\n $ C_org            : num  1.54 1.97 2.99 3.22 3.77 2.5 4.59 3.67 2.16 2.38 ...\n $ CN_ratio         : num  10.8 11.5 12.5 12.6 12.8 ...\n $ Temperature      : int  79 79 80 80 82 82 82 82 79 83 ...\n $ Temperature_range: int  330 330 329 329 328 328 328 328 326 327 ...\n $ Precipitation    : int  608 608 603 603 594 594 594 594 600 586 ...\n\nsummary(ukraine)\n\n\n    PlotID          Species_richness    Altitude      Inclination   \n Length:199         Min.   :14.00    Min.   : 73.0   Min.   : 1.00  \n Class :character   1st Qu.:34.00    1st Qu.:140.0   1st Qu.:12.00  \n Mode  :character   Median :40.00    Median :166.0   Median :19.00  \n                    Mean   :40.23    Mean   :161.7   Mean   :19.28  \n                    3rd Qu.:47.50    3rd Qu.:188.0   3rd Qu.:25.00  \n                    Max.   :67.00    Max.   :251.0   Max.   :48.00  \n                                                                    \n   Heat_index        Microrelief      Grazing_intensity\n Min.   :-0.94000   Min.   :  0.000   Min.   :0.0000   \n 1st Qu.:-0.15500   1st Qu.:  2.500   1st Qu.:0.0000   \n Median : 0.01000   Median :  5.000   Median :1.0000   \n Mean   : 0.01603   Mean   :  7.126   Mean   :0.9296   \n 3rd Qu.: 0.21500   3rd Qu.:  7.000   3rd Qu.:2.0000   \n Max.   : 0.85000   Max.   :100.000   Max.   :3.0000   \n                                                       \n     Litter      Stones_and_rocks     Gravel         Fine_soil    \n Min.   : 0.00   Min.   : 0.000   Min.   : 0.000   Min.   : 0.00  \n 1st Qu.: 3.50   1st Qu.: 0.000   1st Qu.: 0.000   1st Qu.: 2.00  \n Median : 7.00   Median : 0.500   Median : 0.000   Median : 5.00  \n Mean   :12.16   Mean   : 3.994   Mean   : 2.984   Mean   : 7.02  \n 3rd Qu.:13.50   3rd Qu.: 4.000   3rd Qu.: 3.000   3rd Qu.:10.00  \n Max.   :90.00   Max.   :68.000   Max.   :40.000   Max.   :38.00  \n                                                                  \n      Sand            Silt            Clay             pH       \n Min.   : 5.00   Min.   : 5.00   Min.   : 5.00   Min.   :4.890  \n 1st Qu.:20.00   1st Qu.:20.00   1st Qu.:20.00   1st Qu.:7.240  \n Median :30.00   Median :35.00   Median :20.00   Median :7.420  \n Mean   :35.81   Mean   :40.43   Mean   :23.74   Mean   :7.286  \n 3rd Qu.:55.00   3rd Qu.:60.00   3rd Qu.:35.00   3rd Qu.:7.545  \n Max.   :80.00   Max.   :90.00   Max.   :55.00   Max.   :7.790  \n NA's   :1       NA's   :1       NA's   :1                      \n  Conductivity       CaCO3            N_total           C_org       \n Min.   : 40.0   Min.   : 0.0042   Min.   :0.0700   Min.   : 1.040  \n 1st Qu.:148.5   1st Qu.: 0.4306   1st Qu.:0.2000   1st Qu.: 2.850  \n Median :171.0   Median : 4.6578   Median :0.2700   Median : 3.560  \n Mean   :162.3   Mean   : 7.4757   Mean   :0.2788   Mean   : 3.689  \n 3rd Qu.:189.5   3rd Qu.:13.0002   3rd Qu.:0.3300   3rd Qu.: 4.400  \n Max.   :232.0   Max.   :35.2992   Max.   :0.9500   Max.   :11.300  \n                                                                    \n    CN_ratio      Temperature    Temperature_range Precipitation  \n Min.   : 6.04   Min.   :78.00   Min.   :326.0     Min.   :577.0  \n 1st Qu.:12.24   1st Qu.:82.00   1st Qu.:328.0     1st Qu.:583.0  \n Median :12.95   Median :84.00   Median :329.0     Median :592.0  \n Mean   :13.48   Mean   :84.82   Mean   :328.6     Mean   :596.4  \n 3rd Qu.:14.02   3rd Qu.:88.00   3rd Qu.:330.0     3rd Qu.:602.5  \n Max.   :27.42   Max.   :92.00   Max.   :331.0     Max.   :630.0  \n                                                                  \n\nMan erkennt, dass alle Spalten bis auf die erste mit der Plot ID numerisch (num oder int) und dass die abhängige Variable in Spalte 2 sowie die Prediktorvariablen in den Spalten 3 bis 23 stehen.\n\n\n#Explorative Datenanalyse der abhängigen Variablen\nboxplot(ukraine$Species_richness)\n\n\n\nDer Boxplot sieht sehr gut symmetrisch aus. Insofern gibt es keinen Anlass über eine Transformation nachzudenken. (Da es sich bei Artenzahlen um Zähldaten handelt, müsste man theoretisch ein glm mit Poisson-Verteilung rechnen; bei einem Mittelwert, der hinreichend von Null verschieden ist (hier: ca. 40), ist eine Poisson-Verteilung aber praktisch nicht von einer Normalverteilung zu unterscheiden und wir können uns den Aufwand auch sparen).\n\n\ncor <- cor(ukraine[,3:23])\ncor\ncor[abs(cor)<0.7] <- 0\ncor\n\n\n\nDie Korrelationsanalyse dient dazu, zu entscheiden, ob die Prädiktorvariablen hinreichend voneinander unabhängig sind, um alle in das globale Modell hinein zu nehmen. Bei Pearson’s Korrelationskoeffizienten r, die betragsmässig grösser als 0.7 sind, würde es problematisch. Alternativ hätten wir auch den VIF (Variance Inflation Factor) als Kriterium für den möglichen Ausschluss von Variablen aus dem globalen Modell nehmen können. Diese initiale Korrelationsanalyse zeigt uns aber, dass unsere Daten noch ein anderes Problem haben: für die drei Korngrössenfraktionen des Bodens (Sand, Silt, Clay) stehen lauter NA’s. Um herauszufinden, was das Problem ist, geben wir ein:\n\n\nsummary(ukraine$Sand)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   5.00   20.00   30.00   35.81   55.00   80.00       1 \n\nukraine[!complete.cases(ukraine), ] # Zeigt zeilen mit NAs ein\n\n\n   PlotID Species_richness Altitude Inclination Heat_index\n85 UAR061               23      159          48        0.1\n   Microrelief Grazing_intensity Litter Stones_and_rocks Gravel\n85         100                 0      1               68      0\n   Fine_soil Sand Silt Clay   pH Conductivity   CaCO3 N_total C_org\n85         1   NA   NA   NA 7.53          203 10.9638    0.95  11.3\n   CN_ratio Temperature Temperature_range Precipitation\n85    11.86          82               327           599\n\nDa gibt es offensichtlich je ein NA in jeder dieser Zeilen. Jetzt können wir entscheiden, entweder auf die drei Variablen oder auf die eine Beobachtung zu verzichten. Da wir eh schon eher mehr unabhängige Variablen haben als wir händeln können, entscheide ich pragmatisch für ersteres. Wir rechnen die Korrelation also noch einmal ohne diese drei Spalten (es sind die Nummern 12:14, wie wir aus der anfänglichen Variablenbetrachtung oben wissen).\n\n\ncor <- cor(ukraine[, c(3:11, 15:23)])\ncor[abs(cor)<0.7] <- 0\ncor\n\n\n\nWenn man auf cor nun doppel-clickt und es in einem separaten Fenster öffnet, sieht man, wo es problematische Korrelationen zwischen Variablenpaaren gibt. Es sind dies Altitude vs. Temperature und N.total vs. C.org. Wir müssen aus jedem dieser Paare jetzt eine Variable rauswerfen, am besten jene, die weniger gut interpretierbar ist. Ich entscheide mich dafür Temperature statt Altitude (weil das der direktere ökologische Wirkfaktor ist) und C.org statt N.total zu behalten (weil es in der Literatur mehr Daten zum Humusgehalt als zum N-Gehalt gibt, damit eine bessere Vergleichbarkeit erzielt wird). Die Aussagen, die wir für die beibehaltene Variable erzielen, stehen aber +/- auch für die entfernte. Das Problem ist aber, dass wir immer noch 16 Variablen haben, was einen sehr leistungsfähigen Rechner oder sehr lange Rechenzeit erfordern würde. Wir sollten also unter 15 Variablen kommen. Wir könnten uns jetzt überlegen, welche uns ökologisch am wichtigsten sind, oder ein noch strengeres Kriterium bei r verwenden, etwa 0.6\n\n\ncor <- cor(ukraine[,c(3:11, 15:23)])\ncor[abs(cor)<0.6] <- 0\ncor\n\n\n                    Altitude Inclination Heat_index Microrelief\nAltitude           1.0000000           0          0           0\nInclination        0.0000000           1          0           0\nHeat_index         0.0000000           0          1           0\nMicrorelief        0.0000000           0          0           1\nGrazing_intensity  0.0000000           0          0           0\nLitter             0.0000000           0          0           0\nStones_and_rocks   0.0000000           0          0           0\nGravel             0.0000000           0          0           0\nFine_soil          0.0000000           0          0           0\npH                 0.0000000           0          0           0\nConductivity       0.0000000           0          0           0\nCaCO3              0.0000000           0          0           0\nN_total            0.0000000           0          0           0\nC_org              0.0000000           0          0           0\nCN_ratio           0.0000000           0          0           0\nTemperature       -0.8309559           0          0           0\nTemperature_range -0.6794514           0          0           0\nPrecipitation      0.0000000           0          0           0\n                  Grazing_intensity Litter Stones_and_rocks Gravel\nAltitude                          0      0                0      0\nInclination                       0      0                0      0\nHeat_index                        0      0                0      0\nMicrorelief                       0      0                0      0\nGrazing_intensity                 1      0                0      0\nLitter                            0      1                0      0\nStones_and_rocks                  0      0                1      0\nGravel                            0      0                0      1\nFine_soil                         0      0                0      0\npH                                0      0                0      0\nConductivity                      0      0                0      0\nCaCO3                             0      0                0      0\nN_total                           0      0                0      0\nC_org                             0      0                0      0\nCN_ratio                          0      0                0      0\nTemperature                       0      0                0      0\nTemperature_range                 0      0                0      0\nPrecipitation                     0      0                0      0\n                  Fine_soil       pH Conductivity CaCO3   N_total\nAltitude                  0 0.000000     0.000000     0 0.0000000\nInclination               0 0.000000     0.000000     0 0.0000000\nHeat_index                0 0.000000     0.000000     0 0.0000000\nMicrorelief               0 0.000000     0.000000     0 0.0000000\nGrazing_intensity         0 0.000000     0.000000     0 0.0000000\nLitter                    0 0.000000     0.000000     0 0.0000000\nStones_and_rocks          0 0.000000     0.000000     0 0.0000000\nGravel                    0 0.000000     0.000000     0 0.0000000\nFine_soil                 1 0.000000     0.000000     0 0.0000000\npH                        0 1.000000     0.674678     0 0.0000000\nConductivity              0 0.674678     1.000000     0 0.0000000\nCaCO3                     0 0.000000     0.000000     1 0.0000000\nN_total                   0 0.000000     0.000000     0 1.0000000\nC_org                     0 0.000000     0.000000     0 0.9551133\nCN_ratio                  0 0.000000     0.000000     0 0.0000000\nTemperature               0 0.000000     0.000000     0 0.0000000\nTemperature_range         0 0.000000     0.000000     0 0.0000000\nPrecipitation             0 0.000000     0.000000     0 0.0000000\n                      C_org CN_ratio Temperature Temperature_range\nAltitude          0.0000000        0  -0.8309559        -0.6794514\nInclination       0.0000000        0   0.0000000         0.0000000\nHeat_index        0.0000000        0   0.0000000         0.0000000\nMicrorelief       0.0000000        0   0.0000000         0.0000000\nGrazing_intensity 0.0000000        0   0.0000000         0.0000000\nLitter            0.0000000        0   0.0000000         0.0000000\nStones_and_rocks  0.0000000        0   0.0000000         0.0000000\nGravel            0.0000000        0   0.0000000         0.0000000\nFine_soil         0.0000000        0   0.0000000         0.0000000\npH                0.0000000        0   0.0000000         0.0000000\nConductivity      0.0000000        0   0.0000000         0.0000000\nCaCO3             0.0000000        0   0.0000000         0.0000000\nN_total           0.9551133        0   0.0000000         0.0000000\nC_org             1.0000000        0   0.0000000         0.0000000\nCN_ratio          0.0000000        1   0.0000000         0.0000000\nTemperature       0.0000000        0   1.0000000         0.6900784\nTemperature_range 0.0000000        0   0.6900784         1.0000000\nPrecipitation     0.0000000        0  -0.6237053         0.0000000\n                  Precipitation\nAltitude              0.0000000\nInclination           0.0000000\nHeat_index            0.0000000\nMicrorelief           0.0000000\nGrazing_intensity     0.0000000\nLitter                0.0000000\nStones_and_rocks      0.0000000\nGravel                0.0000000\nFine_soil             0.0000000\npH                    0.0000000\nConductivity          0.0000000\nCaCO3                 0.0000000\nN_total               0.0000000\nC_org                 0.0000000\nCN_ratio              0.0000000\nTemperature          -0.6237053\nTemperature_range     0.0000000\nPrecipitation         1.0000000\n\nEntsprechend „werfen“ wir auch noch die folgenden Variablen „raus“: Temperature.range (positiv mit Temperature), Precipitation (negativ mit Temperature) sowie Conductivity (positiv mit pH).\nNun können wir das globale Modell definieren, indem wir alle verbleibenden Variablen aufnehmen, das sind 13. (Wenn das nicht eh schon so viele wären, dass es uns an die Grenze der Rechenleistung bringt, hätten wir auch noch darüber nachdenken können, einzelne quadratische Terme oder Interaktionsterme zu berücksichtigen).\n\n\nglobal.model <- lm(Species_richness ~ Inclination + Heat_index + Microrelief + Grazing_intensity +\n                    Litter + Stones_and_rocks + Gravel + Fine_soil + pH + CaCO3 + C_org + CN_ratio + Temperature, data = ukraine)\n\n\n\nNun gibt es im Prinzip zwei Möglichkeiten, vom globalen (vollen) Modell zu einem minimal adäquaten Modell zu kommen. (1) Der Ansatz der „frequentist statistic“, in dem man aus dem vollen Modell so lange schrittweise Variablen entfernt, bis nur noch signifikante Variablen verbleiben. (2) Den informationstheoretischen Ansatz, bei dem alle denkbaren Modelle berechnet und verglichen werden (also alle möglichen Kombinationen von 13,12,…, 1, 0 Parametern). Diese Lösung stelle ich im Folgenden vor:\n\n\n# Multimodel inference\nif(!require(MuMIn)){install.packages(\"MuMIn\")}\nlibrary(MuMIn)\n\noptions(na.action = \"na.fail\")\nallmodels <- dredge(global.model)\n\n\n\n\n\nallmodels\n\n\n\nJetzt bekommen wir die besten der insgesamt 8192 möglichen Modelle gelistet mit ihren Parameterschätzungen und ihrem AICc.\nDas beste Modell umfasst 5 Parameter (CaCO3, CN.ratio, Grazing.intensity. Heat.index, Litter). Allerdings ist das nächstbeste Modell (mit 6 Parametern) nur wenig schlechter (delta AICc = 0.71), was sich in fast gleichen (und zudem sehr niedrigen) Akaike weights bemerkbar macht. Nach dem Verständnis des Information theoretician approach, sollte man in einer solchen Situation nicht das eine „beste“ Modell benennen, sondern eine Aussage über die Gruppe der insgesamt brauchbaren Modelle treffen. Hierzu kann man (a) Importance der Parameter über alle Modelle hinweg berechnen (= Summe der Akaike weights aller Modelle, die den betreffenden Parameter enthalten) und/oder (b) ein nach Akaike weights gemitteltes Modell berechnen.\n\n\n# Importance values der Variablen\nimportance(allmodels)\n\n\n                     Heat_index Litter CaCO3 CN_ratio\nSum of weights:      1.00       0.92   0.82  0.73    \nN containing models: 4096       4096   4096  4096    \n                     Grazing_intensity Stones_and_rocks Temperature\nSum of weights:      0.68              0.43             0.39       \nN containing models: 4096              4096             4096       \n                     Microrelief Gravel Fine_soil C_org pH  \nSum of weights:      0.33        0.31   0.31      0.30  0.26\nN containing models: 4096        4096   4096      4096  4096\n                     Inclination\nSum of weights:      0.26       \nN containing models: 4096       \n\nDemnach ist Heat.index die wichtigste Variable (in 100% aller relevanten Modelle), während ferner Litter, CaCO3, CN_ratio und Grazing_intensity in mehr als 50% der relevanten Modelle enthalten sind.\n\n\n# Modelaveraging (Achtung: dauert mit 13 Variablen einige Minuten)\nsummary(model.avg(allmodels, rank = \"AICc\"), subset = TRUE)\n\n\n\nAus dem gemittelten Modell können wir die Richtung der Beziehung (positiv oder negativ) und ggf. die Effektgrössen (wie verändert sich die Artenzahl, wenn die Prädiktorvariable um eine Einheit zunimmt?) ermitteln.\n\n\n# Modelldiagnostik nicht vergessen\npar(mfrow = c(2, 2))\nplot(global.model)\n\n\n\nplot(lm(Species_richness ~ Heat_index + Litter + CaCO3 + CN_ratio + Grazing_intensity, data = ukraine))\n\n\n\nsummary(global.model)\n\n\n\nCall:\nlm(formula = Species_richness ~ Inclination + Heat_index + Microrelief + \n    Grazing_intensity + Litter + Stones_and_rocks + Gravel + \n    Fine_soil + pH + CaCO3 + C_org + CN_ratio + Temperature, \n    data = ukraine)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.1317  -5.8226   0.5007   5.9982  21.4941 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        29.35672   17.93590   1.637  0.10338    \nInclination         0.01179    0.08581   0.137  0.89084    \nHeat_index        -12.17483    2.41802  -5.035 1.13e-06 ***\nMicrorelief         0.07488    0.07312   1.024  0.30716    \nGrazing_intensity   1.23000    0.67730   1.816  0.07098 .  \nLitter             -0.12338    0.04309  -2.864  0.00467 ** \nStones_and_rocks   -0.14803    0.08840  -1.675  0.09570 .  \nGravel             -0.03114    0.12924  -0.241  0.80988    \nFine_soil          -0.08720    0.10181  -0.856  0.39286    \npH                 -0.21774    1.70826  -0.127  0.89871    \nCaCO3               0.22638    0.10597   2.136  0.03397 *  \nC_org               0.31994    0.55929   0.572  0.56798    \nCN_ratio           -0.75167    0.33393  -2.251  0.02556 *  \nTemperature         0.24527    0.21510   1.140  0.25566    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.149 on 185 degrees of freedom\nMultiple R-squared:  0.2349,    Adjusted R-squared:  0.1812 \nF-statistic:  4.37 on 13 and 185 DF,  p-value: 2.027e-06\n\nWie immer kommt am Ende die Modelldiagnostik. Wir können uns entweder das globale Modell oder das Modell mit den 5 Variablen mit importance > 50% anschauen. Das Bild sieht fast identisch aus und zeigt keinerlei problematische Abweichungen, d. h. links oben weder ein Keil, noch eine Banane, rechts oben eine nahezu perfekte Gerade.\n\n\n\n",
    "preview": "statistik/Statistik3_03_Solution/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik4_01_Demo/",
    "title": "Demo Statistik 4",
    "description": {},
    "author": [],
    "date": "2021-11-09",
    "categories": [
      "Statistik4"
    ],
    "contents": "\n\nContents\nvon LMs zu GLMs\nLogistische Regression\nNicht-lineare Regression\nSmoother\nGAMs\n\nDemoscript als Download\nDatensatz loyn.csv\nvon LMs zu GLMs\n\n\ntemp <- c(10, 12 ,16, 20, 24, 25, 30, 33, 37)\nbesucher <- c(40, 12, 50, 500, 400, 900, 1500, 900, 2000)\nstrand <- data.frame(\"Temperatur\" = temp, \"Besucher\" = besucher)\n\nplot(besucher~temp, data = strand)\n\n\n\nlm.strand <- lm(Besucher~Temperatur, data = strand)\nsummary(lm.strand)\n\n\n\nCall:\nlm(formula = Besucher ~ Temperatur, data = strand)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-476.41 -176.89   55.59  218.82  353.11 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -855.01     290.54  -2.943 0.021625 *  \nTemperatur     67.62      11.80   5.732 0.000712 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 311.7 on 7 degrees of freedom\nMultiple R-squared:  0.8244,    Adjusted R-squared:  0.7993 \nF-statistic: 32.86 on 1 and 7 DF,  p-value: 0.0007115\n\npar(mfrow = c(2, 2))\nplot(lm.strand)\n\n\n\npar(mfrow = c(1 ,1))\nxv <- seq(0, 40, by = .1)\nyv <- predict(lm.strand, list(Temperatur = xv))\nplot(strand$Temperatur, strand$Besucher, xlim = c(0, 40))\nlines(xv, yv, lwd = 3, col=  \"blue\")\n\n\n\nglm.gaussian <- glm(Besucher~Temperatur, family = gaussian, data = strand)\nglm.poisson <- glm(Besucher~Temperatur, family = poisson, data = strand)\n\nsummary(glm.gaussian)\n\n\n\nCall:\nglm(formula = Besucher ~ Temperatur, family = gaussian, data = strand)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-476.41  -176.89    55.59   218.82   353.11  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -855.01     290.54  -2.943 0.021625 *  \nTemperatur     67.62      11.80   5.732 0.000712 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 97138.03)\n\n    Null deviance: 3871444  on 8  degrees of freedom\nResidual deviance:  679966  on 7  degrees of freedom\nAIC: 132.63\n\nNumber of Fisher Scoring iterations: 2\n\nsummary(glm.poisson)\n\n\n\nCall:\nglm(formula = Besucher ~ Temperatur, family = poisson, data = strand)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-13.577  -12.787   -4.491    9.515   15.488  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) 3.500301   0.056920   61.49   <2e-16 ***\nTemperatur  0.112817   0.001821   61.97   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 6011.8  on 8  degrees of freedom\nResidual deviance: 1113.7  on 7  degrees of freedom\nAIC: 1185.1\n\nNumber of Fisher Scoring iterations: 5\n\nRücktranformation der Werte auf die orginale Skale (Hier Exponentialfunktion da family=possion als Link-Funktion den natürlichen Logarithmus (log) verwendet) Besucher = exp(3.50 + 0.11 Temperatur/°C)\n\n\nexp(3.500301) # Anzahl besucher bei 0°C\n\n\n[1] 33.12542\n\nexp(glm.poisson$coefficients[1]) # Werte aus Modell\n\n\n(Intercept) \n   33.12542 \n\nexp(3.500301 + 30*0.112817) # Anzahl besucher bei 30°C\n\n\n[1] 977.3169\n\nexp(glm.poisson$coeff[1] * glm.poisson$coeff[2]) #coefficients kann mit coeff abgekürzt werden\n\n\n(Intercept) \n   1.484225 \n\n# Test Overdispersion\nif(!require(AER)){install.packages(\"AER\")}\nlibrary(AER)\ndispersiontest(glm.poisson)\n\n\n\n    Overdispersion test\n\ndata:  glm.poisson\nz = 3.8576, p-value = 5.726e-05\nalternative hypothesis: true dispersion is greater than 1\nsample estimates:\ndispersion \n  116.5467 \n\nglm.quasi <- glm(Besucher~Temperatur, family = quasipoisson, data = strand)\nsummary(glm.quasi)\n\n\n\nCall:\nglm(formula = Besucher ~ Temperatur, family = quasipoisson, data = strand)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-13.577  -12.787   -4.491    9.515   15.488  \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  3.50030    0.69639   5.026  0.00152 **\nTemperatur   0.11282    0.02227   5.065  0.00146 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 149.6826)\n\n    Null deviance: 6011.8  on 8  degrees of freedom\nResidual deviance: 1113.7  on 7  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 5\n\npar(mfrow = c(2,2))\nplot(glm.gaussian)\n\n\n\nplot(glm.poisson)\n\n\n\nplot(glm.quasi)\n\n\n\npar(mfrow = c(1, 1))\nplot(strand$Temperatur, strand$Besucher, xlim=c(0, 40))\nxv <- seq(0, 40, by = .1)\n\nyv <- predict(lm.strand, list(Temperatur = xv))\nlines(xv, yv, lwd = 3, col = \"blue\")\n\nyv2 <- predict(glm.poisson, list(Temperatur = xv))\nlines(xv, exp(yv2), lwd = 3, col = \"red\")\n\nyv3 <- predict(glm.quasi, list(Temperatur = xv))\nlines(xv, exp(yv3), lwd = 3, col = \"green\")\n\n\n\n\nLogistische Regression\n\n\nbathing <- data.frame(\n  \"temperature\" = c(1, 2, 5, 9, 14, 14, 15, 19, 22, 24, 25, 26, 27, 28, 29),\n  \"bathing\" = c(0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1))\nplot(bathing~temperature, data = bathing)\n\n\n\nglm.1<-glm(bathing~temperature, family = \"binomial\", data = bathing)\nsummary(glm.1)\n\n\n\nCall:\nglm(formula = bathing ~ temperature, family = \"binomial\", data = bathing)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.7408  -0.4723  -0.1057   0.5123   1.8615  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)  \n(Intercept)  -5.4652     2.8501  -1.918   0.0552 .\ntemperature   0.2805     0.1350   2.077   0.0378 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 20.728  on 14  degrees of freedom\nResidual deviance: 10.829  on 13  degrees of freedom\nAIC: 14.829\n\nNumber of Fisher Scoring iterations: 6\n\n# Modeldiagnostik (wenn nicht signifikant, dann OK)\n1 - pchisq (glm.1$deviance, glm.1$df.resid)\n\n\n[1] 0.6251679\n\n# Modellgüte (pseudo-R²)\n1 - (glm.1$dev / glm.1$null)\n\n\n[1] 0.4775749\n\n# Steilheit der Beziehung (relative Änderung der odds bei x + 1 vs. x)\nexp(glm.1$coefficients[2])\n\n\ntemperature \n   1.323807 \n\n# LD50 (also hier: Temperatur, bei der 50% der Touristen baden)\n-glm.1$coefficients[1] / glm.1$coefficients[2]\n\n\n(Intercept) \n   19.48311 \n\n# Vorhersagen\npredicted <- predict(glm.1, type = \"response\")\n\n# Konfusionsmatrix\nkm <- table(bathing$bathing, predicted > 0.5)\nkm\n\n\n   \n    FALSE TRUE\n  0     7    1\n  1     1    6\n\n# Missklassifizierungsrate\n1 - sum(diag(km) / sum(km))\n\n\n[1] 0.1333333\n\n#Plotting\nxs <- seq(0, 30, l = 1000)\nmodel.predict <- predict(glm.1, type = \"response\", se = T, \n                         newdata = data.frame(temperature = xs))\n\nplot(bathing~temperature, xlab = \"Temperature (°C)\", \n     ylab = \"% Bathing\", pch = 16, col = \"red\", data = bathing)\npoints(model.predict$fit ~ xs, type=\"l\")\nlines(model.predict$fit+model.predict$se.fit ~ xs, type = \"l\", lty = 2)\nlines(model.predict$fit-model.predict$se.fit ~ xs, type = \"l\", lty = 2)\n\n\n\n\nNicht-lineare Regression\n\n\nif(!require(AICcmodavg)){install.packages(\"AICcmodavg\")}\nif(!require(nlstools)){install.packages(\"nlstools\")}\nlibrary(AICcmodavg)\nlibrary(nlstools)\n\nloyn <- read.delim(\"loyn.csv\", sep = \",\") # Verzeichnis muss dort gesetzt sein wo Daten sind\n\n#Selbstdefinierte Funktion, hier Potenzfunktion\npower.model <- nls(ABUND~c*AREA^z, start = (list(c = 1, z = 0)), data = loyn)\nsummary(power.model)\n\n\n\nFormula: ABUND ~ c * AREA^z\n\nParameters:\n  Estimate Std. Error t value Pr(>|t|)    \nc 13.39418    1.30721  10.246 2.87e-14 ***\nz  0.16010    0.02438   6.566 2.09e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.995 on 54 degrees of freedom\n\nNumber of iterations to convergence: 12 \nAchieved convergence tolerance: 7.124e-06\n\nAICc(power.model)\n\n\n[1] 396.1723\n\n#Modeldiagnostik (in nlstools)\nplot(nlsResiduals(power.model))\n\n\n\n#Vordefinierte \"Selbststartfunktionen\"#\n?selfStart\nlogistic.model <- nls(ABUND~SSlogis(AREA, Asym, xmid, scal), data = loyn)\nsummary(logistic.model)\n\n\n\nFormula: ABUND ~ SSlogis(AREA, Asym, xmid, scal)\n\nParameters:\n     Estimate Std. Error t value Pr(>|t|)    \nAsym   31.306      2.207  14.182  < 2e-16 ***\nxmid    6.501      2.278   2.854  0.00614 ** \nscal    9.880      3.152   3.135  0.00280 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.274 on 53 degrees of freedom\n\nNumber of iterations to convergence: 8 \nAchieved convergence tolerance: 4.371e-06\n\nAICc(logistic.model)\n\n\n[1] 386.8643\n\n#Modeldiagnostik (in nlstools)\nplot(nlsResiduals(logistic.model))\n\n\n\n#Visualisierung\nplot(ABUND~AREA, data = loyn)\npar(mfrow = c(1, 1))\nxv <- seq(0, 2000, 0.01)\n\n# 1. Potenzfunktion\nyv1 <- predict(power.model, list(AREA = xv))\nlines(xv, yv1, col = \"green\")\n\n# 2. Logistische Funktion\nyv2 <- predict(logistic.model, list(AREA = xv))\nlines(xv, yv2, col = \"blue\")\n\n\n\n#Visualisierung II\nplot(ABUND~log10(AREA), data = loyn)\npar(mfrow = c(1, 1))\n\n# 1. Potenzfunktion\nyv1 <- predict(power.model, list(AREA = xv))\nlines(log10(xv), yv1, col = \"green\")\n\n# 2. Logistische Funktion\nyv2 <- predict(logistic.model, list(AREA = xv))\nlines(log10(xv), yv2, col = \"blue\")\n\n\n\n#Model seletkion zwischen den nicht-lineraen Modelen\ncand.models<-list()\ncand.models[[1]] <- power.model\ncand.models[[2]] <- logistic.model\n\nModnames <- c(\"Power\", \"Logistic\")\n\naictab(cand.set = cand.models, modnames = Modnames)\n\n\n\nModel selection based on AICc:\n\n         K   AICc Delta_AICc AICcWt Cum.Wt      LL\nLogistic 4 386.86       0.00   0.99   0.99 -189.04\nPower    3 396.17       9.31   0.01   1.00 -194.86\n\nSmoother\n\n\nloyn$log_AREA<-log10(loyn$AREA)       \nplot(ABUND~log_AREA, data = loyn)\nlines(lowess(loyn$log_AREA, loyn$ABUND, f = 0.25), lwd = 2, col = \"red\")\nlines(lowess(loyn$log_AREA, loyn$ABUND, f = 0.5), lwd = 2, col = \"blue\")\nlines(lowess(loyn$log_AREA, loyn$ABUND, f = 1), lwd = 2, col = \"green\")\n\n\n\n\nGAMs\n\n\nif(!require(mgcv)){install.packages(\"mgcv\")}\nlibrary(mgcv)\n\ngam.1 <- gam(ABUND~s(log_AREA), data = loyn)\ngam.1\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nABUND ~ s(log_AREA)\n\nEstimated degrees of freedom:\n2.88  total = 3.88 \n\nGCV score: 52.145     \n\nsummary(gam.1)\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nABUND ~ s(log_AREA)\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  19.5143     0.9309   20.96   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n              edf Ref.df     F p-value    \ns(log_AREA) 2.884  3.628 21.14  <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.579   Deviance explained = 60.1%\nGCV = 52.145  Scale est. = 48.529    n = 56\n\nplot(loyn$log_AREA, loyn$ABUND, pch = 16)\nxv <- seq(-1,4, by = 0.1)\nyv <- predict(gam.1, list(log_AREA = xv))\nlines(xv, yv, lwd = 2, col = \"red\")\n\n\n\nAICc(gam.1)\n\n\n[1] 383.2109\n\nsummary(gam.1)\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nABUND ~ s(log_AREA)\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  19.5143     0.9309   20.96   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n              edf Ref.df     F p-value    \ns(log_AREA) 2.884  3.628 21.14  <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.579   Deviance explained = 60.1%\nGCV = 52.145  Scale est. = 48.529    n = 56\n\n\n\n\n",
    "preview": "statistik/Statistik4_01_Demo/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik4_02_Uebung/",
    "title": "Übungen Statistik 4",
    "description": {},
    "author": [],
    "date": "2021-11-08",
    "categories": [
      "Statistik4"
    ],
    "contents": "\n\nContents\nAufgabe 4.1: Nicht-lineare Regression\nAufgabe 4.2N: Logistische Regression (NatWis)\nAufgabe 4.2S: Multiple logistische Regression (SozWis)\n\nAufgabe 4.1: Nicht-lineare Regression\nDatensatz Curonian_Spit.csv\nDieser enthält gemittelte Pflanzenartenzahlen (Species.richness) von geschachtelten Plots (Vegetationsaufnahmen) der Pflanzengesellschaft LolioCynosuretum im Nationalpark Kurische Nehrung (Russland) auf Flächengrössen (Area) von 0.0001 bis 900 m².\nErmittelt den funktionellen Zusammenhang (das beste Modell), der die Zunahme der Artenzahl mit der Flächengrösse am besten beschreibt.Berücksichtigt dabei mindestens die Potenzfunktion (power function, die logarithmische Funktion (logarithmic function,und eine Funktion mit Sättigung (saturation, asymptote) eurer Wahl.\nAufgabe 4.2N: Logistische Regression (NatWis)\nDatensatz polis.csv\nDer Datensatz polis.csv beschreibt für 19 Inseln im Golf von Kalifornien, ob Eidechsen der Gattung Uta vorkommen (presence/absence: PA) in Abhängigkeit von der Form der Inseln (Verhältnis Umfang zu Fläche: RATIO).\nBitte prüft mit einer logistischen Regression, ob und ggf. wie die Inselform die Präsenz der Eidechsen beinflusst\nAufgabe 4.2S: Multiple logistische Regression (SozWis)\nFührt mit dem Datensatz der Gästebefragung eine logistische Regression durch. Kann der Mensabesuch druch die sozioökonomischen Variablen (Alter, Geschlecht, Hochschulzugehörigkeit), wahrgenommener Fleischkonsum und Einstellung zu ?? vorhergesagt werden?\nHinweise:\nDas Item tho_2 (“Ich mache mir allgemein Gedanken über die Folgen meiner Ernährungsgewohnheiten für die Umwelt.”) müsst ihr in einem ersten Schritt zu einer Dummy-Variable umcodieren: die Antwortkategorien «stimme eher zu» (=3) und «stimme zu» (=4) müsst ihr eine 1 zuweisen, den anderen zwei Kategorien eine 0. Hinweis dafür könnt ihr die Funktion dpylr::case_when() oder dpylr::if_else() verwenden.\nFehlende Werten könnt ihr weglassen (z.B. dpylr::drop_na())\nDefiniert das Modell und wendet es auf den Datensatz an\nBerechnet eine Vorhersage des Modells mit predict()\nEruiert den Modellfit und die Modellgenauigkeit\nFür Motivierte: Berechnet eine Konfusionsmatrix und zieht euer Fazit daraus\nStellt eure Ergebnisse angemessen dar (Text und/oder Tabelle)\n\n\n\n",
    "preview": {},
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik4_03_Solution_4.1/",
    "title": "Musterlösung Übung 4.1",
    "description": {},
    "author": [],
    "date": "2021-11-12",
    "categories": [
      "Statistik4"
    ],
    "contents": "\n\nContents\nMusterloesung Aufgabe 4.1: Nicht-lineare Regression\nMusterlösung Aufgabe 4.1 - Nicht-lineare Regression\n\n\n\n\n\nMusterloesung Aufgabe 4.1: Nicht-lineare Regression\nR-Code als Download\nLoesungstext Beispiel\nÜbungsaufgabe (hier so ausführlich formuliert, wie dies auch in der Klausur der Fall sein wird)\nLaden Sie den Datensatz Curonia_spit.xlsx. Dieser enthält gemittelte\nPflanzenartenzahlen (Species.richness) von geschachtelten Plots (Vegetationsaufnahmen) der Pflanzengesellschaft Lolio-Cynosuretum im Nationalpark Kurische Nehrung (Russland) auf Flächengrössen (Area) von 0.0001 bis 900 m².\nErmitteln Sie den funktionellen Zusammenhang, der die Zunahme der Artenzahl mit der Flächengrösse am besten beschreibt. Berücksichtigen Sie dabei mindestens die Potenzfunktion (power function), die logarithmische Funktion (logarithmic function) und eine Funktion mit Sättigung (saturation, asymptote) Ihrer Wahl\nBitte erklären und begründen Sie die einzelnen Schritte, die Sie unternehmen, um zu diesem Ergebnis zu kommen. Dazu erstellen Sie bitte ein Word-Dokument, in das Sie Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, Ihre Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere Vorgehen dokumentieren.\nDieser Ablauf sollte insbesondere beinhalten:\nÜberprüfen der Datenstruktur nach dem Einlesen, welches sind die abhängige(n) und welches die unabängige(n) Variablen\nExplorative Datenanalyse, um zu sehen, ob eine nicht-lineare Regression überhaupt nötig ist und ob evtl. Dateneingabefehler vorliegen vorgenommen werden sollten\nDefinition von mindestens drei nicht-linearen Regressionsmodellen\nSelektion des/der besten Models/Modelle\nDurchführen der Modelldiagnostik für die Modelle in der engeren Auswahl, um zu entscheiden, ob das gewählte Vorgehen korrekt war oder ggf. angepasst werden muss\nGenerieren aller Zahlen, Statistiken und Tabellen, die für eine wiss. Ergebnisdarstellung benötigt werden\n\nFormulieren Sie abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (ausformulierte schriftliche Zusammenfassung, mit je einem Absatz von ca. 60-100 Worten, resp. 3-8 Sätzen für den Methoden- und Ergebnisteil). D. h. alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden.\nAbzugeben sind am Ende (a) Ein lauffähiges R-Skript; (b) begründeter Lösungsweg (Kombination aus R-Code, R Output und dessen Interpretation) und (c) ausformulierter Methoden- und Ergebnisteil (für eine wiss. Arbeit).\nMusterlösung Aufgabe 4.1 - Nicht-lineare Regression\nAus der Excel-Tabelle wurde das relevante Arbeitsblatt als csv gespeichert\n\n\nSAR <- read.delim(\"https://media.githubusercontent.com/media/ResearchMethods-ZHAW/datasets/main/statistik/Curonian_Spit.csv\", sep=\";\")\nstr(SAR)\n\n\n'data.frame':   16 obs. of  2 variables:\n $ Area            : num  0.0001 0.0025 0.01 0.0625 0.25 1 4 9 16 25 ...\n $ Species.richness: num  2.1 9.1 14.3 23.1 30.1 37.4 48.5 54.5 58 59.9 ...\n\nsummary(SAR)\n\n\n      Area          Species.richness\n Min.   :  0.0001   Min.   : 2.10   \n 1st Qu.:  0.2031   1st Qu.:28.35   \n Median : 12.5000   Median :56.25   \n Mean   :147.1453   Mean   :50.09   \n 3rd Qu.:131.2500   3rd Qu.:69.95   \n Max.   :900.0000   Max.   :92.40   \n\n # Explorative Datenanalyse\nplot(Species.richness~Area, data = SAR)\n\n\n\n\nEs liegt in der Tat ein nicht-linearer Zusammenhang vor, der sich gut mit nls analysieren lässt. Die Daten beinhalten keine erkennbaren Fehler, da der Artenreichtum der geschachtelten Plots mit der Fläche ansteigt.\n\n\n# Potenzfunktion selbst definiert\nif(!require(nlstools)){install.packages(\"nlstools\")}\nlibrary(nlstools)\n# power.model <- nls(Species.richness~c*Area^z, data = SAR)\n# summary(power.model)\n\n\n\nFalls die Funktion so keine Ergebnisse liefert, oder das Ergebnis unsinnig aussieht, wenn man es später plottet, müsste man hier geeignete Startwerte angeben, die man aus der Betrachtung der Daten oder aus Erfahrungen mit der Funktion für ähnliche Datensets gewinnt,etwa so:\n\n\npower.model <- nls(Species.richness~c * Area^z, start = (list(c = 1, z = 0.2)), data = SAR)\nsummary(power.model)\n\n\n\nFormula: Species.richness ~ c * Area^z\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)    \nc 36.168960   1.408966   25.67 3.56e-13 ***\nz  0.138941   0.007472   18.60 2.88e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.142 on 14 degrees of freedom\n\nNumber of iterations to convergence: 9 \nAchieved convergence tolerance: 8.138e-06\n\nDas Ergebnis ist identisch\n\n\n#logarithmische Funktion selbst definiert\nlogarithmic.model <- nls(Species.richness~b0 + b1 * log10(Area), data = SAR)\nsummary(logarithmic.model)\n\n\n\nFormula: Species.richness ~ b0 + b1 * log10(Area)\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)    \nb0   43.333      1.358   31.91 1.78e-14 ***\nb1   13.281      0.654   20.31 8.75e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.265 on 14 degrees of freedom\n\nNumber of iterations to convergence: 1 \nAchieved convergence tolerance: 3.56e-09\n\nZu den verschiedenen Funktionen mit Sättigungswert (Asymptote) gehören Michaelis-Menten, das aymptotische Modell durch den Ursprung und die logistische Funktion. Die meisten gibt es in R als selbststartende Funktionen, was meist besser funktioniert als wenn man sich selbst Gedanken über Startwerte usw. machen muss. Man kann sie aber auch selbst definieren\nIm Folgenden habe ich ein paar unterschiedliche Sättigungsfunktionen mit verschiedenen Einstellungen durchprobiert, um zu zeigen, was alles passieren kann…\n\n\nmicmen.1 <- nls(Species.richness~SSmicmen(Area, Vm, K), data = SAR)\nsummary(micmen.1)\n\n\n\nFormula: Species.richness ~ SSmicmen(Area, Vm, K)\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)    \nVm  72.0108     4.2708  16.861 1.07e-10 ***\nK    0.8477     0.4371   1.939   0.0729 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.96 on 14 degrees of freedom\n\nNumber of iterations to convergence: 0 \nAchieved convergence tolerance: 3.377e-06\n\n# Dasselbe selbst definiert (mit default-Startwerten)\nmicmen.2 <- nls(Species.richness~Vm*Area/(K+Area), data = SAR)\nsummary(micmen.2)\n\n\n\nFormula: Species.richness ~ Vm * Area/(K + Area)\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)    \nVm  46.7020     9.6748   4.827 0.000268 ***\nK   -2.1532     0.5852  -3.679 0.002477 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 35.14 on 14 degrees of freedom\n\nNumber of iterations to convergence: 23 \nAchieved convergence tolerance: 9.113e-06\n\nHier ist das Ergebnis deutlich verschieden, ein Phänomen, das einem bei nicht-linearen Regressionen anders als bei linearen Regressionen immer wieder begegnen kann, da der Iterationsalgorithmus in lokalen Optima hängen bleiben kann. Oftmals dürfte die eingebaute Selbststartfunktion bessere Ergebnisse liefern, aber das werden wir unten sehen.\n\n\n# Dasselbe selbst definiert (mit sinnvollen Startwerten, basierend auf dem Plot)\nmicmen.3 <- nls(Species.richness~Vm*Area/(K+Area), start = list(Vm = 100, K = 1), data = SAR)\nsummary(micmen.3)\n\n\n\nFormula: Species.richness ~ Vm * Area/(K + Area)\n\nParameters:\n   Estimate Std. Error t value Pr(>|t|)    \nVm  72.0111     4.2708  16.861 1.07e-10 ***\nK    0.8477     0.4371   1.939   0.0729 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.96 on 14 degrees of freedom\n\nNumber of iterations to convergence: 22 \nAchieved convergence tolerance: 7.026e-06\n\nWenn man sinnvollere Startwerte als die default-Werte (1 für alle Parameter) eingibt, hier etwas einen mutmasslichen Asymptoten-Wert (aus der Grafik) von Vm = ca. 100, dann bekommt man das gleiche Ergebnis wie bei der Selbsstartfunktion\n\n\n# Eine asymptotische Funktion durch den Ursprung (mit implementierter Selbststartfunktion)\nasym.model <- nls(Species.richness~SSasympOrig(Area, Asym, lrc), data = SAR)\nsummary(asym.model)\n\n\n\nFormula: Species.richness ~ SSasympOrig(Area, Asym, lrc)\n\nParameters:\n     Estimate Std. Error t value Pr(>|t|)    \nAsym  68.5066     4.4278  15.472 3.38e-10 ***\nlrc    0.1184     0.4864   0.244    0.811    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 13.88 on 14 degrees of freedom\n\nNumber of iterations to convergence: 0 \nAchieved convergence tolerance: 2.808e-06\n\n\n\nlogistic.model <- nls(Species.richness~SSlogis(Area, asym, xmid, scal), data = SAR)\nsummary(logistic.model)\n\n\n\nError in nls(y ~ 1/(1 + exp((xmid - x)/scal)), data = xy, start = list(xmid= aux[1L], : Iterationenzahl überschritt Maximum 50\nDas ist etwas, was einem bei nls immer wieder passieren kann. Die Iteration ist nach der eingestellten max. Iterationszahl noch nicht zu einem Ergebnis konvergiert. Um ein Ergebnis für diese Funktion zu bekommen, müsste man mit den Einstellungen von nls „herumspielen“, etwas bei den Startwerten oder den max. Um das effizient zu machen, braucht man aber etwas Erfahrung Interationszahlen (man kann z. B. manuell die Maximalzahl der Iterationen erhöhen, indem man in den Funktionsaufruf etwa maxiter =100 als zusätzliches Argument reinschreibtn).\n#Logistische Regression mit Startwerten\n\n\nlogistic.model.2 <- nls(Species.richness~asym/(1 + exp((xmid-Area) / scal)), \n                      control = nls.control(maxiter = 100), \n                      start = (list(xmid = 1, scal = 0.2, asym = 100)), data = SAR)\nsummary(logistic.model.2)\n\n\n\nFormula: Species.richness ~ asym/(1 + exp((xmid - Area)/scal))\n\nParameters:\n     Estimate Std. Error t value Pr(>|t|)    \nxmid    3.970      1.608   2.469   0.0282 *  \nscal    4.112      1.676   2.453   0.0290 *  \nasym   73.634      4.507  16.339 4.79e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 12.11 on 13 degrees of freedom\n\nNumber of iterations to convergence: 59 \nAchieved convergence tolerance: 9.685e-06\n\n\n\n# Vergleich der Modellgüte mittels AICc\nlibrary(AICcmodavg)\ncand.models <- list()\ncand.models[[1]] <- power.model\ncand.models[[2]] <- logarithmic.model\ncand.models[[3]] <- micmen.1\ncand.models[[4]] <- micmen.2\ncand.models[[5]] <- asym.model\ncand.models[[6]] <- logistic.model.2\n\nModnames<-c(\"Power\", \"Logarithmic\", \"Michaelis-Menten (SS)\", \"Michaelis-Menten\", \n            \"Asymptotic through origin\", \"Logistische Regression\")\naictab(cand.set=cand.models, modnames=Modnames)\n\n\n\nModel selection based on AICc:\n\n                          K   AICc Delta_AICc AICcWt Cum.Wt     LL\nPower                     3  96.75       0.00   0.98   0.98 -44.38\nLogarithmic               3 104.43       7.68   0.02   1.00 -48.21\nMichaelis-Menten (SS)     3 130.67      33.92   0.00   1.00 -61.34\nLogistische Regression    4 133.53      36.78   0.00   1.00 -60.95\nAsymptotic through origin 3 135.44      38.69   0.00   1.00 -63.72\nMichaelis-Menten          3 165.17      68.42   0.00   1.00 -78.58\n\nDiese Ergebnistabelle vergleicht die Modellgüte zwischen den fünf Modellen, die wir in unsere Auswahl reingesteckt haben. Alle haben drei geschätzte Parameter (K), also zwei Funktionsparameter und die Varianz. Das beste Modell (niedrigster AICc bzw. Delta = 0) hat das Potenzmodell (power). Das zweitbeste Modell (logarithmic) hat bereits einen Delta-AICc von mehr als 4, ist daher statistisch nicht relevant. Das zeigt sich auch am Akaike weight, das für das zweite Modell nur noch 2 % ist. Die verschiedenen Modelle mit oberem Grenzwert (3-5) sind komplett ungeeignet.\n\n\n# Modelldiagnostik für das beste Modell\nlibrary(nlstools)\nplot(nlsResiduals(power.model))\n\n\n\n\nLinks oben sieht man zwar ein Muster (liegt daran, dass in diesem Fall die Plots geschachtelt, und nicht unabhängig waren), aber jedenfalls keinen problematischen Fall wie einen Bogen oder einen Keil. Der QQ-Plot rechts unten ist völlig OK. Somit haben wir auch keine problematische Abweichung von der Normalverteilung der Residuen. Da es sich bei den einzelnen Punkten allerdings bereits um arithmetische Mittelwerte aus je 8 Beobachtungen handelt, hätte man sich auch einfach auf das Central Limit Theorem beziehen können, das sagt, dass Mittelwerte automatisch einer Normalverteilung folgen.\n\n\n# Ergebnisplot\nplot(Species.richness~Area, pch = 16, xlab = \"Fläche [m²]\", ylab = \"Artenreichtum\", data = SAR)\nxv <- seq(0, 1000, by = 0.1)\nyv <- predict(power.model, list(Area = xv))\nlines(xv, yv, lwd = 2, col = \"red\")\nyv2 <- predict(micmen.1, list(Area = xv))\nlines(xv, yv2, lwd = 2, col = \"blue\")\n\n\n\n\nDas ist der Ergebnisplot für das beste Modell. Wichtig ist, dass man die Achsen korrekt beschriftet und nicht einfach die mehr oder weniger kryptischen Spaltennamen aus R nimmt.\nIm Weiteren habe ich noch eine Sättigungsfunktion (Michaelis-Menten mit Selbststarter) zum Vergleich hinzugeplottet\nMan erkennt, dass die Sättigungsfunktion offensichtlich den tatsächlichen Kurvenverlauf sehr schlecht widergibt. Im mittleren Kurvenbereich sind die Schätzwerte zu hoch, für grosse Flächen dann aber systematisch viel zu niedrig. Man kann die Darstellung im doppeltlogarithmischen Raum wiederholen, um die Kurvenanpassung im linken Bereich besser differenzieren zu können:\n\n\n# Ergebnisplot Double-log\nplot(log10(Species.richness)~log10(Area), pch = 16, xlab = \"log A\", ylab = \"log (S)\", data = SAR)\n\nxv <- seq(0, 1000, by = 0.0001)\n\nyv <- predict(power.model, list(Area = xv))\nlines(log10(xv), log10(yv), lwd = 2, col = \"red\")\n\nyv2 <- predict(micmen.1, list(Area=xv))\nlines(log10(xv), log10(yv2), lwd = 2, col = \"blue\")\n\n\n\n\nAuch hier sieht man, dass die rote Kurve zwar nicht perfekt, aber doch viel besser als die blaue Kurve ist.\n\n\n\n",
    "preview": "statistik/Statistik4_03_Solution_4.1/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik4_03_Solution_4.2s/",
    "title": "Musterlösung Übung 4.2s",
    "description": {},
    "author": [
      {
        "name": "Gian-Andrea Egeler",
        "url": {}
      }
    ],
    "date": "2021-11-12",
    "categories": [
      "Statistik4"
    ],
    "contents": "\n\nContents\nMusterlösung Übung 4.2S: Multiple logistische Regression (SozWis)\nkommentierter Loesungsweg\nMethode\nErgebnisse\n\n\n\n\n\n\nDownload R-Skript\n\nMusterlösung Übung 4.2S: Multiple logistische Regression (SozWis)\nLese-Empfehlung Kapitel 6 von Manny Gimond\nLese-Empfehlung Kapitel 4 von Gareth (2016)\nLese-Empfehlung Vorlesungsfolien von Oscar Torres-Reyna Princeton University\nkommentierter Loesungsweg\n\n\n\n\n\n# Genereiert eine Dummyvariable: Fleisch 1, kein Fleisch 0\ndf <- nova_survey %>%  # kopiert originaler Datensatz\n  rename(umwelteinstellung = tho_2) %>% # änderung name der variable\n  mutate(umwelteinstellung = case_when(umwelteinstellung == 4 ~ 1,\n                                       umwelteinstellung == 3 ~ 1,\n                                       umwelteinstellung == 2 ~ 0, \n                                       umwelteinstellung == 1 ~ 0)) %>% \n  # lasse die kleine Gruppe mit x weg\n  dplyr::filter(!str_detect(string = \"x\", gender)) %>% \n  # lasse die kleine Gruppe \"andere\" weg\n  dplyr::filter(!str_detect(string = \"Andere\", member)) %>%  \n  # wähle nur die relevanten variablen aus\n  dplyr::select(mensa, age_groups, gender, member, umwelteinstellung, meat) \n\n# Schaut euch die Missings an in der Kriteriumsvariable \"mensa\"\nsum(is.na(df$mensa))\n\n\n[1] 0\n\n# schaut euch die Missings an in den Prädiktorvariablen \"Alter\", \"Geschlecht\", \"Hochschulzugehörigkeit\", \"Umwelteinstellung\"\n\nAmelia::missmap(df) \n\n\n\n# vieles deutet darauf hin, dass die missings (fehlende Werte) \n# zufällig zustande gekommen sind (sog. MCAR); für mehr Informationen: https://uvastatlab.github.io/2019/05/01/getting-started-with-multiple-imputation-in-r/\n\n# bester Weg wäre, die wenigen fehlenden Werte zu imputieren; \n# einfachheitshalber löschen wir sie aber :)\ndf %<>%\n  drop_na()\n\n#  sieht euch die Verteilung zwischen Mensagänger und Selbstverpfleger an\n# sind nicht gleichmässig verteilt, bei der Vorhersage müssen wir das berücksichtigen\ntable(df$mensa) \n\n\n\n  0   1 \n282 786 \n\ndf %>% count(mensa) # alternativ\n\n\n# A tibble: 2 x 2\n  mensa     n\n  <dbl> <int>\n1     0   282\n2     1   786\n\n# definiert das logistische Modell und wendet es auf den Datensatz an\n\nmod0 <-glm(mensa ~ gender + member + age_groups + meat + umwelteinstellung, \n           data = df, binomial(\"logit\"))\nsummary.lm(mod0) # Umwelteinstellung scheint keinen Einfluss auf die \n\n\n\nCall:\nglm(formula = mensa ~ gender + member + age_groups + meat + umwelteinstellung, \n    family = binomial(\"logit\"), data = df)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-5.6740 -0.8078  0.3712  0.5867  1.2379 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  -0.18889    0.40225  -0.470 0.638750    \ngenderMann                    0.71017    0.16018   4.434 1.02e-05 ***\nmemberStudent/in             -0.63072    0.29442  -2.142 0.032404 *  \nage_groups26- bis 34-jaehrig  1.09429    0.19574   5.591 2.88e-08 ***\nage_groups35- bis 49-jaehrig  1.75379    0.45968   3.815 0.000144 ***\nage_groups50- bis 64-jaehrig  2.43530    0.78923   3.086 0.002083 ** \nmeat                          0.19945    0.05055   3.945 8.49e-05 ***\numwelteinstellung             0.19334    0.18688   1.035 0.301107    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.009 on 1060 degrees of freedom\nMultiple R-squared:  0.004042,  Adjusted R-squared:  -0.002536 \nF-statistic: 0.6145 on 7 and 1060 DF,  p-value: 0.7443\n\n# Verpflegung zu haben, gegeben die Daten\n\n# neues Modell ohne Umwelteinstellung\nmod1 <- update(mod0, ~. -umwelteinstellung)\nsummary.lm(mod1)\n\n\n\nCall:\nglm(formula = mensa ~ gender + member + age_groups + meat, family = binomial(\"logit\"), \n    data = df)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-6.0117 -0.8060  0.3584  0.6100  1.2407 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                   0.03212    0.34053   0.094 0.924860    \ngenderMann                    0.69697    0.15951   4.369 1.37e-05 ***\nmemberStudent/in             -0.64418    0.29426  -2.189 0.028806 *  \nage_groups26- bis 34-jaehrig  1.11651    0.19458   5.738 1.25e-08 ***\nage_groups35- bis 49-jaehrig  1.77409    0.45947   3.861 0.000120 ***\nage_groups50- bis 64-jaehrig  2.44683    0.78953   3.099 0.001992 ** \nmeat                          0.18070    0.04709   3.837 0.000132 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.01 on 1061 degrees of freedom\nMultiple R-squared:  0.003998,  Adjusted R-squared:  -0.001635 \nF-statistic: 0.7098 on 6 and 1061 DF,  p-value: 0.6418\n\n# Modeldiagnostik (wenn nicht signifikant, dann OK)\n1 - pchisq(mod1$deviance, mod1$df.resid) # Ok\n\n\n[1] 0.4509591\n\n#Modellgüte (pseudo-R²)\n1 - (mod1$dev / mod1$null) # eher kleines pseudo-R2, deckt sich mit dem R-Squared aus dem obigen output summary.lm()\n\n\n[1] 0.1354244\n\n# Konfusionsmatrix vom  Datensatz\n# Model Vorhersage\n# hier ein anderes Beispiel: \npredicted <- predict(mod1, df, type = \"response\")\n\n# erzeugt eine Tabelle mit den beobachteten\n# Mensagänger/Selbstverpfleger und den Vorhersagen des Modells\nkm <- table(predicted > 0.5, df$mensa) \n# alles was höher ist als 50% ist \n# kommt in die Kategorie Mensagänger\n\n# anpassung der namen\ndimnames(km) <- list(\n  c(\"Modell Selbst\", \"Modell Mensa\"),\n  c(\"Daten Selbst\", \"Daten Mensa\"))\nkm\n\n\n              Daten Selbst Daten Mensa\nModell Selbst           87          59\nModell Mensa           195         727\n\n#############\n### reminder: https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62\n#############\n\n#TP = true positive: you predicted positive and it’s true; hier vorhersage \n# mensagänger stimmt also (727)\n\n#TN = true negative: you predicted negative and it’s true, hier vorhersage der \n# selbstverpfleger stimmt (87)\n\n#FP = false positive (fehler 1. art, auch spezifizität genannt) you predicted \n# and it’s false. hier modell sagt mensagänger vorher \n# (obwohl in realität selbstverpfleger) (195)\n\n#FN = false negative (fehler 2. art, auch sensitivität genannt), \n# you predicted negative and it’s false. hier modell sagt selbtverpfleger vorher \n# (obwohl in realität mensagänger) (59)\n\n\n# es scheint, dass das Modell häufig einen alpha Fehler zu machen, d.h. es \n# das Modell weist keine hohe Spezifizität auf: konkret werden viele Mensagänger als \n# Selbstverpfleger vorhergesagt resp. klassifiziert. Dafür gibt es mehere Gründe: \n\n#1) die Kriteriumsvariable ist sehr ungleich verteilt, d.h. es gibt weniger\n# Selbstverpfleger als Mensgänger im Datensatz \n \n#2) nicht adäquates Modell z.B. link mit probit zeigt besserer fit\n\n#3) Overfitting: wurde hier nicht berücksichtigt, in einem Paper/Arbeit \n# müsste noch einen Validierungstest gemacht werden z.B. test-train \n# Cross-Validation oder k fold Cross-Validation \n\n# kalkuliert die Missklassifizierungsrate \nmf <- 1-sum(diag(km)/sum(km)) # ist mit knapp 23 %  eher hoch\nmf\n\n\n[1] 0.2378277\n\n# kleiner exkurs: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/\n# col wise proportion, da diese die \"realität\" ist\nkm_prop <- prop.table(km,2)\n\n\n# specificity = a / (a+c) => ability of a test to correctly \n# classify an individual as disease-free is called the test′s specificity\nspec = km_prop[1] / (km_prop[1] + km_prop[2])\nspec\n\n\n[1] 0.3085106\n\n# sensitivity = d / (b+d) => Sensitivity is the ability of a \n# test to correctly classify an individual as ′diseased′\nsens = km_prop[4] / (km_prop[3] + km_prop[4])\nsens\n\n\n[1] 0.9249364\n\nMethode\nIn der Aufgabe war es das Ziel zu schauen, ob wir einen potenziellen Besuch eines Mensagasts vorhersagen können und zwar in Abhängigkeit von den sozioökonimischen Variablen, wahrgenommene Fleischkonsum und der Umwelteinstellung. Die Kriteriumsvariable “Mensa” weist eine binäre Verteilung auf: Deshalb rechnen wir eine multiple logistische Regression mit den Prädiktoren “Alter”, “Geschlecht”, “Hochschulzugehörigkeit”, “Fleischkonsum” und \"Umwelteinstellung. Mehr Informatinen zu den logistischen Regressinen findet ihr im Buch von Crawley (2015) oder auch im Buch von Gareth (2016), Kapitel 4.3; passendes Video hier.\nErgebnisse\n\n\nDaten Selbst\nDaten Mensa\nModell Selbst\n87\n59\nModell Mensa\n195\n727\n\nDer Output des logistischen Models mit der Linkfunktin “logit” sagt und, dass das Modell nicht gut zu den Daten passt, d.h. mit dem Modell (gegeben die Daten) können wir nur schlecht vorhersagen, ob eine Person zukünftig sich in der Mensa verpflegt oder ihr Mittagessen selber mitnimmt. Hinweise dafür geben das kleine pseudo-R2 (14%) als auch die hohe Missklassifizierungsrate (24%): bei genauerer Betrachtung fällt auf, dass das Modell häufig einen alpha-Fehler begeht, d.h. unser Modell sagt zu viele Mensagänger vorher, obwohl diese in Realität Selbstverpfleger sind. Es gibt verschiedene Gründe für diesen schlechten Modelfit:\ndie Kriteriumsvariable ist sehr ungleich verteilt, d.h. es gibt weniger Selbstverpfleger als Mensgänger im Datensatz (26% vs. 74%)\ndie Prädiktorvariablen sind alle entweder kategorial oder ordinal: dies kann dazu führen, dass das Model keinen guten fit zu den Daten erzielt\nFazit: Es sollte nach einem weiteren adäquateren Modell gesucht werden: insbesondere ein Modell, welches einen mit ordinalen Prädiktorvariablen umgehen kann:\neine bessere Link-Funktion für das GLM suchen z.B. probit\npolynomiale Kontraste\nSmooth Splines hier\nmultinomiale Regression z.M. nnet::mulitom()hier\n\n\n\n",
    "preview": "statistik/Statistik4_03_Solution_4.2s/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik4_04_Solution_4.2n/",
    "title": "Musterlösung Übung 4.2n",
    "description": {},
    "author": [],
    "date": "2021-11-12",
    "categories": [
      "Statistik4"
    ],
    "contents": "\n\nContents\nMusterlösung Aufgabe 4.2N: Multiple logistische Regression\n\n\n\n\nMusterlösung Aufgabe 4.2N: Multiple logistische Regression\nR-Skript als Download\nLoesungstext\n\n\npolis <- read.csv(\"https://media.githubusercontent.com/media/ResearchMethods-ZHAW/datasets/main/statistik/polis.csv\")\npolis\n\n\n       ISLAND RATIO PA\n1        Bota 15.41  1\n2      Cabeza  5.63  1\n3     Cerraja 25.92  1\n4  Coronadito 15.17  0\n5      Flecha 13.04  1\n6    Gemelose 18.85  0\n7    Gemelosw 30.95  0\n8    Jorabado 22.87  0\n9      Mitlan 12.01  0\n10       Pata 11.60  1\n11      Piojo  6.09  1\n12      Smith  2.28  1\n13    Ventana  4.05  1\n14    Bahiaan 59.94  0\n15    Bahiaas 63.16  0\n16     Blanca 22.76  0\n17   Pescador 23.54  0\n18   Angeldlg  0.21  1\n19      Mejia  2.55  1\n\nstr(polis)\n\n\n'data.frame':   19 obs. of  3 variables:\n $ ISLAND: chr  \"Bota\" \"Cabeza\" \"Cerraja\" \"Coronadito\" ...\n $ RATIO : num  15.41 5.63 25.92 15.17 13.04 ...\n $ PA    : int  1 1 1 0 1 0 0 0 0 1 ...\n\nsummary(polis)\n\n\n    ISLAND              RATIO             PA        \n Length:19          Min.   : 0.21   Min.   :0.0000  \n Class :character   1st Qu.: 5.86   1st Qu.:0.0000  \n Mode  :character   Median :15.17   Median :1.0000  \n                    Mean   :18.74   Mean   :0.5263  \n                    3rd Qu.:23.20   3rd Qu.:1.0000  \n                    Max.   :63.16   Max.   :1.0000  \n\nMan erkennt, dass polis 19 Beobachtungen von drei Parametern enthält, wobei ISLAND ein Faktor mit den Inselnamen ist, während RATIO metrisch ist und PA nur 0 oder 1 enthält. Prädiktorvariable ist RATIO, abhängige Variable PA, mithin ist das korrekte statistische Verfahren eine logistische Regression (GLM).\n\n\n# Explorative Datenanalyse\nboxplot(polis$RATIO)\n\n\n\n\nDer Boxplot zeigt zwei starke Ausreisser, ist also etwas rechtsschief. Da es sich aber um die unabhängige Variable handelt, muss uns das nicht weiter stören.\n\n\n# Definition des logistischen Modells\nglm.1 <- glm(PA~RATIO, family = \"binomial\", data = polis)\nsummary (glm.1)\n\n\n\nCall:\nglm(formula = PA ~ RATIO, family = \"binomial\", data = polis)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.6067  -0.6382   0.2368   0.4332   2.0986  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)  \n(Intercept)   3.6061     1.6953   2.127   0.0334 *\nRATIO        -0.2196     0.1005  -2.184   0.0289 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 26.287  on 18  degrees of freedom\nResidual deviance: 14.221  on 17  degrees of freedom\nAIC: 18.221\n\nNumber of Fisher Scoring iterations: 6\n\nModell ist signifikant (p-Wert in Zeile RATIO ist < 0.05). Jetzt müssen wir noch prüfen, ob es auch valide ist:\n\n\n# Modelldiagnostik für das gewählte Modell (wenn nicht signifikant, dann OK)\n1 - pchisq(glm.1$deviance, glm.1$df.resid)\n\n\n[1] 0.6514215\n\n# Visuelle Inspektion der Linearität\nlibrary(car)\ncrPlots(glm.1, ask = F)\n\n\n\n\nBeide Aspekte sind OK, d.h. der Test war nicht signifikant und die pinkfarbene Linie liegt fast auf der theoretischen Linie (blau gestrichelt).\nJetzt brauchen wir noch die Modellgüte (Pseudo-R2):\n\n\n# Modellgüte (pseudo-R²)\n1 - (glm.1$dev / glm.1$null)\n\n\n[1] 0.4590197\n\nUm zu unser Modell zu interpretieren müssen wir noch in Betracht ziehen, dass wir nicht die Vorkommenswahrscheinlichkeit selbst, sondern logit (Vorkommenswahrscheinlichkeit) modelliert haben. Unser Ergebnis (die beiden Parameterschätzungen von oben, also 3.6061 und -0.2196) muss also zunächst in etwas Interpretierbares übersetzt werden:\n\n\n# Steilheit der Beziehung in Modellen mit nur einem Parameter\nexp(glm.1$coef[2])\n\n\n    RATIO \n0.8028734 \n\n< 1, d. h. Vorkommenswahrscheinlichkeit sinkt mit zunehmender Isolation.\n\n\n# LD50 für 1-Parameter-Modelle (hier also x-Werte, bei der 50% der Inseln besiedelt sind)\n-glm.1$coef[1] / glm.1$coef[2]\n\n\n(Intercept) \n    16.4242 \n\nAm besten stellen wir auch unsere Funktionsgleichung dar. Dazu müssen wir das „Rohergebnis“ (mit P = Vorkommenswahrscheinlichkeit)\nln (P/ (1- P)) = 3.606 – 0.220 RATIO\nso umformen, dass wir links nur P stehen haben:\nP = exp (3.606 – 0.220 RATIO) / (1 + exp (3.606 – 0.220 RATIO))\nDas ist also unsere vorhergesagte Regressionsfunktion, die wir in einem letzten Schritt auch noch visualisieren können (und sollten):\n\n\n# Ergebnisplots\npar(mfrow = c(1, 1))\n\nxs <- seq(0, 70, l = 1000)\nglm.predict <- predict(glm.1, type = \"response\", se = T, newdata = data.frame(RATIO=xs))\n\nplot(PA~RATIO, data = polis, xlab = \"Umfang-Flächen-Verhältnis\", ylab = \"Vorkommenswahrscheinlichkeit\", pch = 16, col = \"red\")\n     points(glm.predict$fit ~ xs,type=\"l\")\n     lines(glm.predict$fit + glm.predict$se.fit ~ xs, type = \"l\", lty = 2)\n     lines(glm.predict$fit - glm.predict$se.fit ~ xs, type = \"l\", lty = 2)\n\n\n\n\n\n\n\n",
    "preview": "statistik/Statistik4_04_Solution_4.2n/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik5_01_Demo/",
    "title": "Demo Statistik 5",
    "description": {},
    "author": [],
    "date": "2021-11-15",
    "categories": [
      "Statistik5"
    ],
    "contents": "\nVon linearen Modellen zu GLMMs\nDemoscript als Download\nDatensatz spf.csv\nDatensatz DeerEcervi.txt\nSplit-plot ANOVA\nBased on Logan (2010), Chapter 14\n\n\nspf <- read.delim(\"spf.csv\", sep = \";\") \nspf.aov <- aov(Reaktion~Signal * Messung + Error(VP), data = spf)\nsummary(spf.aov)\n\n\n\nError: VP\n          Df Sum Sq Mean Sq F value Pr(>F)\nSignal     1  3.125   3.125       2  0.207\nResiduals  6  9.375   1.562               \n\nError: Within\n               Df Sum Sq Mean Sq F value   Pr(>F)    \nMessung         3 194.50   64.83  127.89 2.52e-12 ***\nSignal:Messung  3  19.37    6.46   12.74 0.000105 ***\nResiduals      18   9.13    0.51                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ninteraction.plot(spf$Messung, spf$Signal, spf$Reaktion)\n\n# nun als LMM\nif(!require(nlme)){install.packages(\"nlme\")}\n\n\n\nlibrary(nlme)\n\n# mit random intercept (VP) und random slope (Messung)\nspf.lme.1 <- lme(Reaktion~Signal * Messung, random = ~Messung | VP, data = spf)\n# nur random intercept\nspf.lme.2 <- lme(Reaktion~Signal * Messung, random = ~1 | VP, data = spf)\n\nanova(spf.lme.1)\n\n\n               numDF denDF   F-value p-value\n(Intercept)        1    18 1488.1631  <.0001\nSignal             1     6    2.0808  0.1993\nMessung            3    18   70.7887  <.0001\nSignal:Messung     3    18   11.8592  0.0002\n\nanova(spf.lme.2)\n\n\n               numDF denDF  F-value p-value\n(Intercept)        1    18 591.6800  <.0001\nSignal             1     6   2.0000  0.2070\nMessung            3    18 127.8904  <.0001\nSignal:Messung     3    18  12.7397  0.0001\n\nsummary(spf.lme.1)\n\n\nLinear mixed-effects model fit by REML\n  Data: spf \n       AIC      BIC    logLik\n  97.63924 120.0223 -29.81962\n\nRandom effects:\n Formula: ~Messung | VP\n Structure: General positive-definite, Log-Cholesky parametrization\n            StdDev    Corr                \n(Intercept) 1.0801385 (Intr) MssnH2 MssnH3\nMessungH2   0.6455527 -0.717              \nMessungH3   0.6455528 -0.837  0.600       \nMessungH4   1.3229024 -0.816  0.390  0.878\nResidual    0.2886126                     \n\nFixed effects:  Reaktion ~ Signal * Messung \n                        Value Std.Error DF   t-value p-value\n(Intercept)              3.75 0.5590162 18  6.708213  0.0000\nSignalvisuell           -2.00 0.7905683  6 -2.529826  0.0447\nMessungH2                0.25 0.3818811 18  0.654654  0.5210\nMessungH3                3.25 0.3818811 18  8.510501  0.0000\nMessungH4                4.25 0.6922184 18  6.139681  0.0000\nSignalvisuell:MessungH2  1.00 0.5400614 18  1.851641  0.0806\nSignalvisuell:MessungH3  0.50 0.5400615 18  0.925821  0.3668\nSignalvisuell:MessungH4  4.00 0.9789446 18  4.086033  0.0007\n Correlation: \n                        (Intr) Sgnlvs MssnH2 MssnH3 MssnH4 Sg:MH2\nSignalvisuell           -0.707                                   \nMessungH2               -0.683  0.483                            \nMessungH3               -0.781  0.552  0.571                     \nMessungH4               -0.808  0.571  0.394  0.788              \nSignalvisuell:MessungH2  0.483 -0.683 -0.707 -0.404 -0.279       \nSignalvisuell:MessungH3  0.552 -0.781 -0.404 -0.707 -0.557  0.571\nSignalvisuell:MessungH4  0.571 -0.808 -0.279 -0.557 -0.707  0.394\n                        Sg:MH3\nSignalvisuell                 \nMessungH2                     \nMessungH3                     \nMessungH4                     \nSignalvisuell:MessungH2       \nSignalvisuell:MessungH3       \nSignalvisuell:MessungH4  0.788\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-0.86583578 -0.26649517 -0.03263197  0.23603775  0.95285749 \n\nNumber of Observations: 32\nNumber of Groups: 8 \n\nsummary(spf.lme.2)\n\n\nLinear mixed-effects model fit by REML\n  Data: spf \n       AIC      BIC    logLik\n  89.64876 101.4293 -34.82438\n\nRandom effects:\n Formula: ~1 | VP\n        (Intercept)  Residual\nStdDev:   0.5137012 0.7120003\n\nFixed effects:  Reaktion ~ Signal * Messung \n                        Value Std.Error DF   t-value p-value\n(Intercept)              3.75 0.4389856 18  8.542422  0.0000\nSignalvisuell           -2.00 0.6208194  6 -3.221549  0.0181\nMessungH2                0.25 0.5034602 18  0.496564  0.6255\nMessungH3                3.25 0.5034602 18  6.455326  0.0000\nMessungH4                4.25 0.5034602 18  8.441580  0.0000\nSignalvisuell:MessungH2  1.00 0.7120003 18  1.404494  0.1772\nSignalvisuell:MessungH3  0.50 0.7120003 18  0.702247  0.4915\nSignalvisuell:MessungH4  4.00 0.7120003 18  5.617975  0.0000\n Correlation: \n                        (Intr) Sgnlvs MssnH2 MssnH3 MssnH4 Sg:MH2\nSignalvisuell           -0.707                                   \nMessungH2               -0.573  0.405                            \nMessungH3               -0.573  0.405  0.500                     \nMessungH4               -0.573  0.405  0.500  0.500              \nSignalvisuell:MessungH2  0.405 -0.573 -0.707 -0.354 -0.354       \nSignalvisuell:MessungH3  0.405 -0.573 -0.354 -0.707 -0.354  0.500\nSignalvisuell:MessungH4  0.405 -0.573 -0.354 -0.354 -0.707  0.500\n                        Sg:MH3\nSignalvisuell                 \nMessungH2                     \nMessungH3                     \nMessungH4                     \nSignalvisuell:MessungH2       \nSignalvisuell:MessungH3       \nSignalvisuell:MessungH4  0.500\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-1.34519292 -0.63943480 -0.06164167  0.41510594  2.15199656 \n\nNumber of Observations: 32\nNumber of Groups: 8 \n\nGLMM\nBased on Zuur et al. (2009), chapter 13\n\n\nDeerEcervi <- read.delim(\"DeerEcervi.txt\", sep = \"\", stringsAsFactors = T)\n\n\n# Anzahl Larven hier in Presence/Absence übersetzt\nDeerEcervi$Ecervi.01 <- DeerEcervi$Ecervi\nDeerEcervi$Ecervi.01[DeerEcervi$Ecervi>0] <- 1\n\n#Numerische Geschlechtscodierung als Factor\nDeerEcervi$fSex <- as.factor(DeerEcervi$Sex)\n\n\n\nHirschlänge hier standardisiert, sonst würde der Achsenabschnitt im Modell für einen Hirsch der Länge 0 modelliert, was schlecht interpretierbar ist, jetzt ist der Achsenabschnitt für einen durschnittlich langen Hirsch\n\n\nDeerEcervi$CLength <- DeerEcervi$Length - mean(DeerEcervi$Length)\n\n# Zunächst als GLM\n# Interaktionen mit fFarm nicht berücksichtigt, da zu viele Freiheitsgrade verbraucht würden\nDE.glm <- glm(Ecervi.01 ~ CLength * fSex + Farm, family = binomial, data = DeerEcervi)\n\ndrop1(DE.glm, test = \"Chi\")\n\n\nSingle term deletions\n\nModel:\nEcervi.01 ~ CLength * fSex + Farm\n             Df Deviance     AIC     LRT  Pr(>Chi)    \n<none>            745.50  799.50                      \nFarm         23  1003.72 1011.72 258.225 < 2.2e-16 ***\nCLength:fSex  1   755.48  807.48   9.984  0.001579 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(DE.glm)\n\n\n\nCall:\nglm(formula = Ecervi.01 ~ CLength * fSex + Farm, family = binomial, \n    data = DeerEcervi)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.8400  -0.7576   0.3556   0.6431   2.2964  \n\nCoefficients:\n                Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   -1.796e+00  5.900e-01  -3.044 0.002336 ** \nCLength        4.062e-02  7.132e-03   5.695 1.24e-08 ***\nfSex2          6.280e-01  2.292e-01   2.740 0.006150 ** \nFarmAU         3.340e+00  7.841e-01   4.259 2.05e-05 ***\nFarmBA         3.510e+00  7.150e-01   4.908 9.19e-07 ***\nFarmBE         1.883e+01  6.216e+02   0.030 0.975831    \nFarmCB         3.012e+00  6.573e-01   4.583 4.58e-06 ***\nFarmCRC       -1.293e+01  2.400e+03  -0.005 0.995701    \nFarmHB        -2.364e-01  9.730e-01  -0.243 0.808045    \nFarmLN         3.831e+00  8.881e-01   4.314 1.60e-05 ***\nFarmMAN        1.046e+00  6.960e-01   1.503 0.132855    \nFarmMB         3.693e+00  8.152e-01   4.529 5.91e-06 ***\nFarmMO         9.722e-01  5.969e-01   1.629 0.103380    \nFarmNC         1.370e+00  6.904e-01   1.985 0.047169 *  \nFarmNV         2.098e+00  7.702e-01   2.725 0.006435 ** \nFarmPN         4.185e+00  8.584e-01   4.875 1.09e-06 ***\nFarmQM         3.975e+00  7.220e-01   5.506 3.68e-08 ***\nFarmRF         4.552e+00  1.050e+00   4.337 1.45e-05 ***\nFarmRN         8.706e-01  7.454e-01   1.168 0.242822    \nFarmRO         4.555e+00  9.556e-01   4.766 1.88e-06 ***\nFarmSAU       -1.545e+01  1.368e+03  -0.011 0.990986    \nFarmSE         2.785e+00  7.876e-01   3.536 0.000407 ***\nFarmTI         3.900e+00  1.166e+00   3.343 0.000828 ***\nFarmTN         3.102e+00  7.665e-01   4.046 5.21e-05 ***\nFarmVISO       3.720e+00  1.011e+00   3.679 0.000234 ***\nFarmVY         3.974e+00  1.257e+00   3.162 0.001565 ** \nCLength:fSex2  3.618e-02  1.168e-02   3.097 0.001953 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1073.1  on 825  degrees of freedom\nResidual deviance:  745.5  on 799  degrees of freedom\nAIC: 799.5\n\nNumber of Fisher Scoring iterations: 15\n\nanova(DE.glm)\n\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: Ecervi.01\n\nTerms added sequentially (first to last)\n\n             Df Deviance Resid. Df Resid. Dev\nNULL                           825    1073.13\nCLength       1   64.815       824    1008.31\nfSex          1    0.191       823    1008.12\nFarm         23  252.638       800     755.48\nCLength:fSex  1    9.984       799     745.50\n\n# Response curves für die einzelnen Farmen (Weibliche Tiere: fSex = \"1\" )\nplot(DeerEcervi$CLength, DeerEcervi$Ecervi.01,\n     xlab = \"Length\", ylab = \"Probability of \\\n     presence of E. cervi L1\")\n\nI <- order(DeerEcervi$CLength)\nAllFarms <- unique(DeerEcervi$Farm)\nfor (j in AllFarms){\n  mydata <- data.frame(CLength=DeerEcervi$CLength, fSex = \"1\",\n                       Farm = j)\n  n <- dim(mydata)[1]\n  if (n>10){\n    P.DE2 <- predict(DE.glm, mydata, type = \"response\")\n    lines(mydata$CLength[I], P.DE2[I])\n  }}\n\n\n\n\nGLMM\n\n\nif(!require(MASS)){install.packages(\"MASS\")}\nlibrary(MASS)\nDE.PQL <- glmmPQL(Ecervi.01 ~ CLength * fSex,\n                random = ~ 1 | Farm, family = binomial, data = DeerEcervi)\nsummary(DE.PQL)\n\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: DeerEcervi \n  AIC BIC logLik\n   NA  NA     NA\n\nRandom effects:\n Formula: ~1 | Farm\n        (Intercept)  Residual\nStdDev:    1.462108 0.9620576\n\nVariance function:\n Structure: fixed weights\n Formula: ~invwt \nFixed effects:  Ecervi.01 ~ CLength * fSex \n                  Value Std.Error  DF  t-value p-value\n(Intercept)   0.8883697 0.3373283 799 2.633547  0.0086\nCLength       0.0378608 0.0065269 799 5.800768  0.0000\nfSex2         0.6104570 0.2137293 799 2.856216  0.0044\nCLength:fSex2 0.0350666 0.0108558 799 3.230228  0.0013\n Correlation: \n              (Intr) CLngth fSex2 \nCLength       -0.108              \nfSex2         -0.191  0.230       \nCLength:fSex2  0.092 -0.522  0.235\n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-6.3466592 -0.6387839  0.2978382  0.5218829  3.4912879 \n\nNumber of Observations: 826\nNumber of Groups: 24 \n\ng <- 0.8883697 + 0.0378608 * DeerEcervi$CLength\np.averageFarm1 <- exp(g)/(1 + exp(g))\nI <- order(DeerEcervi$CLength)  #Avoid spaghetti plot\nplot(DeerEcervi$CLength, DeerEcervi$Ecervi.01, xlab=\"Length\",\n     ylab = \"Probability of presence of E. cervi L1\")\nlines(DeerEcervi$CLength[I], p.averageFarm1[I],lwd = 3)\np.Upp <- exp(g + 1.96 * 1.462108)/(1 + exp(g + 1.96 * 1.462108))\np.Low <- exp(g - 1.96 * 1.462108)/(1 + exp(g - 1.96 * 1.462108))\nlines(DeerEcervi$CLength[I], p.Upp[I])\nlines(DeerEcervi$CLength[I], p.Low[I])\n\n\n\nif(!require(lme4)){install.packages(\"lme4\")}\nlibrary(lme4)\nDE.lme4 <- glmer(Ecervi.01 ~ CLength * fSex + (1|Farm), \n                 family = binomial, data = DeerEcervi)\nsummary(DE.lme4)\n\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: Ecervi.01 ~ CLength * fSex + (1 | Farm)\n   Data: DeerEcervi\n\n     AIC      BIC   logLik deviance df.resid \n   832.6    856.1   -411.3    822.6      821 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-6.2678 -0.6090  0.2809  0.5022  3.4546 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n Farm   (Intercept) 2.391    1.546   \nNumber of obs: 826, groups:  Farm, 24\n\nFixed effects:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   0.938969   0.356004   2.638  0.00835 ** \nCLength       0.038964   0.006917   5.633 1.77e-08 ***\nfSex2         0.624487   0.222938   2.801  0.00509 ** \nCLength:fSex2 0.035859   0.011409   3.143  0.00167 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) CLngth fSex2 \nCLength     -0.107              \nfSex2       -0.189  0.238       \nCLngth:fSx2  0.091 -0.514  0.232\n\nif(!require(glmmML)){install.packages(\"glmmML\")}\nlibrary(glmmML)\nDE.glmmML <- glmmML(Ecervi.01 ~ CLength * fSex,\n                  cluster = Farm, family = binomial, data = DeerEcervi)\nsummary(DE.glmmML)\n\n\n\nCall:  glmmML(formula = Ecervi.01 ~ CLength * fSex, family = binomial,      data = DeerEcervi, cluster = Farm) \n\n                 coef se(coef)     z Pr(>|z|)\n(Intercept)   0.93968 0.357915 2.625 8.65e-03\nCLength       0.03898 0.006956 5.604 2.10e-08\nfSex2         0.62451 0.224251 2.785 5.35e-03\nCLength:fSex2 0.03586 0.011437 3.135 1.72e-03\n\nScale parameter in mixing distribution:  1.547 gaussian \nStd. Error:                              0.2975 \n\n        LR p-value for H_0: sigma = 0:  1.346e-41 \n\nResidual deviance: 822.6 on 821 degrees of freedom  AIC: 832.6 \n\n\n\n\n",
    "preview": "statistik/Statistik5_01_Demo/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik5_02_Assigment/",
    "title": "Übungen Statistik 5",
    "description": {},
    "author": [],
    "date": "2021-11-11",
    "categories": [
      "Statistik5"
    ],
    "contents": "\n\nContents\nAufgabe 5.1: Split-plot ANOVA\nAufgabe 5.2: GLMM\n\n\n\n\nAufgabe 5.1: Split-plot ANOVA\nDatensatz splityield.csv\nVersuch zum Ernteertrag (yield) einer Kulturpflanze in Abhängigkeit der drei Faktoren Bewässerung (irrigated vs. control), Düngung (N, NP, P) und Aussaatdichten (low, medium, high). Es gab vier ganze Felder (block), die zwei Hälften mit den beiden Bewässerungstreatments, diese wiederum drei Drittel für die drei Saatdichten und diese schliesslich je drei Drittel für die drei Düngertreatments hatten.\nAufgaben\nBestimmt das minimal adäquate Modell\nStellt die Ergebnisse da\nAufgabe 5.2: GLMM\nFührt mit dem Datensatz novanimal.csv eine logistische Regression durch, wobei ihr die einzelnen Käufer (single campus_card holder) als weitere randomisierte Variable mitberücksichtigt. Kann der Fleischkonsum durch das Geschlecht, die Hochschulzugehörigkeit und das Alter erklärt werden? Vergleich die Ergebnisse mit der eurem multiplen logistische Modell von Aufgabe 4.2\nKann der Fleischkonsum nun besser durch das Geschlecht, die Hochschulzugehörigkeit und das Alter erklärt werden?\nAufgaben\nBestimmt das minimal adäquate Modell\nStellt die Ergebnisse dar\nÄhnliches Vorgehen wie bei der Übung 4.2S:\nGeneriert eine neue Variable “Fleisch” (0 = kein Fleisch, 1 = Fleisch)\nEntfernt fehlende Werte aus der Variable “Fleisch”\nLasst für die Analyse den Menüinhalt “Buffet” weg\n\n\n\n",
    "preview": {},
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik5_03_Solution_5.1/",
    "title": "Musterlösung Übung 5.1",
    "description": {},
    "author": [],
    "date": "2021-11-23",
    "categories": [
      "Statistik5"
    ],
    "contents": "\n\nContents\nMusterloesung Aufgabe 5.1: Split-plot ANOVA\n\n\n\n\nMusterloesung Aufgabe 5.1: Split-plot ANOVA\nÜbungsaufgabe (hier so ausführlich formuliert, wie dies auch in der Klausur der Fall sein wird)\nLadet den Datensatz splityield.csv. Dieser enthält Versuchsergebnisse eines Experiments zum Ernteertrag (yield) einer Kulturpflanze in Abhängigkeit der drei Faktoren Bewässerung (irrigated vs. control), Düngung (N, NP, P) und Aussaatdichten (low, medium, high). Es gab vier ganze Felder (block), die zwei Hälften mit den beiden Bewässerungstreatments (irrigation), diese wiederum drei Drittel für die drei Saatdichten (density) und diese schliesslich je drei Drittel für die drei Düngertreatments (fertilizer) hatten.\nErmittelt das minimal adäquate statistische Modell, das den Ernteertrag in Abhängigkeit von den angegebenen Faktoren beschreibt.\nBitte erklärt und begründet die einzelnen Schritte, die ihr unternehmt, um zu diesem Ergebnis zu kommen. Dazu erstellt bitte ein Word-Dokument, in das ihr Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, eure Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere Vorgehen dokumentieren.\nDieser Ablauf sollte insbesondere beinhalten:\nÜberprüfen der Datenstruktur nach dem Einlesen, welches sind die abhängige(n) und welches die unabängige(n) Variablen\nExplorative Datenanalyse, um zu sehen, ob evtl. Dateneingabefehler vorliegen oder Datentransformationen vorgenommen werden sollten\nAuswahl und Begründung eines statistischen Verfahrens\nBestimmung des vollständigen/maximalen Models\nSelektion des/der besten Models/Modelle\nGenerieren aller Zahlen, Statistiken und Tabellen, die für eine wiss\n(Ergebnisdarstellung benötigt werden)\nFormuliert abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (ausformulierte schriftliche Zusammenfassung, mit je einem Absatz von ca. 60-100 Worten, resp. 3-8 Sätzen für den Methoden- und Ergebnisteil). D. h. alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden.\nAbzugeben sind am Ende (a) Ein lauffähiges R-Skript; (b) begründeter Lösungsweg (Kombination aus R-Code, R Output und dessen Interpretation) und (c) ausformulierter Methoden- und Ergebnisteil (für eine wiss. Arbeit).\n\nR-Skript als Download\nLoesungstext\nkommentierter Lösungsweg\n\n\nsplityield <- read.delim(\"splityield.csv\", sep = \",\", stringsAsFactors = T)\n\n\n\n\n\n# Checken der eingelesenen Daten\nsplityield\n\n\n   yield block irrigation density fertilizer\n1     90     A    control     low          N\n2     95     A    control     low          P\n3    107     A    control     low         NP\n4     92     A    control  medium          N\n5     89     A    control  medium          P\n6     92     A    control  medium         NP\n7     81     A    control    high          N\n8     92     A    control    high          P\n9     93     A    control    high         NP\n10    80     A  irrigated     low          N\n11    87     A  irrigated     low          P\n12   100     A  irrigated     low         NP\n13   121     A  irrigated  medium          N\n14   110     A  irrigated  medium          P\n15   119     A  irrigated  medium         NP\n16    78     A  irrigated    high          N\n17    98     A  irrigated    high          P\n18   122     A  irrigated    high         NP\n19    83     B    control     low          N\n20    80     B    control     low          P\n21    95     B    control     low         NP\n22    98     B    control  medium          N\n23    98     B    control  medium          P\n24   106     B    control  medium         NP\n25    74     B    control    high          N\n26    81     B    control    high          P\n27    74     B    control    high         NP\n28   102     B  irrigated     low          N\n29   109     B  irrigated     low          P\n30   105     B  irrigated     low         NP\n31    99     B  irrigated  medium          N\n32    94     B  irrigated  medium          P\n33   123     B  irrigated  medium         NP\n34   136     B  irrigated    high          N\n35   133     B  irrigated    high          P\n36   132     B  irrigated    high         NP\n37    85     C    control     low          N\n38    88     C    control     low          P\n39    88     C    control     low         NP\n40   112     C    control  medium          N\n41   104     C    control  medium          P\n42    91     C    control  medium         NP\n43    82     C    control    high          N\n44    78     C    control    high          P\n45    94     C    control    high         NP\n46    60     C  irrigated     low          N\n47   104     C  irrigated     low          P\n48   114     C  irrigated     low         NP\n49    90     C  irrigated  medium          N\n50   118     C  irrigated  medium          P\n51   113     C  irrigated  medium         NP\n52   119     C  irrigated    high          N\n53   122     C  irrigated    high          P\n54   136     C  irrigated    high         NP\n55    86     D    control     low          N\n56    78     D    control     low          P\n57    89     D    control     low         NP\n58    79     D    control  medium          N\n59    86     D    control  medium          P\n60    87     D    control  medium         NP\n61    85     D    control    high          N\n62    89     D    control    high          P\n63    83     D    control    high         NP\n64    73     D  irrigated     low          N\n65   114     D  irrigated     low          P\n66   114     D  irrigated     low         NP\n67   109     D  irrigated  medium          N\n68   131     D  irrigated  medium          P\n69   126     D  irrigated  medium         NP\n70   116     D  irrigated    high          N\n71   136     D  irrigated    high          P\n72   133     D  irrigated    high         NP\n\nMan sieht, dass das Design vollkommen balanciert ist, d.h. jede Kombination irrigation  density  fertilizer kommt genau 4x vor (in jedem der vier Blöcke A-D einmal).\n\n\nstr(splityield)\n\n\n'data.frame':   72 obs. of  5 variables:\n $ yield     : int  90 95 107 92 89 92 81 92 93 80 ...\n $ block     : Factor w/ 4 levels \"A\",\"B\",\"C\",\"D\": 1 1 1 1 1 1 1 1 1 1 ...\n $ irrigation: Factor w/ 2 levels \"control\",\"irrigated\": 1 1 1 1 1 1 1 1 1 2 ...\n $ density   : Factor w/ 3 levels \"high\",\"low\",\"medium\": 2 2 2 3 3 3 1 1 1 2 ...\n $ fertilizer: Factor w/ 3 levels \"N\",\"NP\",\"P\": 1 3 2 1 3 2 1 3 2 1 ...\n\nsummary(splityield)\n\n\n     yield        block      irrigation   density   fertilizer\n Min.   : 60.00   A:18   control  :36   high  :24   N :24     \n 1st Qu.: 86.00   B:18   irrigated:36   low   :24   NP:24     \n Median : 95.00   C:18                  medium:24   P :24     \n Mean   : 99.72   D:18                                        \n 3rd Qu.:114.00                                               \n Max.   :136.00                                               \n\nsplityield$density <- ordered(splityield$density, levels = c(\"low\", \"medium\", \"high\"))\nsplityield$density\n\n\n [1] low    low    low    medium medium medium high   high   high  \n[10] low    low    low    medium medium medium high   high   high  \n[19] low    low    low    medium medium medium high   high   high  \n[28] low    low    low    medium medium medium high   high   high  \n[37] low    low    low    medium medium medium high   high   high  \n[46] low    low    low    medium medium medium high   high   high  \n[55] low    low    low    medium medium medium high   high   high  \n[64] low    low    low    medium medium medium high   high   high  \nLevels: low < medium < high\n\nMan sieht, dass die Variable yield metrisch ist, während die vier anderen Variablen schon korrekt als kategoriale Variablen (factors) kodiert sind\n\n\n# Explorative Datenanalyse (auf Normalverteilung, Varianzhomogenität)\nboxplot(yield~fertilizer, data = splityield)\n\n\n\nboxplot(yield~irrigation, data = splityield)\n\n\n\nboxplot(yield~density, data = splityield)\n\n\n\nboxplot(yield~irrigation * density * fertilizer, data = splityield)\n\n\n\n\nDie Boxplots sind generell hinreichend symmetrisch, so dass man davon ausgehen kann, dass keine problematische Abweichung von der Normalverteilung vorliegt. Die Varianzhomogenität sieht für den Gesamtboxplot sowie für fertilizer und density bestens aus, für irrigation und für die 3-fach-Interaktion deuten sich aber gewisse Varianzheterogenitäten an, d. h. die Boxen (Interquartil-Spannen) sind deutlich unterschiedlich lang. Da das Design aber vollkommen „balanciert“ war, wie wir von oben wissen, sind selbst relativ stark divergierende Varianzen nicht besonders problematisch. Der Boxplot der Dreifachinteraktion zeigt zudem, dass grössere Varianzen (~Boxen) mal bei kleinen, mal bei grossen Mittelwerten vorkommen, womit wir bedenkenlos weitermachen können (Wenn die grossen Varianzen immer bei grossen Mittelwerten aufgetreten wären, hätten wir eine log- oder Wurzeltransformation von yield in Betracht ziehen müssen).\n\n\nboxplot(log10(yield)~irrigation * density * fertilizer, data = splityield)# bringt keine Verbesserung\n\n\n\naov.1 <- aov(yield~irrigation * density * fertilizer + Error(block/irrigation/density), data = splityield)\n\n\n\nDas schwierigste an der Analyse ist hier die Definition des Splitt-Plot ANOVA-Modells. Hier machen wir es mit der einfachsten Möglichkeit, dem aov-Befehl. Um diesen richtig zu spezifieren, muss man verstanden haben, welches der „random“-Faktor war und wie die „fixed“ factors ineinander geschachtelt waren. In diesem Fall ist block der random Faktor, in den zunächst irrigation und dann density geschachtelt sind (die unterste Ebene fertilizer muss man nicht mehr angeben, da diese in der nächsthöheren nicht repliziert ist).\n(Übrigens: das simple 3-faktorielle ANOVA-Modell aov(yield~irrigationdensityfertilizer,data=splityield) würde unterstellen, dass alle 72 subplot unabhängig von allen anderen angeordnet sind, also nicht in Blöcken. Man kann ausprobieren, wie sich das Ergebnis mit dieser Einstellung unterscheidet)\n\n\nsummary(aov.1)\n\n\n\nError: block\n          Df Sum Sq Mean Sq F value Pr(>F)\nResiduals  3  194.4   64.81               \n\nError: block:irrigation\n           Df Sum Sq Mean Sq F value Pr(>F)  \nirrigation  1   8278    8278   17.59 0.0247 *\nResiduals   3   1412     471                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: block:irrigation:density\n                   Df Sum Sq Mean Sq F value Pr(>F)  \ndensity             2   1758   879.2   3.784 0.0532 .\nirrigation:density  2   2747  1373.5   5.912 0.0163 *\nResiduals          12   2788   232.3                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: Within\n                              Df Sum Sq Mean Sq F value   Pr(>F)    \nfertilizer                     2 1977.4   988.7  11.449 0.000142 ***\nirrigation:fertilizer          2  953.4   476.7   5.520 0.008108 ** \ndensity:fertilizer             4  304.9    76.2   0.883 0.484053    \nirrigation:density:fertilizer  4  234.7    58.7   0.680 0.610667    \nResiduals                     36 3108.8    86.4                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nWir bekommen p-Werte für die drei Einzeltreatments, die drei 2-fach-Interaktionen und die 3- fach Interaktion. Keinen p-Wert gibt es dagegen für block, da dieser als „random“ Faktor spezifiziert wurde. Signifikant sind für sich genommen irrigation und fertilizer sowie die Interaktionen irrigation:density und irrigation:fertilizer.\n\n\n# Modelvereinfachung\naov.2 <- aov(yield ~ irrigation + density + fertilizer + irrigation:density + \n               irrigation:fertilizer + density:fertilizer + Error(block/irrigation/density), data = splityield)\nsummary(aov.2)\n\n\n\nError: block\n          Df Sum Sq Mean Sq F value Pr(>F)\nResiduals  3  194.4   64.81               \n\nError: block:irrigation\n           Df Sum Sq Mean Sq F value Pr(>F)  \nirrigation  1   8278    8278   17.59 0.0247 *\nResiduals   3   1412     471                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: block:irrigation:density\n                   Df Sum Sq Mean Sq F value Pr(>F)  \ndensity             2   1758   879.2   3.784 0.0532 .\nirrigation:density  2   2747  1373.5   5.912 0.0163 *\nResiduals          12   2788   232.3                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: Within\n                      Df Sum Sq Mean Sq F value   Pr(>F)    \nfertilizer             2   1977   988.7  11.828 9.21e-05 ***\nirrigation:fertilizer  2    953   476.7   5.703  0.00662 ** \ndensity:fertilizer     4    305    76.2   0.912  0.46639    \nResiduals             40   3344    83.6                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\naov.3 <- aov(yield ~ irrigation + density + fertilizer + irrigation:density + \n               irrigation:fertilizer+ Error(block/irrigation/density), data = splityield)\nsummary(aov.3)\n\n\n\nError: block\n          Df Sum Sq Mean Sq F value Pr(>F)\nResiduals  3  194.4   64.81               \n\nError: block:irrigation\n           Df Sum Sq Mean Sq F value Pr(>F)  \nirrigation  1   8278    8278   17.59 0.0247 *\nResiduals   3   1412     471                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: block:irrigation:density\n                   Df Sum Sq Mean Sq F value Pr(>F)  \ndensity             2   1758   879.2   3.784 0.0532 .\nirrigation:density  2   2747  1373.5   5.912 0.0163 *\nResiduals          12   2788   232.3                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nError: Within\n                      Df Sum Sq Mean Sq F value   Pr(>F)    \nfertilizer             2   1977   988.7  11.924 7.28e-05 ***\nirrigation:fertilizer  2    953   476.7   5.749  0.00605 ** \nResiduals             44   3648    82.9                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nJetzt muss man nur noch herausfinden, wie irrigation und fertilizer wirken und wie die Interaktionen aussehen. Bei multiplen ANOVAs macht man das am besten visuell:\n\n\n# Visualisierung der Ergebnisse\nboxplot(yield~fertilizer, data = splityield)\n\n\n\nboxplot(yield~irrigation, data = splityield)\n\n\n\ninteraction.plot(splityield$fertilizer, splityield$irrigation, splityield$yield, \n                 xlab= \"fertilizer\", ylab = \"mean of splityield\", trace.label = \"irrigation\")\n\n\n\ninteraction.plot(splityield$density, splityield$irrigation, splityield$yield, \n                 xlab= \"fertilizer\", ylab = \"mean of splityield\", trace.label = \"irrigation\")\n\n\n\n\n\n\n\n",
    "preview": "statistik/Statistik5_03_Solution_5.1/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik5_03_Solution_5.2/",
    "title": "Musterlösung Übung 5.2",
    "description": {},
    "author": [
      {
        "name": "Gian-Andrea Egeler",
        "url": {}
      }
    ],
    "date": "2021-11-22",
    "categories": [
      "Statistik5"
    ],
    "contents": "\n\nContents\nMusterlösung Übung 5.2: GLMM\nkommentierter Lösungsweg\nMethoden\nErgebnisse\n\n\n\n\n\n\nDownload R-Skript\n\nMusterlösung Übung 5.2: GLMM\n\nLese-Empfehlung Kapitel 4.3.1 von Christopher Molnar - Interessierte hier oder hier\n\nkommentierter Lösungsweg\n\n\n\n\n\ndf <- nova # kopiert originaler Datensatz\n\n# Genereiert eine Dummyvariable: Fleisch 1, kein Fleisch 0\ndf %<>%\n  # entfernt Personen die sich ein Buffet Teller gekauft\n  filter(label_content != \"Hot and Cold\") %>%\n  # ihr könnt keine Angabe vernachlässigen, sind (nur) 54 Personen\n  filter(age_group != \"keine Angaben\") %>% \n  mutate(label_content = str_replace_all(.$label_content, \n                                         c(\"Fisch|Geflügel\"),\"Fleisch\")) %>%   \n  mutate(meat = if_else(.$label_content == \"Fleisch\", 1, 0)) %>%\n  # setzt andere Reihenfolge für die Hochschulzugehörigkeit, nur für die Interpretation\n  # nützlich: neu Referenzkategorie Studierende (vorher Mitarbeitende)\n  mutate(member = factor(.$member, levels = c(\"Studierende\", \"Mitarbeitende\")))  \n\n\n# wie viele NA's hat es dirn (uns interessiert v.a. die responsevariable: meat)\nsum(is.na(df$meat)) #Amelia::missmap(df_)\n\n\n[1] 0\n\n# sieht euch die Verteilung zwischen Fleisch und  kein Fleisch an, \n# beide kategorien kommen nicht gleich häufig vor, aber nicht super tragisch\nprop.table(table(df$meat)) # gibt die prozente an\n\n\n\n        0         1 \n0.4782123 0.5217877 \n\ntable(df$meat) # gibt die absoluten werte an\n\n\n\n   0    1 \n8560 9340 \n\n# definiert das logistische Modell mit ccrs als random intercept und \n# wendet es auf den Datensatz an\n\n\n#check out ICC: https://www.datanovia.com/en/lessons/intraclass-correlation-coefficient-in-r/\n#however data needs to be wide format\n#not working yet\ndf %>% dplyr::select(ccrs, label_content) %>% tidyr::pivot_wider(names_from = \"ccrs\", values_fill = \"label_content\") -> tt\n\n\nlibrary(lme4)\n#dauert ein paar sekunden\nmod0 <- glmer(meat ~ gender + member + age_group + (1|ccrs),\n              data = df, binomial(\"logit\")) \n\n# lasst euch das Modell anzeigen: sieht so aus, als ob v.a. Geschlecht eine \n# Rolle spielt\n# wahrnmeldung kann vernachlässigt werden (aufgrund der unicode resp. \n# umlaute in den variablen)\nsummary(mod0) \n\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: meat ~ gender + member + age_group + (1 | ccrs)\n   Data: df\n\n     AIC      BIC   logLik deviance df.resid \n 22611.1  22665.6 -11298.5  22597.1    17893 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.9879 -0.8253  0.4831  0.7618  3.2980 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n ccrs   (Intercept) 1.047    1.023   \nNumber of obs: 17900, groups:  ccrs, 1427\n\nFixed effects:\n                           Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                -0.61178    0.07146  -8.561  < 2e-16 ***\ngenderM                     0.85769    0.07384  11.615  < 2e-16 ***\nmemberMitarbeitende         0.14252    0.11044   1.290  0.19690    \nage_group26 bis 34-jÃ¤hrig -0.23126    0.08914  -2.594  0.00948 ** \nage_group35 bis 49-jÃ¤hrig -0.07394    0.13687  -0.540  0.58905    \nage_group50 bis 64-jÃ¤hrig -0.01069    0.17538  -0.061  0.95138    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) gendrM mmbrMt a_26b3 a_35b4\ngenderM     -0.658                            \nmmbrMtrbtnd -0.076  0.029                     \nag_26b34-Ã¤ -0.411 -0.025 -0.353              \nag_35b49-Ã¤ -0.281  0.041 -0.663  0.467       \nag_50b64-Ã¤ -0.208  0.020 -0.598  0.393  0.517\n\n## erste Interpretation: Geschlecht (Mann) und Alter (junge Personen) scheinen den Fleischkonsum positiv zu beeinflussen + Hochschulzugehörigkeit spielt keien Rolle\n# d.h. könnte man vernachlässigen. Ich lasse aus inhaltlichen Gründen aber im Modell drin\n\n# Pseudo R^2\nlibrary(MuMIn)\nr.squaredGLMM(mod0) \n\n\n                   R2m       R2c\ntheoretical 0.03760018 0.2699647\ndelta       0.03240612 0.2326719\n\n# das marginale R^2 (r2m) gibt uns die erklärte Varianz der fixen Effekte: hier 4% (das ist sehr wenig)\n# das conditionale R^2 (r2c) gibt uns die erklärte Varianz für das ganze Modell \n# (mit fixen und variablen Effekten): hier 27% (ganz ok, aber auch nicht super mega)\n# für weitere Informationen: https://rdrr.io/cran/MuMIn/man/r.squaredGLMM.html \n\n# zusätzliche Informationen, welche für die Interpretation gut sein kann\n# berechnet den Standardfehler (mehr infos: https://www.youtube.com/watch?v=r-txC-dpI-E oder hier: https://mgimond.github.io/Stats-in-R/CI.html)\n# weitere info: https://stats.stackexchange.com/questions/26650/how-do-i-reference-a-regression-models-coefficients-standard-errors\nse <- sqrt(diag(vcov(mod0)))\n\n# zeigt eine Tabelle der Schätzer mit 95% Konfidenzintervall (KI)\n# => Faustregel: falls 0 im KI enthalten ist, dann ist der Unterschied statistisch NICHT signifikant\ntab1 <- cbind(Est = fixef(mod0), LL = fixef(mod0) - 1.96 * se,\n              UL = fixef(mod0) + 1.96 * se)\n\n# erzeugt die Odds Ratios\ntab2 <- exp(tab1)\n\n\n\nMethoden\nDie Responsevariable “Fleischkonsum” ist eine binäre Variable. Demnach wird eine multiple logistische Regression mit den Prädiktoren “Alter (Gruppen)”, “Geschlecht” und “Hochschulzugehörigkeit” gerechnet. Da in den Daten gewisse Individuen mehrmals vorkommen, wird das Individuum (Variable ccrs) als variabler Effekt in das Modell aufgenommen.\nErgebnisse\nDas Geschlecht und das Alter nehmen einen signifikanten Einfluss auf den Fleischkonsum (siehe Table 1): Männer kaufen signifikant häufiger ein fleischhaltiges Gericht als Frauen; junge Personen (15 bis 25-jährig) kaufen signifikant häufiger ein fleischhaltiges Gericht in der Mensa. Es sieht so aus, als ob die Hochschulzugehörigkeit auf den ersten Blick keinen Einfluss nimmt. Aber man müsste auch die Interaktion zwischen Geschlecht und Hochschulzugehörigkeit berücksichtigen, um ein abschliessendes Bild zu bekommen. Das kleine marginale Pseudo-R^2 zeigt auf, dass es nicht das “beste” Modell ist. Insbesondere die tiefe Varianzaufklärung für die randomisierte Variable (r2c; ccrs) scheint mit (nur) 4% sehr gering. Das sind Hinweise dafür, dass das Modell ggf. noch weitere Ebenen haben könnte (z.B. Standort Mensa).\n\nTable 1: Modellschätzer (Coefficients) mit dazugehörigem 95% Konfidenzintervall\n\nCoefficients\nLower Limit (LL)\nUppewr Limit (UL)\nIntercept\n-0.61\n-0.75\n-0.47\nMänner\n0.86\n0.71\n1.00\nMitarbeitende\n0.14\n-0.07\n0.36\n26 bis 34-jährig\n-0.23\n-0.41\n-0.06\n35 bis 49-jährig\n-0.07\n-0.34\n0.19\n50 bis 64-jährig\n-0.01\n-0.35\n0.33\n\nDie Chance, dass Männer ein fleischhaltiges Gericht kaufen ist 2.36mal (+136%) höher als bei Frauen (siehe Table 2). Die Chance, dass 26 bis 34-jährige Personen ein fleischhaltiges Gericht kaufen ist kleiner (-21%) als bei den 15 bis 25-jährigen Personen.\n\nTable 2: Odds Ratio (OR) mit dazugehörigem 95% Konfidenzintervall\n\nOR\nLower Limit (LL)\nUppewr Limit (UL)\nIntercept\n0.54\n0.47\n0.62\nMänner\n2.36\n2.04\n2.72\nMitarbeitende\n1.15\n0.93\n1.43\n26 bis 34-jährig\n0.79\n0.67\n0.95\n35 bis 49-jährig\n0.93\n0.71\n1.21\n50 bis 64-jährig\n0.99\n0.70\n1.40\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik6_01_Demo/",
    "title": "Demo Statistik 6",
    "description": {},
    "author": [
      {
        "name": "Jürgen Dengler",
        "url": {}
      }
    ],
    "date": "2021-11-16",
    "categories": [
      "Statistik6"
    ],
    "contents": "\n\n\n\nOrdinationen I\nDemoscript als Download\nPCA\n\n\nif(!require(labdsv)){install.packages(\"labdsv\")}\nlibrary(labdsv)\n\n# Für Ordinationen benötigen wir Matrizen, nicht Data.frames\n# Generieren von Daten\nraw <- matrix(c(1, 2, 2.5, 2.5, 1, 0.5, 0, 1, 2, 4, 3, 1), nrow = 6)\ncolnames(raw) <- c(\"spec.1\", \"spec.2\")\nrownames(raw) <- c(\"r1\", \"r2\", \"r3\", \"r4\", \"r5\", \"r6\")\nraw\n\n\n   spec.1 spec.2\nr1    1.0      0\nr2    2.0      1\nr3    2.5      2\nr4    2.5      4\nr5    1.0      3\nr6    0.5      1\n\n# Originale Daten im zweidimensionalen Raum\nx1 <- raw[,1]\ny1 <- raw[,2]\nz <- c(rep(1:6))\n\n\n# Plot Abhängigkeit der Arten vom Umweltgradienten\nplot(c(x1, y1)~c(z, z), type = \"n\", axes = T, bty = \"l\", \n     las = 1, xlim = c(1,6), ylim = c(0,5),\n     xlab = \"Umweltgradient\", ylab = \"Deckung der Arten\")\npoints(x1~z, pch = 21, type = \"b\")\npoints(y1~z, pch = 16, type = \"b\")\n\n\n\n# zentrierte Daten\ncent <- scale(raw, scale = F)\nx2 <- cent[,1]\ny2 <- cent[,2]\n\n# rotierte Daten\no.pca <- pca(raw)\nx3 <- o.pca$scores[,1]\ny3 <- o.pca$scores[,2]\n\n# Visualisierung der Schritte im Ordinationsraum\nplot(c(y1, y2, y3)~c(x1, x2, x3), type = \"n\", axes = T, bty = \"l\", las = 1,\n     xlim = c(-4, 4), ylim = c(-4, 4), xlab = \"Art 1\", ylab=  \"Art 2\")\npoints(y1~x1, pch = 21, type = \"b\", col = \"green\", lwd = 2)\npoints(y2~x2, pch = 16, type = \"b\",col = \"red\", lwd = 2)\npoints(y3~x3, pch = 17, type = \"b\", col = \"blue\", lwd = 2)\n\n\n\n# Durchführung der PCA\no.pca <- pca(raw)\n\n# Koordinaten im Ordinationsraum\no.pca$scores\n\n\n          PC1         PC2\nr1 -1.9216223 -0.09357697\nr2 -0.6353776 -0.68143293\nr3  0.4762699 -0.80076373\nr4  2.3503705 -0.10237502\nr5  0.8895287  0.95400610\nr6 -1.1591692  0.72414255\n\n# Korrelationen der Variablen mit den Ordinationsachsen\no.pca$loadings\n\n\n             PC1        PC2\nspec.1 0.3491944 -0.9370503\nspec.2 0.9370503  0.3491944\n\n#Erklärte Varianz der Achsen\nE <- o.pca$sdev^2 / o.pca$totdev * 100\nE\n\n\n[1] 82.40009 17.59991\n\n# mit prcomp\npca.2 <- prcomp(raw, scale = F)\nsummary(pca.2)\n\n\nImportance of components:\n                         PC1    PC2\nStandard deviation     1.548 0.7154\nProportion of Variance 0.824 0.1760\nCumulative Proportion  0.824 1.0000\n\nplot(pca.2)\n\n\n\nbiplot(pca.2)\n\n\n\n# mit vegan\nif(!require(vegan)){install.packages(\"vegan\")}\nlibrary(\"vegan\")\n# Die Funktion rda führt ein PCA aus an wenn nicht Artdaten UND Umweltdaten definiert werden\npca.3 <- rda(raw, scale = FALSE)\n#scores(pca.3, display = c(\"sites\"))\n#scores(pca.3, display = c(\"species\"))\nsummary(pca.3, axes = 0)\n\n\n\nCall:\nrda(X = raw, scale = FALSE) \n\nPartitioning of variance:\n              Inertia Proportion\nTotal           2.908          1\nUnconstrained   2.908          1\n\nEigenvalues, and their contribution to the variance \n\nImportance of components:\n                        PC1    PC2\nEigenvalue            2.396 0.5119\nProportion Explained  0.824 0.1760\nCumulative Proportion 0.824 1.0000\n\nScaling 2 for species and site scores\n* Species are scaled proportional to eigenvalues\n* Sites are unscaled: weighted dispersion equal on all dimensions\n* General scaling constant of scores:  \n\nbiplot(pca.3)\n\n\n\n# Mit Beispieldaten aus Wildi\nif(!require(dave)){install.packages(\"dave\")}\nlibrary(dave)\ndata(sveg)\n\n\n\n\n\nstr(sveg)\nsummary(sveg)\nnames(sveg)\n\n\n\n\n\n# PCA: Deckungen Wurzeltransformiert, cor=T erzwingt Nutzung der Korrelationsmatrix\npca.5 <- pca(sveg^0.25, cor = T)\n\n\n\n\n\n# Koordinaten im Ordinationsraum\npca.5$scores\n\n# Korrelationen der Variablen mit den Ordinationsachsen\npca.5$loadings\n\n\n\n\n\n# Erklärte Varianz der Achsen in Prozent (sdev ist die Wurzel daraus)\nE <- pca.5$sdev^2 / pca.5$totdev * 100\nE\n\n\n [1] 2.061885e+01 8.098205e+00 6.070537e+00 3.666650e+00 3.322363e+00\n [6] 3.128942e+00 3.003875e+00 2.634636e+00 2.605558e+00 2.449637e+00\n[11] 2.339344e+00 2.265430e+00 2.116464e+00 2.046578e+00 1.969912e+00\n[16] 1.871020e+00 1.777063e+00 1.693483e+00 1.524015e+00 1.503332e+00\n[21] 1.434245e+00 1.378271e+00 1.329404e+00 1.291336e+00 1.251895e+00\n[26] 1.186157e+00 1.109340e+00 1.068661e+00 1.044385e+00 9.891552e-01\n[31] 9.764586e-01 8.869747e-01 8.451212e-01 8.049318e-01 7.603242e-01\n[36] 7.311274e-01 6.945830e-01 6.339064e-01 6.063542e-01 5.502527e-01\n[41] 5.411059e-01 4.956931e-01 4.795188e-01 4.601244e-01 3.936176e-01\n[46] 3.477631e-01 3.402128e-01 3.165971e-01 2.951856e-01 2.728882e-01\n[51] 2.635725e-01 2.233500e-01 2.125542e-01 1.989449e-01 1.681852e-01\n[56] 1.555571e-01 1.485298e-01 1.271079e-01 9.164615e-02 7.880113e-02\n[61] 5.913306e-02 5.113452e-02 4.066351e-30\n\nE[1:5]\n\n\n[1] 20.618848  8.098205  6.070537  3.666650  3.322363\n\n# PCA-Plot der Lage der Beobachtungen im Ordinationsraum\nplot(pca.5$scores[,1], pca.5$scores[,2], type = \"n\", asp = 1, xlab = \"PC1\", ylab = \"PC2\")\npoints(pca.5$scores[,1], pca.5$scores[,2], pch = 18)\n\n\n\n# Subjektive Auswahl von Arten zur Darstellung\nsel.sp <- c(3, 11, 23, 39, 46, 72, 77, 96)\nsnames <- names(sveg[,sel.sp])\nsnames\n\n\n[1] \"Vaccinium.oxycoccos\" \"Carex.echinata\"      \"Arnica.montana\"     \n[4] \"Carex.pulicaris\"     \"Sphagnum.recurvum\"   \"Viola.palustris\"    \n[7] \"Galium.uliginosum\"   \"Stachys.officinalis\"\n\n# PCA-Plot der Korrelationen der Variablen (hier Arten) mit den Achsen (h)\nx <- pca.5$loadings[,1]\ny <- pca.5$loadings[,2]\nplot(x, y, type = \"n\", asp = 1)\narrows(0,0, x[sel.sp], y[sel.sp], length = 0.08)\ntext(x[sel.sp], y[sel.sp], snames, pos = 1, cex = 0.6)\n\n\n\n# Mit vegan\npca.6 <- rda(sveg^0.25, scale = TRUE)\n# Erklärte Varianz der Achsen\nsummary(pca.6, axes = 0)\n\n\n\nCall:\nrda(X = sveg^0.25, scale = TRUE) \n\nPartitioning of correlations:\n              Inertia Proportion\nTotal             119          1\nUnconstrained     119          1\n\nEigenvalues, and their contribution to the correlations \n\nImportance of components:\n                          PC1     PC2     PC3     PC4     PC5     PC6\nEigenvalue            24.5364 9.63686 7.22394 4.36331 3.95361 3.72344\nProportion Explained   0.2062 0.08098 0.06071 0.03667 0.03322 0.03129\nCumulative Proportion  0.2062 0.28717 0.34788 0.38454 0.41777 0.44906\n                          PC7     PC8     PC9   PC10    PC11    PC12\nEigenvalue            3.57461 3.13522 3.10061 2.9151 2.78382 2.69586\nProportion Explained  0.03004 0.02635 0.02606 0.0245 0.02339 0.02265\nCumulative Proportion 0.47909 0.50544 0.53150 0.5560 0.57939 0.60204\n                         PC13    PC14   PC15    PC16    PC17    PC18\nEigenvalue            2.51859 2.43543 2.3442 2.22651 2.11470 2.01524\nProportion Explained  0.02116 0.02047 0.0197 0.01871 0.01777 0.01693\nCumulative Proportion 0.62320 0.64367 0.6634 0.68208 0.69985 0.71679\n                         PC19    PC20    PC21    PC22    PC23    PC24\nEigenvalue            1.81358 1.78896 1.70675 1.64014 1.58199 1.53669\nProportion Explained  0.01524 0.01503 0.01434 0.01378 0.01329 0.01291\nCumulative Proportion 0.73203 0.74706 0.76140 0.77518 0.78848 0.80139\n                         PC25    PC26    PC27    PC28    PC29\nEigenvalue            1.48976 1.41153 1.32011 1.27171 1.24282\nProportion Explained  0.01252 0.01186 0.01109 0.01069 0.01044\nCumulative Proportion 0.81391 0.82577 0.83687 0.84755 0.85800\n                          PC30     PC31    PC32     PC33     PC34\nEigenvalue            1.177095 1.161986 1.05550 1.005694 0.957869\nProportion Explained  0.009892 0.009765 0.00887 0.008451 0.008049\nCumulative Proportion 0.867887 0.877652 0.88652 0.894973 0.903022\n                          PC35     PC36     PC37     PC38     PC39\nEigenvalue            0.904786 0.870042 0.826554 0.754349 0.721562\nProportion Explained  0.007603 0.007311 0.006946 0.006339 0.006064\nCumulative Proportion 0.910626 0.917937 0.924883 0.931222 0.937285\n                          PC40     PC41     PC42     PC43     PC44\nEigenvalue            0.654801 0.643916 0.589875 0.570627 0.547548\nProportion Explained  0.005503 0.005411 0.004957 0.004795 0.004601\nCumulative Proportion 0.942788 0.948199 0.953156 0.957951 0.962552\n                          PC45     PC46     PC47     PC48     PC49\nEigenvalue            0.468405 0.413838 0.404853 0.376750 0.351271\nProportion Explained  0.003936 0.003478 0.003402 0.003166 0.002952\nCumulative Proportion 0.966488 0.969966 0.973368 0.976534 0.979486\n                          PC50     PC51     PC52     PC53     PC54\nEigenvalue            0.324737 0.313651 0.265787 0.252939 0.236744\nProportion Explained  0.002729 0.002636 0.002234 0.002126 0.001989\nCumulative Proportion 0.982215 0.984851 0.987084 0.989210 0.991199\n                          PC55     PC56     PC57     PC58      PC59\nEigenvalue            0.200140 0.185113 0.176750 0.151258 0.1090589\nProportion Explained  0.001682 0.001556 0.001485 0.001271 0.0009165\nCumulative Proportion 0.992881 0.994436 0.995922 0.997193 0.9981093\n                          PC60      PC61      PC62\nEigenvalue            0.093773 0.0703683 0.0608501\nProportion Explained  0.000788 0.0005913 0.0005113\nCumulative Proportion 0.998897 0.9994887 1.0000000\n\nScaling 2 for species and site scores\n* Species are scaled proportional to eigenvalues\n* Sites are unscaled: weighted dispersion equal on all dimensions\n* General scaling constant of scores:  \n\n# PCA-Plot der Lage der Beobachtungen im Ordinationsraum\nbiplot(pca.6, display = \"sites\", type = \"points\", scaling = 1)\n\n\n\n# Subjektive Auswahl von Arten zur Darstellung\nsel.sp <- c(3, 11, 23, 39, 46, 72, 77, 96)\nsnames <- names(sveg[,sel.sp])\nsnames\n\n\n[1] \"Vaccinium.oxycoccos\" \"Carex.echinata\"      \"Arnica.montana\"     \n[4] \"Carex.pulicaris\"     \"Sphagnum.recurvum\"   \"Viola.palustris\"    \n[7] \"Galium.uliginosum\"   \"Stachys.officinalis\"\n\n# PCA-Plot der Korrelationen der Variablen (hier Arten) mit den Achsen (h)\nscores <- scores(pca.6, display = \"species\")\nx <- scores[,1]\ny <- scores[,2]\nplot(x, y, type = \"n\", asp = 1)\narrows(0,0, x[sel.sp], y[sel.sp], length = 0.08)\ntext(x[sel.sp], y[sel.sp], snames, pos = 1, cex = 0.6)\n\n\n\n# Mit angepassten Achsen\nplot(x, y, type = \"n\", asp = 1, xlim = c(-1, 1), ylim = c(-0.6, 0.6))\narrows(0,0, x[sel.sp], y[sel.sp], length = 0.08)\ntext(x[sel.sp], y[sel.sp], snames, pos = 1, cex = 0.6)\n\n\n\n\nCA\n\n\nca.1 <- cca(sveg^0.5)\n# Arten (o) und Communities (+) plotten\nplot(ca.1)\n\n\n\n# Nur Arten plotten\nplot(ca.1, display = \"species\", type = \"points\")\n\n\n\n# Anteilige Varianz, die durch die ersten beiden Achsen erklärt wird\nca.1$CA$eig[1:2] / sum(ca.1$CA$eig)\n\n\n      CA1       CA2 \n0.1938717 0.0784178 \n\nsummary(eigenvals(ca.1))\n\n\nImportance of components:\n                         CA1     CA2     CA3     CA4     CA5     CA6\nEigenvalue            0.4248 0.17182 0.12995 0.09102 0.07954 0.07274\nProportion Explained  0.1939 0.07842 0.05931 0.04154 0.03630 0.03320\nCumulative Proportion 0.1939 0.27229 0.33160 0.37314 0.40944 0.44264\n                          CA7     CA8     CA9    CA10    CA11    CA12\nEigenvalue            0.06705 0.06245 0.05811 0.05348 0.05261 0.05133\nProportion Explained  0.03060 0.02850 0.02652 0.02441 0.02401 0.02343\nCumulative Proportion 0.47324 0.50174 0.52826 0.55267 0.57668 0.60010\n                         CA13   CA14    CA15    CA16    CA17    CA18\nEigenvalue            0.04868 0.0480 0.04421 0.04279 0.03913 0.03752\nProportion Explained  0.02222 0.0219 0.02018 0.01953 0.01786 0.01712\nCumulative Proportion 0.62232 0.6442 0.66440 0.68393 0.70179 0.71892\n                         CA19    CA20    CA21    CA22    CA23    CA24\nEigenvalue            0.03699 0.03412 0.03309 0.03253 0.03033 0.02963\nProportion Explained  0.01688 0.01557 0.01510 0.01485 0.01384 0.01352\nCumulative Proportion 0.73580 0.75137 0.76647 0.78132 0.79516 0.80869\n                         CA25    CA26    CA27    CA28    CA29\nEigenvalue            0.02718 0.02621 0.02486 0.02372 0.02262\nProportion Explained  0.01241 0.01196 0.01135 0.01083 0.01032\nCumulative Proportion 0.82109 0.83305 0.84440 0.85523 0.86555\n                          CA30     CA31     CA32     CA33     CA34\nEigenvalue            0.021397 0.020274 0.018805 0.018216 0.017737\nProportion Explained  0.009765 0.009253 0.008582 0.008314 0.008095\nCumulative Proportion 0.875318 0.884571 0.893153 0.901467 0.909561\n                          CA35    CA36     CA37     CA38     CA39\nEigenvalue            0.016855 0.01422 0.014044 0.013002 0.011367\nProportion Explained  0.007693 0.00649 0.006409 0.005934 0.005188\nCumulative Proportion 0.917254 0.92374 0.930153 0.936087 0.941275\n                          CA40     CA41     CA42     CA43     CA44\nEigenvalue            0.011185 0.010417 0.010172 0.009513 0.009183\nProportion Explained  0.005105 0.004754 0.004643 0.004342 0.004191\nCumulative Proportion 0.946379 0.951133 0.955776 0.960118 0.964308\n                          CA45     CA46     CA47     CA48     CA49\nEigenvalue            0.008162 0.007993 0.006900 0.006684 0.006108\nProportion Explained  0.003725 0.003648 0.003149 0.003051 0.002788\nCumulative Proportion 0.968033 0.971681 0.974830 0.977881 0.980668\n                          CA50    CA51     CA52     CA53     CA54\nEigenvalue            0.005493 0.00515 0.004995 0.004426 0.004011\nProportion Explained  0.002507 0.00235 0.002279 0.002020 0.001830\nCumulative Proportion 0.983176 0.98553 0.987805 0.989825 0.991656\n                          CA55     CA56     CA57     CA58      CA59\nEigenvalue            0.003517 0.003455 0.003059 0.002279 0.0019296\nProportion Explained  0.001605 0.001577 0.001396 0.001040 0.0008807\nCumulative Proportion 0.993261 0.994837 0.996233 0.997274 0.9981544\n                           CA60      CA61      CA62\nEigenvalue            0.0017784 0.0011904 0.0010752\nProportion Explained  0.0008116 0.0005433 0.0004907\nCumulative Proportion 0.9989660 0.9995093 1.0000000\n\nDCA\n\n\nlibrary(vegan)\ndca.1 <- decorana(sveg, mk = 10)\nplot(dca.1, display = \"sites\", type = \"point\")\n\n\n\ndca.2 <- decorana(sveg, mk = 100)\nplot(dca.2, display = \"sites\", type = \"point\")\n\n\n\n\nNMDS\n\n\n# Distanzmatrix als Start erzeugen\nmde <- vegdist(sveg, method = \"euclidean\")\n\n# Alternative mit einem für Vegetationsdaten häufig verwendeten Dissimilarity-index\nmde <- vegdist(sveg, method = \"bray\")\n\n#Z wei verschiedene NMDS-Methoden\nif(!require(MASS)){install.packages(\"MASS\")}\nlibrary(MASS)\nset.seed(1) # macht man, wenn man bei einer Wiederholung exakt die gleichen Ergebnisse will\nimds <- isoMDS(mde, k = 2)\n\n\ninitial  value 16.524491 \niter   5 value 12.518681\niter  10 value 12.025808\niter  10 value 12.020751\niter  10 value 12.020751\nfinal  value 12.020751 \nconverged\n\nset.seed(1)\nmmds <- metaMDS(mde, k = 2)\n\n\nRun 0 stress 0.1179909 \nRun 1 stress 0.1179909 \n... Procrustes: rmse 1.11122e-05  max resid 4.697213e-05 \n... Similar to previous best\nRun 2 stress 0.170918 \nRun 3 stress 0.1529993 \nRun 4 stress 0.1179909 \n... Procrustes: rmse 2.021269e-06  max resid 1.184555e-05 \n... Similar to previous best\nRun 5 stress 0.1252011 \nRun 6 stress 0.1583424 \nRun 7 stress 0.1181212 \n... Procrustes: rmse 0.006525662  max resid 0.04396629 \nRun 8 stress 0.1596312 \nRun 9 stress 0.1630026 \nRun 10 stress 0.1179909 \n... New best solution\n... Procrustes: rmse 3.475822e-06  max resid 2.360888e-05 \n... Similar to previous best\nRun 11 stress 0.1538119 \nRun 12 stress 0.1252011 \nRun 13 stress 0.1500845 \nRun 14 stress 0.1251634 \nRun 15 stress 0.1251634 \nRun 16 stress 0.1179909 \n... Procrustes: rmse 5.655652e-06  max resid 1.960818e-05 \n... Similar to previous best\nRun 17 stress 0.1179909 \n... Procrustes: rmse 7.036898e-06  max resid 2.755273e-05 \n... Similar to previous best\nRun 18 stress 0.1179909 \n... Procrustes: rmse 1.0129e-05  max resid 3.793497e-05 \n... Similar to previous best\nRun 19 stress 0.1251572 \nRun 20 stress 0.1179909 \n... Procrustes: rmse 5.011736e-06  max resid 2.261906e-05 \n... Similar to previous best\n*** Solution reached\n\nplot(imds$points)\n\n\n\nplot(mmds$points)\n\n\n\n#Stress = S² = Abweichung der zweidimensionalen NMDS-Lösung von der originalen Distanzmatrix\nstressplot(imds, mde)\n\n\n\nstressplot(mmds, mde)\n\n\n\n\n\n\n\n",
    "preview": "statistik/Statistik6_01_Demo/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik6_02_Assigment/",
    "title": "Uebung Statistik 6",
    "description": {},
    "author": [],
    "date": "2021-11-11",
    "categories": [
      "Statistik6"
    ],
    "contents": "\nÜbung 6.1: PCA (naturwissenschaftlich)\nDatensatz Doubs.RData\nLädt den Datensatz Doubs.RData mit dem folgenden Befehl ins R: load(“Doubs.RData”)\nDie Umweltvariablen findet ihr im data.frame env die Abundanzen im data.frame spe. Im data.frame fishtrait findet ihr die Vollständigen Namen der Fische\nDer Datensatz enthält Daten zum Vorkommen von Fischarten und den zugehörigen Umweltvariablen im Fluss Doubs (Jura). Es gibt 30 Probestellen (sites), an denen jeweils die Abundanzen von 27 Fischarten (auf einer Skalen von 0 bis 5) sowie 11 Umweltvariablen erhoben wurden:\ndfs = Distance from source (km) ele = Elevation (m a.s.l.) slo = Slope (‰) dis = Mean annual discharge (m3 s-1) pH = pH of water har = Hardness (Ca concentration) (mg L-1) pho = Phosphate concentration (mg L-1) nit = Nitrate concentration (mg L-1) amm = Ammonium concentration (mg L-1) oxy = Dissolved oxygen (mg L-1) bod = Biological oxygen demand (mg L-1)\nEure Aufgabe ist nun, in einem ersten Schritt eine PCA für die 11 Umweltvariablen zu rechnen. Da die einzelnen Variablen auf ganz unterschiedlichen Skalen gemessen wurden, ist dazu eine Standardisierung nötig (pca mit der Funktion rda, scale=TRUE). Überlegt, wie viele Achsen wichtig sind und für was sie jeweils stehen.\nIn einem zweiten Schritt sollen dann die vollständig unkorrelierten PCA-Achsen als Prädiktoren einer multiplen Regression zur Erklärung der Fischartenzahl (Anzahl kann z.B. kann mit dem Befehl specnumber(spe) ermittel werden) verwendet werden (wahlweise lm oder glm). Gebt das minimal adäquate Modell an und interpretiert dieses (wahlweise im frequentist oder information theoretician approach). (Wer noch mehr probieren möchte, kann zum Vergleich noch eine multiple Regression mit den Originaldaten rechnen).\n\n\n\n",
    "preview": {},
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik6_03_Solution/",
    "title": "Muserlösung Übung 6",
    "description": {},
    "author": [],
    "date": "2021-11-25",
    "categories": [
      "Statistik6"
    ],
    "contents": "\n\n\n\nR-Skript als Download\nLoesungstext\n\n\nload(\"Doubs.RData\")\nsummary(env)\n\n\n      dfs              ele             slo              dis       \n Min.   :  0.30   Min.   :172.0   Min.   : 0.200   Min.   : 0.84  \n 1st Qu.: 54.45   1st Qu.:248.0   1st Qu.: 0.525   1st Qu.: 4.20  \n Median :175.20   Median :395.0   Median : 1.200   Median :22.10  \n Mean   :188.23   Mean   :481.6   Mean   : 3.497   Mean   :22.20  \n 3rd Qu.:301.73   3rd Qu.:782.0   3rd Qu.: 2.875   3rd Qu.:28.57  \n Max.   :453.00   Max.   :934.0   Max.   :48.000   Max.   :69.00  \n       pH             har              pho              nit       \n Min.   :7.700   Min.   : 40.00   Min.   :0.0100   Min.   :0.150  \n 1st Qu.:7.925   1st Qu.: 84.25   1st Qu.:0.1250   1st Qu.:0.505  \n Median :8.000   Median : 89.00   Median :0.2850   Median :1.600  \n Mean   :8.050   Mean   : 86.10   Mean   :0.5577   Mean   :1.654  \n 3rd Qu.:8.100   3rd Qu.: 96.75   3rd Qu.:0.5600   3rd Qu.:2.425  \n Max.   :8.600   Max.   :110.00   Max.   :4.2200   Max.   :6.200  \n      amm              oxy              bod        \n Min.   :0.0000   Min.   : 4.100   Min.   : 1.300  \n 1st Qu.:0.0000   1st Qu.: 8.025   1st Qu.: 2.725  \n Median :0.1000   Median :10.200   Median : 4.150  \n Mean   :0.2093   Mean   : 9.390   Mean   : 5.117  \n 3rd Qu.:0.2000   3rd Qu.:10.900   3rd Qu.: 5.275  \n Max.   :1.8000   Max.   :12.400   Max.   :16.700  \n\nsummary(spe)\n\n\n      Cogo           Satr           Phph            Babl      \n Min.   :0.00   Min.   :0.00   Min.   :0.000   Min.   :0.000  \n 1st Qu.:0.00   1st Qu.:0.00   1st Qu.:0.000   1st Qu.:1.000  \n Median :0.00   Median :1.00   Median :3.000   Median :2.000  \n Mean   :0.50   Mean   :1.90   Mean   :2.267   Mean   :2.433  \n 3rd Qu.:0.75   3rd Qu.:3.75   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :3.00   Max.   :5.00   Max.   :5.000   Max.   :5.000  \n      Thth           Teso             Chna          Pato       \n Min.   :0.00   Min.   :0.0000   Min.   :0.0   Min.   :0.0000  \n 1st Qu.:0.00   1st Qu.:0.0000   1st Qu.:0.0   1st Qu.:0.0000  \n Median :0.00   Median :0.0000   Median :0.0   Median :0.0000  \n Mean   :0.50   Mean   :0.6333   Mean   :0.6   Mean   :0.8667  \n 3rd Qu.:0.75   3rd Qu.:0.7500   3rd Qu.:1.0   3rd Qu.:2.0000  \n Max.   :4.00   Max.   :5.0000   Max.   :3.0   Max.   :4.0000  \n      Lele            Sqce            Baba            Albi    \n Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.0  \n 1st Qu.:0.000   1st Qu.:1.000   1st Qu.:0.000   1st Qu.:0.0  \n Median :1.000   Median :2.000   Median :0.000   Median :0.0  \n Mean   :1.433   Mean   :1.867   Mean   :1.433   Mean   :0.9  \n 3rd Qu.:2.000   3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:1.0  \n Max.   :5.000   Max.   :5.000   Max.   :5.000   Max.   :5.0  \n      Gogo            Eslu            Pefl          Rham    \n Min.   :0.000   Min.   :0.000   Min.   :0.0   Min.   :0.0  \n 1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.0   1st Qu.:0.0  \n Median :1.000   Median :1.000   Median :0.5   Median :0.0  \n Mean   :1.833   Mean   :1.333   Mean   :1.2   Mean   :1.1  \n 3rd Qu.:3.750   3rd Qu.:2.000   3rd Qu.:2.0   3rd Qu.:2.0  \n Max.   :5.000   Max.   :5.000   Max.   :5.0   Max.   :5.0  \n      Legi             Scer          Cyca             Titi    \n Min.   :0.0000   Min.   :0.0   Min.   :0.0000   Min.   :0.0  \n 1st Qu.:0.0000   1st Qu.:0.0   1st Qu.:0.0000   1st Qu.:0.0  \n Median :0.0000   Median :0.0   Median :0.0000   Median :1.0  \n Mean   :0.9667   Mean   :0.7   Mean   :0.8333   Mean   :1.5  \n 3rd Qu.:1.7500   3rd Qu.:1.0   3rd Qu.:1.0000   3rd Qu.:3.0  \n Max.   :5.0000   Max.   :5.0   Max.   :5.0000   Max.   :5.0  \n      Abbr             Icme          Gyce            Ruru    \n Min.   :0.0000   Min.   :0.0   Min.   :0.000   Min.   :0.0  \n 1st Qu.:0.0000   1st Qu.:0.0   1st Qu.:0.000   1st Qu.:0.0  \n Median :0.0000   Median :0.0   Median :0.000   Median :1.0  \n Mean   :0.8667   Mean   :0.6   Mean   :1.267   Mean   :2.1  \n 3rd Qu.:1.0000   3rd Qu.:0.0   3rd Qu.:2.000   3rd Qu.:5.0  \n Max.   :5.0000   Max.   :5.0   Max.   :5.000   Max.   :5.0  \n      Blbj            Alal          Anan     \n Min.   :0.000   Min.   :0.0   Min.   :0.00  \n 1st Qu.:0.000   1st Qu.:0.0   1st Qu.:0.00  \n Median :0.000   Median :0.0   Median :0.00  \n Mean   :1.033   Mean   :1.9   Mean   :0.90  \n 3rd Qu.:1.750   3rd Qu.:5.0   3rd Qu.:1.75  \n Max.   :5.000   Max.   :5.0   Max.   :5.00  \n\n# Die Dataframes env und spe enthalten die Umwelt- respective die Artdaten\n\nif(!require(vegan)){install.packages(\"vegan\")}\nlibrary(\"vegan\")\n\n\n\nDie PCA wird im Package vegan mit dem Befehl rda ausgeführt, wobei in diesem scale = TRUE gesetzt werden muss, da die Umweltdaten mit ganz unterschiedlichen Einheiten und Wertebereichen daherkommen\n\n\nenv.pca <- rda(env, scale = TRUE)\nenv.pca\n\n\nCall: rda(X = env, scale = TRUE)\n\n              Inertia Rank\nTotal              11     \nUnconstrained      11   11\nInertia is correlations \n\nEigenvalues for unconstrained axes:\n  PC1   PC2   PC3   PC4   PC5   PC6   PC7   PC8   PC9  PC10  PC11 \n5.969 2.164 1.065 0.739 0.400 0.336 0.173 0.108 0.024 0.017 0.006 \n\n# In env.pca sieht man, dass es bei 11 Umweltvariablen logischerweise 11 orthogonale Principle Components gibt\n\nsummary(env.pca, axes = 0)\n\n\n\nCall:\nrda(X = env, scale = TRUE) \n\nPartitioning of correlations:\n              Inertia Proportion\nTotal              11          1\nUnconstrained      11          1\n\nEigenvalues, and their contribution to the correlations \n\nImportance of components:\n                         PC1    PC2     PC3     PC4     PC5     PC6\nEigenvalue            5.9687 2.1639 1.06517 0.73875 0.40019 0.33563\nProportion Explained  0.5426 0.1967 0.09683 0.06716 0.03638 0.03051\nCumulative Proportion 0.5426 0.7393 0.83616 0.90332 0.93970 0.97022\n                          PC7      PC8      PC9     PC10     PC11\nEigenvalue            0.17263 0.108228 0.023701 0.017083 0.005983\nProportion Explained  0.01569 0.009839 0.002155 0.001553 0.000544\nCumulative Proportion 0.98591 0.995748 0.997903 0.999456 1.000000\n\nScaling 2 for species and site scores\n* Species are scaled proportional to eigenvalues\n* Sites are unscaled: weighted dispersion equal on all dimensions\n* General scaling constant of scores:  \n\n# Hier sieht man auch die Übersetzung der Eigenvalues in erklärte Varianzen der einzelnen Principle Components\n\nsummary(env.pca)\n\n\n\nCall:\nrda(X = env, scale = TRUE) \n\nPartitioning of correlations:\n              Inertia Proportion\nTotal              11          1\nUnconstrained      11          1\n\nEigenvalues, and their contribution to the correlations \n\nImportance of components:\n                         PC1    PC2     PC3     PC4     PC5     PC6\nEigenvalue            5.9687 2.1639 1.06517 0.73875 0.40019 0.33563\nProportion Explained  0.5426 0.1967 0.09683 0.06716 0.03638 0.03051\nCumulative Proportion 0.5426 0.7393 0.83616 0.90332 0.93970 0.97022\n                          PC7      PC8      PC9     PC10     PC11\nEigenvalue            0.17263 0.108228 0.023701 0.017083 0.005983\nProportion Explained  0.01569 0.009839 0.002155 0.001553 0.000544\nCumulative Proportion 0.98591 0.995748 0.997903 0.999456 1.000000\n\nScaling 2 for species and site scores\n* Species are scaled proportional to eigenvalues\n* Sites are unscaled: weighted dispersion equal on all dimensions\n* General scaling constant of scores:  4.226177 \n\n\nSpecies scores\n\n         PC1     PC2      PC3      PC4      PC5      PC6\ndfs  1.08657  0.5342 -0.27333 -0.13477  0.07336 -0.22566\nele -1.04396 -0.6148  0.20712  0.12854  0.14610 -0.02111\nslo -0.57703 -0.4893 -0.63490 -0.71684  0.33349  0.11782\ndis  0.95843  0.6608 -0.32456 -0.16183  0.11542 -0.13935\npH  -0.06364  0.4629  1.01317 -0.58606  0.17094 -0.07360\nhar  0.90118  0.5850  0.06449  0.25696  0.30995  0.53390\npho  1.05821 -0.6014  0.13866 -0.17883 -0.11125  0.13751\nnit  1.15013 -0.1005 -0.05167 -0.24537 -0.35105 -0.02145\namm  1.00679 -0.6969  0.14077 -0.14684 -0.19200  0.11904\noxy -0.97459  0.4991 -0.09017 -0.31040 -0.38066  0.36500\nbod  0.97315 -0.7148  0.15145  0.07193  0.23633  0.05540\n\n\nSite scores (weighted sums of species scores)\n\n        PC1      PC2      PC3      PC4       PC5       PC6\n1  -1.41274 -1.40098 -2.03484 -2.67759  1.117150  0.184951\n2  -1.03725 -0.77955  0.24400  0.25635 -1.192043 -1.849810\n3  -0.94507 -0.46765  1.25042 -0.49330 -0.234194 -1.319198\n4  -0.87371 -0.26988  0.19304  0.51979 -0.494639  0.116092\n5  -0.42088 -0.66944  0.83191  0.71729  0.867751  0.112219\n6  -0.77224 -0.72067 -0.07357  0.77902 -0.386130 -0.654273\n7  -0.77466 -0.08103  0.39630  0.19224  0.416470  1.026304\n8  -0.28840 -0.60589  0.83822  1.01440  1.707316  0.295861\n9  -0.28305 -0.47710  0.39908  1.13075  0.882098  0.002961\n10 -0.48714 -0.41860 -1.27555  0.90267  0.013704  0.542270\n11 -0.26940  0.45384  0.09119 -0.15127 -0.233814  1.157483\n12 -0.43834  0.36049 -0.52352  0.57279 -0.650095  0.817673\n13 -0.37794  0.70379  0.10339  0.06127 -0.101571  1.376623\n14 -0.23878  0.75522  0.83648 -0.55822 -0.011527  1.221217\n15 -0.30425  0.95026  1.80274 -1.48211  0.135021  0.031795\n16 -0.13354  0.33951 -0.23252  0.19177 -0.667112  0.227348\n17  0.10111  0.32379 -0.20380  0.18495 -0.676546  0.364915\n18  0.06913  0.37913 -0.25881  0.06998 -0.851379  0.289054\n19  0.05746  0.43915  0.04566 -0.32171 -0.899449 -0.090759\n20  0.17478  0.39927 -0.36244 -0.15647 -1.300718 -0.093396\n21  0.16944  0.35608 -0.73929  0.42751 -0.509249 -0.653892\n22  0.14898  0.55339 -0.08008 -0.04972  0.196636 -0.621753\n23  1.39778 -1.19102  0.66424 -0.46178  0.252908  0.573369\n24  0.99357 -0.52036  0.07186  0.48088  1.068785 -0.373991\n25  2.22002 -2.03168  0.17940 -0.52606 -1.148014  0.786506\n26  0.89388 -0.10410 -0.61440  0.42034  0.343649 -0.800522\n27  0.64866  0.41296 -0.17444 -0.26105  0.274443 -1.259099\n28  0.77100  0.82592  0.43387 -1.00092 -0.001674 -0.703378\n29  0.66413  1.11562 -1.58043  0.65099  0.650327 -0.020001\n30  0.74743  1.36955 -0.22810 -0.43281  1.431895 -0.686570\n\n# Hier das ausführliche Summary mit den Art- und Umweltkorrelationen auf den ersten sechs Achsen\n\nscreeplot(env.pca, bstick = TRUE, npcs = length(env.pca$CA$eig))\n\n\n\n# Visualisierung der Anteile erklärter Varianz, auch im Vergleich zu einem Broken-Stick-Modell\n\n\n\nDie Anteile fallen steil ab. Nur die ersten vier Achsen erklären jeweils mehr als 5 % (und zusammen über 90 %)\nDas Broken-stick-Modell würde sogar nur die ersten beiden Achsen als relevant vorschlagen\nDa die Relevanz für das Datenmuster in den Umweltdaten nicht notwendig die Relevanz für die Erklärung der Artenzahlen ist, nehmen wir ins globale Modell grosszügig die ersten vier Achsen rein (PC1-PC4) Die Bedeutung der Achsen (benötigt man später für die Interpretation!) findet man in den “species scores” (da so, wie wir die PCA hier gerechnet haben, die Umweltdaten die Arten sind. Zusätzlich oder alternative kann man sich die ersten vier Achsen auch visualisieren, indem man PC2 vs. PC1 (ohne choices), PC3 vs. PC1 oder PC4 vs. PC1 plottet.\n\n\npar(mfrow = c(2, 2))\nbiplot(env.pca, scaling = 1)\nbiplot(env.pca, choices = c(1, 3), scaling = 1)\nbiplot(env.pca, choices = c(1, 4), scaling = 1)\n\n\n\n\nPC1 steht v.a. für Nitrat (positiv), Sauerstoff (negativ)\nPC2 steht v.a. für pH (positiv)\nPC3 steht v.a. für pH (positiv) und slo (negativ)\nPC4 steht v.a. für pH (negativ) und slo (negativ)\n\n\n#Wir extrahieren nun die ersten vier PC-Scores aller Aufnahmeflächen\n\nscores <- scores(env.pca, c(1:4), display = c(\"sites\"))\nscores\n\n\n           PC1         PC2         PC3         PC4\n1  -1.41273883 -1.40097880 -2.03483870 -2.67758838\n2  -1.03724733 -0.77955354  0.24400009  0.25634696\n3  -0.94506998 -0.46765361  1.25042488 -0.49329701\n4  -0.87371164 -0.26988488  0.19304045  0.51979381\n5  -0.42087585 -0.66943957  0.83190665  0.71729089\n6  -0.77223581 -0.72066623 -0.07357441  0.77902331\n7  -0.77466085 -0.08103491  0.39629959  0.19223674\n8  -0.28839689 -0.60588978  0.83822295  1.01439781\n9  -0.28305399 -0.47710013  0.39908190  1.13074537\n10 -0.48714448 -0.41859737 -1.27554791  0.90267450\n11 -0.26940072  0.45383527  0.09118967 -0.15126579\n12 -0.43834427  0.36049094 -0.52351661  0.57279309\n13 -0.37793587  0.70379486  0.10338604  0.06127189\n14 -0.23878321  0.75521955  0.83648481 -0.55822243\n15 -0.30424687  0.95025522  1.80274307 -1.48210897\n16 -0.13353523  0.33951332 -0.23252035  0.19177453\n17  0.10111086  0.32378989 -0.20379779  0.18495051\n18  0.06913015  0.37912929 -0.25881042  0.06998196\n19  0.05745832  0.43915445  0.04566423 -0.32171096\n20  0.17478169  0.39926644 -0.36244421 -0.15647276\n21  0.16944233  0.35608121 -0.73929343  0.42751253\n22  0.14898095  0.55338567 -0.08008399 -0.04971692\n23  1.39778235 -1.19101965  0.66424125 -0.46178368\n24  0.99357418 -0.52036211  0.07185912  0.48087634\n25  2.22001746 -2.03168135  0.17940028 -0.52606378\n26  0.89388246 -0.10410321 -0.61440303  0.42034205\n27  0.64865976  0.41296206 -0.17444493 -0.26104930\n28  0.77099833  0.82591720  0.43386950 -1.00091524\n29  0.66413124  1.11561620 -1.58043410  0.65099411\n30  0.74743174  1.36955357 -0.22810459 -0.43281119\nattr(,\"const\")\n[1] 4.226177\n\n#Berechnung der Artenzahl mittels specnumber; Artenzahl und Scores werden zum Dataframe für die Regressionsanalyse hinzugefügt\ndoubs <- data.frame(env, scores, species_richness = specnumber(spe))\ndoubs\n\n\n     dfs ele  slo   dis  pH har  pho  nit  amm  oxy  bod         PC1\n1    0.3 934 48.0  0.84 7.9  45 0.01 0.20 0.00 12.2  2.7 -1.41273883\n2    2.2 932  3.0  1.00 8.0  40 0.02 0.20 0.10 10.3  1.9 -1.03724733\n3   10.2 914  3.7  1.80 8.3  52 0.05 0.22 0.05 10.5  3.5 -0.94506998\n4   18.5 854  3.2  2.53 8.0  72 0.10 0.21 0.00 11.0  1.3 -0.87371164\n5   21.5 849  2.3  2.64 8.1  84 0.38 0.52 0.20  8.0  6.2 -0.42087585\n6   32.4 846  3.2  2.86 7.9  60 0.20 0.15 0.00 10.2  5.3 -0.77223581\n7   36.8 841  6.6  4.00 8.1  88 0.07 0.15 0.00 11.1  2.2 -0.77466085\n8   49.1 792  2.5  1.30 8.1  94 0.20 0.41 0.12  7.0  8.1 -0.28839689\n9   70.5 752  1.2  4.80 8.0  90 0.30 0.82 0.12  7.2  5.2 -0.28305399\n10  99.0 617  9.9 10.00 7.7  82 0.06 0.75 0.01 10.0  4.3 -0.48714448\n11 123.4 483  4.1 19.90 8.1  96 0.30 1.60 0.00 11.5  2.7 -0.26940072\n12 132.4 477  1.6 20.00 7.9  86 0.04 0.50 0.00 12.2  3.0 -0.43834427\n13 143.6 450  2.1 21.10 8.1  98 0.06 0.52 0.00 12.4  2.4 -0.37793587\n14 152.2 434  1.2 21.20 8.3  98 0.27 1.23 0.00 12.3  3.8 -0.23878321\n15 164.5 415  0.5 23.00 8.6  86 0.40 1.00 0.00 11.7  2.1 -0.30424687\n16 185.9 375  2.0 16.10 8.0  88 0.20 2.00 0.05 10.3  2.7 -0.13353523\n17 198.5 349  0.5 24.30 8.0  92 0.20 2.50 0.20 10.2  4.6  0.10111086\n18 211.0 333  0.8 25.00 8.0  90 0.50 2.20 0.20 10.3  2.8  0.06913015\n19 224.6 310  0.5 25.90 8.1  84 0.60 2.20 0.15 10.6  3.3  0.05745832\n20 247.7 286  0.8 26.80 8.0  86 0.30 3.00 0.30 10.3  2.8  0.17478169\n21 282.1 262  1.0 27.20 7.9  85 0.20 2.20 0.10  9.0  4.1  0.16944233\n22 294.0 254  1.4 27.90 8.1  88 0.20 1.62 0.07  9.1  4.8  0.14898095\n23 304.3 246  1.2 28.80 8.1  97 2.60 3.50 1.15  6.3 16.4  1.39778235\n24 314.7 241  0.3 29.76 8.0  99 1.40 2.50 0.60  5.2 12.3  0.99357418\n25 327.8 231  0.5 38.70 7.9 100 4.22 6.20 1.80  4.1 16.7  2.22001746\n26 356.9 214  0.5 39.10 7.9  94 1.43 3.00 0.30  6.2  8.9  0.89388246\n27 373.2 206  1.2 39.60 8.1  90 0.58 3.00 0.26  7.2  6.3  0.64865976\n28 394.7 195  0.3 43.20 8.3 100 0.74 4.00 0.30  8.1  4.5  0.77099833\n29 422.0 183  0.6 67.70 7.8 110 0.45 1.62 0.10  9.0  4.2  0.66413124\n30 453.0 172  0.2 69.00 8.2 109 0.65 1.60 0.10  8.2  4.4  0.74743174\n           PC2         PC3         PC4 species_richness\n1  -1.40097880 -2.03483870 -2.67758838                1\n2  -0.77955354  0.24400009  0.25634696                3\n3  -0.46765361  1.25042488 -0.49329701                4\n4  -0.26988488  0.19304045  0.51979381                8\n5  -0.66943957  0.83190665  0.71729089               11\n6  -0.72066623 -0.07357441  0.77902331               10\n7  -0.08103491  0.39629959  0.19223674                5\n8  -0.60588978  0.83822295  1.01439781                0\n9  -0.47710013  0.39908190  1.13074537                5\n10 -0.41859737 -1.27554791  0.90267450                6\n11  0.45383527  0.09118967 -0.15126579                6\n12  0.36049094 -0.52351661  0.57279309                6\n13  0.70379486  0.10338604  0.06127189                6\n14  0.75521955  0.83648481 -0.55822243               10\n15  0.95025522  1.80274307 -1.48210897               11\n16  0.33951332 -0.23252035  0.19177453               17\n17  0.32378989 -0.20379779  0.18495051               22\n18  0.37912929 -0.25881042  0.06998196               23\n19  0.43915445  0.04566423 -0.32171096               23\n20  0.39926644 -0.36244421 -0.15647276               22\n21  0.35608121 -0.73929343  0.42751253               23\n22  0.55338567 -0.08008399 -0.04971692               22\n23 -1.19101965  0.66424125 -0.46178368                3\n24 -0.52036211  0.07185912  0.48087634                8\n25 -2.03168135  0.17940028 -0.52606378                8\n26 -0.10410321 -0.61440303  0.42034205               21\n27  0.41296206 -0.17444493 -0.26104930               22\n28  0.82591720  0.43386950 -1.00091524               22\n29  1.11561620 -1.58043410  0.65099411               26\n30  1.36955357 -0.22810459 -0.43281119               21\n\nstr(doubs)\n\n\n'data.frame':   30 obs. of  16 variables:\n $ dfs             : num  0.3 2.2 10.2 18.5 21.5 32.4 36.8 49.1 70.5 99 ...\n $ ele             : int  934 932 914 854 849 846 841 792 752 617 ...\n $ slo             : num  48 3 3.7 3.2 2.3 3.2 6.6 2.5 1.2 9.9 ...\n $ dis             : num  0.84 1 1.8 2.53 2.64 2.86 4 1.3 4.8 10 ...\n $ pH              : num  7.9 8 8.3 8 8.1 7.9 8.1 8.1 8 7.7 ...\n $ har             : int  45 40 52 72 84 60 88 94 90 82 ...\n $ pho             : num  0.01 0.02 0.05 0.1 0.38 0.2 0.07 0.2 0.3 0.06 ...\n $ nit             : num  0.2 0.2 0.22 0.21 0.52 0.15 0.15 0.41 0.82 0.75 ...\n $ amm             : num  0 0.1 0.05 0 0.2 0 0 0.12 0.12 0.01 ...\n $ oxy             : num  12.2 10.3 10.5 11 8 10.2 11.1 7 7.2 10 ...\n $ bod             : num  2.7 1.9 3.5 1.3 6.2 5.3 2.2 8.1 5.2 4.3 ...\n $ PC1             : num  -1.413 -1.037 -0.945 -0.874 -0.421 ...\n $ PC2             : num  -1.401 -0.78 -0.468 -0.27 -0.669 ...\n $ PC3             : num  -2.035 0.244 1.25 0.193 0.832 ...\n $ PC4             : num  -2.678 0.256 -0.493 0.52 0.717 ...\n $ species_richness: int  1 3 4 8 11 10 5 0 5 6 ...\n\n##Lösung mit lm (alternativ ginge Poisson-glm) und frequentist approach (alternativ ginge Multimodelinference mit AICc)\nlm.pc.0 <- lm(species_richness ~ PC1 + PC2 + PC3 + PC4, data = doubs)\nsummary(lm.pc.0)\n\n\n\nCall:\nlm(formula = species_richness ~ PC1 + PC2 + PC3 + PC4, data = doubs)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.2359 -4.3792  0.4256  4.5453  7.5058 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  12.5000     0.9869  12.667 2.24e-12 ***\nPC1           4.4035     1.2790   3.443  0.00204 ** \nPC2           6.6729     1.2790   5.217 2.13e-05 ***\nPC3          -2.9645     1.2790  -2.318  0.02893 *  \nPC4           0.1674     1.2790   0.131  0.89694    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.405 on 25 degrees of freedom\nMultiple R-squared:  0.6401,    Adjusted R-squared:  0.5825 \nF-statistic: 11.12 on 4 and 25 DF,  p-value: 2.55e-05\n\n# Modellvereinfachung: PC4 ist nicht signifikant und wird entfernt\nlm.pc.1 <- lm(species_richness ~ PC1 + PC2 + PC3, data = doubs)\nsummary(lm.pc.1) # jetzt sind alle Achsen signifikant und werden in das minimal adäquate Modell aufgenommen\n\n\n\nCall:\nlm(formula = species_richness ~ PC1 + PC2 + PC3, data = doubs)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.226 -4.457  0.403  4.545  7.452 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   12.500      0.968  12.913 8.11e-13 ***\nPC1            4.404      1.255   3.510  0.00165 ** \nPC2            6.673      1.255   5.319 1.45e-05 ***\nPC3           -2.965      1.255  -2.363  0.02589 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.302 on 26 degrees of freedom\nMultiple R-squared:  0.6399,    Adjusted R-squared:  0.5983 \nF-statistic:  15.4 on 3 and 26 DF,  p-value: 5.853e-06\n\n# Modelldiagnostik/Modellvalidierung\npar(mfrow = c(2, 2))\nplot(lm.pc.1) \n\n\n\n\nNicht besonders toll, ginge aber gerade noch. Da wir aber ohnehin Zähldaten haben, können wir es mit einem Poisson-GLM versuchen\n#Alternativ mit glm\n\n\nglm.pc.1 <- glm(species_richness ~ PC1 + PC2 + PC3 + PC4, family = \"poisson\", data = doubs)\nsummary(glm.pc.1)\n\n\n\nCall:\nglm(formula = species_richness ~ PC1 + PC2 + PC3 + PC4, family = \"poisson\", \n    data = doubs)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.6063  -1.4535  -0.1915   1.3852   2.2701  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  2.38447    0.05889  40.491  < 2e-16 ***\nPC1          0.39601    0.08240   4.806 1.54e-06 ***\nPC2          0.54840    0.07550   7.263 3.78e-13 ***\nPC3         -0.15174    0.08345  -1.818    0.069 .  \nPC4          0.06053    0.09661   0.627    0.531    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 179.812  on 29  degrees of freedom\nResidual deviance:  76.312  on 25  degrees of freedom\nAIC: 206.97\n\nNumber of Fisher Scoring iterations: 5\n\nglm.pc.2 <- glm(species_richness ~ PC1 + PC2 + PC3, family = \"poisson\", data = doubs)\nsummary(glm.pc.2)\n\n\n\nCall:\nglm(formula = species_richness ~ PC1 + PC2 + PC3, family = \"poisson\", \n    data = doubs)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.4821  -1.3539  -0.2734   1.4039   2.2096  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  2.38670    0.05858  40.742  < 2e-16 ***\nPC1          0.38609    0.07941   4.862 1.16e-06 ***\nPC2          0.53665    0.07161   7.494 6.70e-14 ***\nPC3         -0.17669    0.07106  -2.486   0.0129 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 179.812  on 29  degrees of freedom\nResidual deviance:  76.722  on 26  degrees of freedom\nAIC: 205.38\n\nNumber of Fisher Scoring iterations: 5\n\npar(mfrow = c(2, 2))\nplot(glm.pc.2) # sieht nicht besser aus als LM, die Normalverteilung ist sogar schlechter\n\n\n\n\nLM oder GLM sind für die Analyse möglich, Modellwahl nach Gusto. Man muss jetzt noch die Ergebnisse adäquat aus all den erzielten Outputs zusammenstellen (siehe Ergebnistext). In dieser Aufgabe haben wir ja die PC-Achsen als Alternative zur direkten Modellierung mit den originalen Umweltvariablen ausprobiert. Deshalb (war nicht Teil der Aufgabe), kommt hier noch eine Lösung, wie wir es bisher gemacht hätten.\nZum Vergleich die Modellierung mit den Originaldaten\n\n\n# Korrelationen zwischen Prädiktoren\ncor <- cor(doubs[, 1:11])\ncor[abs(cor)<.7] <- 0\ncor \n\n\n\nDie Korrelationsmatrix betrachtet man am besten in Excel. Es zeigt sich, dass es zwei grosse Gruppen von untereinander hochkorrelierten Variablen gibt: zum einen dfs-ele-dis-har-nit, zum anderen pho-nit-amm-oxy-bod, während slo und pH mit jeweils keiner anderen Variablen hochkorreliert sind. Insofern behalten wir eine aus der ersten Gruppe (ele), eine aus der zweiten Gruppe (pho) und die beiden «unabhängigen».\n\n\n# Globalmodell (als hinreichend unabhängige Variablen werden ele, slo, pH und pho aufgenommen)\nlm.orig.1 <- lm(species_richness ~ ele + slo + pH + pho, data = doubs)\nsummary(lm.orig.1)\n\n\n\nCall:\nlm(formula = species_richness ~ ele + slo + pH + pho, data = doubs)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.784 -3.265  1.869  3.375  7.664 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 74.19236   47.29223   1.569  0.12926    \nele         -0.02645    0.00441  -5.997 2.91e-06 ***\nslo         -0.09597    0.12988  -0.739  0.46684    \npH          -5.75643    5.84799  -0.984  0.33438    \npho         -4.09089    1.25657  -3.256  0.00324 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.285 on 25 degrees of freedom\nMultiple R-squared:  0.6559,    Adjusted R-squared:  0.6009 \nF-statistic: 11.92 on 4 and 25 DF,  p-value: 1.485e-05\n\n# Modellvereinfachung: slo als am wenigsten signifikante Variable gestrichen\nlm.orig.2 <- lm(species_richness ~ ele + pH + pho, data = doubs)\nsummary(lm.orig.2)\n\n\n\nCall:\nlm(formula = species_richness ~ ele + pH + pho, data = doubs)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.446 -3.323  1.485  3.562  8.209 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 66.416530  45.702262   1.453  0.15812    \nele         -0.027744   0.004011  -6.917 2.41e-07 ***\npH          -4.756146   5.639266  -0.843  0.40670    \npho         -4.068860   1.245202  -3.268  0.00305 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.239 on 26 degrees of freedom\nMultiple R-squared:  0.6484,    Adjusted R-squared:  0.6079 \nF-statistic: 15.98 on 3 and 26 DF,  p-value: 4.305e-06\n\n# Modellvereinfachung: pH ist immer noch nicht signifikant und wird gestrichen\nlm.orig.3 <- lm(species_richness ~ ele + pho, data = doubs)\nsummary(lm.orig.3)\n\n\n\nCall:\nlm(formula = species_richness ~ ele + pho, data = doubs)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.334 -4.548  1.058  3.717  7.889 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 27.929234   2.490667  11.214 1.15e-11 ***\nele         -0.027463   0.003976  -6.908 2.01e-07 ***\npho         -3.951980   1.230833  -3.211  0.00341 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.211 on 27 degrees of freedom\nMultiple R-squared:  0.6388,    Adjusted R-squared:  0.6121 \nF-statistic: 23.88 on 2 and 27 DF,  p-value: 1.07e-06\n\n# Modelldiagnostik\npar(mfrow = c(2, 2))\nplot(lm.orig.3) # nicht so gut, besonders die Bananenform in der linken obereren Abbildung\n\n\n\n# Nach Modellvereinfachung bleiben zwei signifikante Variablen, ele und pho.\n\n# Da das nicht so gut aussieht, versuchen wir es mit dem theoretisch angemesseneren Modell, einem Poisson-GLM.\n\n#Versuch mit glm\nglm.orig.1 <- glm(species_richness ~ ele + pho + pH + slo, family = \"poisson\", data = doubs)\nsummary(glm.orig.1)\n\n\n\nCall:\nglm(formula = species_richness ~ ele + pho + pH + slo, family = \"poisson\", \n    data = doubs)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.3800  -0.7094   0.1622   0.8079   2.4435  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  7.855498   2.550786   3.080  0.00207 ** \nele         -0.002277   0.000321  -7.094  1.3e-12 ***\npho         -0.362280   0.082384  -4.397  1.1e-05 ***\npH          -0.506330   0.316934  -1.598  0.11013    \nslo         -0.054200   0.027685  -1.958  0.05026 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 179.812  on 29  degrees of freedom\nResidual deviance:  55.128  on 25  degrees of freedom\nAIC: 185.79\n\nNumber of Fisher Scoring iterations: 5\n\nglm.orig.2 <- glm(species_richness ~ ele + pho + slo, family = \"poisson\", data = doubs)\nsummary(glm.orig.2)\n\n\n\nCall:\nglm(formula = species_richness ~ ele + pho + slo, family = \"poisson\", \n    data = doubs)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.3902  -0.8159   0.2153   0.8648   2.4389  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  3.7819203  0.1356022  27.890  < 2e-16 ***\nele         -0.0023363  0.0003167  -7.377 1.62e-13 ***\npho         -0.3563681  0.0835094  -4.267 1.98e-05 ***\nslo         -0.0446686  0.0246618  -1.811   0.0701 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 179.812  on 29  degrees of freedom\nResidual deviance:  57.752  on 26  degrees of freedom\nAIC: 186.41\n\nNumber of Fisher Scoring iterations: 5\n\nglm.orig.3 <- glm(species_richness ~ ele + pho, family = \"poisson\", data = doubs)\nsummary(glm.orig.3)\n\n\n\nCall:\nglm(formula = species_richness ~ ele + pho, family = \"poisson\", \n    data = doubs)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.1946  -0.9256   0.0642   0.8567   2.8093  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  3.8381921  0.1342437  28.591  < 2e-16 ***\nele         -0.0026994  0.0002795  -9.658  < 2e-16 ***\npho         -0.3525967  0.0829766  -4.249 2.14e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 179.812  on 29  degrees of freedom\nResidual deviance:  63.336  on 27  degrees of freedom\nAIC: 190\n\nNumber of Fisher Scoring iterations: 5\n\nplot(glm.orig.3)\n\n\n\n# Das sieht deutlich besser aus als beim LM. Wir müssen aber noch prüfen, ob evtl. Overdispersion vorliegt.\n\nif(!require(AER)){install.packages(\"AER\")}\nlibrary(AER)\ndispersiontest(glm.orig.3) #signifikante Überdispersion\n\n\n\n    Overdispersion test\n\ndata:  glm.orig.3\nz = 2.1816, p-value = 0.01457\nalternative hypothesis: true dispersion is greater than 1\nsample estimates:\ndispersion \n  1.967504 \n\n# Ja, es gibt signifikante Overdispersion (obwohl der Dispersionparameter sogar unter 2 ist, also nicht extrem). Wir können nun entweder quasipoisson oder negativebinomial nehmen.\n\nglmq.orig.3 <- glm(species_richness ~ ele + pho, family = \"quasipoisson\", data = doubs)\nsummary(glmq.orig.3)\n\n\n\nCall:\nglm(formula = species_richness ~ ele + pho, family = \"quasipoisson\", \n    data = doubs)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-3.1946  -0.9256   0.0642   0.8567   2.8093  \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.8381921  0.1996453  19.225  < 2e-16 ***\nele         -0.0026994  0.0004157  -6.494 5.81e-07 ***\npho         -0.3525967  0.1234016  -2.857  0.00813 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasipoisson family taken to be 2.211722)\n\n    Null deviance: 179.812  on 29  degrees of freedom\nResidual deviance:  63.336  on 27  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 5\n\n# Parameterschätzung bleiben gleich, aber Signifikanzen sind niedriger als beim GLM ohne Overdispersion.\nplot(glmq.orig.3)\n\n\n\n\nSieht gut aus, wir hätten hier also unser finales Modell.\nIm Vergleich der beiden Vorgehensweisen (PC-Achsen vs. Umweltdaten direkt) scheint in diesem Fall die direkte Modellierung der Umweltachsen informativer: Man kommt mit zwei Prädiktoren aus, die jeweils direkt für eine der Hauptvariablen stehen – Meereshöhe und Phosphor – zugleich aber jeweils eine grössere Gruppe von Variablen mit hohen Korrelationen inkludieren, im ersten Fall Variablen, die sich im Flusslauf von oben nach unten systematisch ändern, im zweiten Masse der Nährstoffbelastung des Gewässers. Bei der PCA-Lösung kamen drei signifikante Komponenten heraus, die allerdings nicht so leicht zu interpretieren sind. Dies insbesondere, weil in diesem Fall auf der Ebene PC2 vs. PC1 die Mehrzahl der Umweltparameter ungefähr in 45-Grad-Winkeln angeordnet sind. Im allgemeinen Fall kann aber die Nutzung von PC-Achsen durchaus eine gute Lösung sein.\n\n\n\n",
    "preview": "statistik/Statistik6_03_Solution/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik7_01_Demo/",
    "title": "Demo Statistik 7",
    "description": {},
    "author": [
      {
        "name": "Jürgen Dengler",
        "url": {}
      }
    ],
    "date": "2021-11-11",
    "categories": [
      "Statistik7"
    ],
    "contents": "\n\nContents\nOrdinationen II\nInterpretation von Ordinationen\nConstrained ordination\nRedundancy analysis (RDA)\nVariation partioning\n\n\n\n\n\nOrdinationen II\nDemoscript als Download\nDatensatz Doubs.RData\nFunktion triplot.rda.R\nInterpretation von Ordinationen\nWildi pp. 96 et seq.\n\n\n# Plot Arten\nif(!require(dave)){install.packages(\"dave\")}\nlibrary(dave)\nca <- cca(sveg^0.5)\n\n# Plot mit ausgewählten Arten\nsel.spec <- c(3, 11, 23, 31, 39, 46, 72, 77, 96)\nsnames <- names(sveg[,sel.spec])\nsnames\n\n\n[1] \"Vaccinium.oxycoccos\" \"Carex.echinata\"      \"Arnica.montana\"     \n[4] \"Festuca.rubra\"       \"Carex.pulicaris\"     \"Sphagnum.recurvum\"  \n[7] \"Viola.palustris\"     \"Galium.uliginosum\"   \"Stachys.officinalis\"\n\nscores <- scores(ca, display = \"species\", scaling = \"sites\")\nsx <- scores[sel.spec, 1]\nsy <- scores[sel.spec, 2]\nplot(ca, display = \"sites\", type = \"point\")\npoints(sx, sy, pch = 16)\nsnames <- make.cepnames(snames)\ntext(sx, sy, snames, pos = c(1,2,1,1,3,2,4,3,1), cex = 0.8)\n\n\n\n# Plot \"response surfaces\" in der CA\nplot(ca, display = \"sites\", type = \"point\")\nordisurf(ca, ssit$pH.peat, add = T)\n\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\ny ~ s(x1, x2, k = 10, bs = \"tp\", fx = FALSE)\n\nEstimated degrees of freedom:\n4.63  total = 5.63 \n\nREML score: 28.14791     \n\nplot(ca, display = \"sites\", type = \"points\")\nordisurf(ca, ssit$Waterlev.av, add = T, col = \"blue\")\n\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\ny ~ s(x1, x2, k = 10, bs = \"tp\", fx = FALSE)\n\nEstimated degrees of freedom:\n5.07  total = 6.07 \n\nREML score: 161.492     \n\n# Das gleiche für die DCA\ndca <- decorana(sveg)\nplot(dca, display = \"sites\", type = \"points\")\nordisurf(dca, ssit$pH.peat, add = T)\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\ny ~ s(x1, x2, k = 10, bs = \"tp\", fx = FALSE)\n\nEstimated degrees of freedom:\n2.61  total = 3.61 \n\nREML score: 29.47878     \n\nordisurf(dca, ssit$Waterlev.av, add = T, col = \"blue\")\n\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\ny ~ s(x1, x2, k = 10, bs = \"tp\", fx = FALSE)\n\nEstimated degrees of freedom:\n6.23  total = 7.23 \n\nREML score: 161.1293     \n\n# Das gleiche mit NMDS\nmde <- vegdist(sveg, method = \"euclidean\")\nmmds <- metaMDS(mde)\n\n\nRun 0 stress 0.1478603 \nRun 1 stress 0.1602556 \nRun 2 stress 0.1965569 \nRun 3 stress 0.2050062 \nRun 4 stress 0.1929923 \nRun 5 stress 0.1611976 \nRun 6 stress 0.1652625 \nRun 7 stress 0.14849 \nRun 8 stress 0.1866079 \nRun 9 stress 0.1803332 \nRun 10 stress 0.1611976 \nRun 11 stress 0.1471495 \n... New best solution\n... Procrustes: rmse 0.01081065  max resid 0.06880781 \nRun 12 stress 0.148944 \nRun 13 stress 0.1462959 \n... New best solution\n... Procrustes: rmse 0.03088096  max resid 0.1476946 \nRun 14 stress 0.1489369 \nRun 15 stress 0.1462959 \n... New best solution\n... Procrustes: rmse 8.517913e-06  max resid 4.676538e-05 \n... Similar to previous best\nRun 16 stress 0.1471649 \nRun 17 stress 0.1471495 \nRun 18 stress 0.1911354 \nRun 19 stress 0.1716976 \nRun 20 stress 0.1889192 \n*** Solution reached\n\nif(!require(MASS)){install.packages(\"MASS\")}\nlibrary(MASS)\nimds <- isoMDS(mde)\n\n\ninitial  value 21.981028 \niter   5 value 15.595142\niter  10 value 15.269201\nfinal  value 15.229997 \nconverged\n\nplot(mmds$points)\nordisurf(mmds, ssit$pH.peat, add = T)\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\ny ~ s(x1, x2, k = 10, bs = \"tp\", fx = FALSE)\n\nEstimated degrees of freedom:\n5.97  total = 6.97 \n\nREML score: 41.99563     \n\nordisurf(mmds, ssit$Waterlev.av,add = T, col = \"blue\")\n\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\ny ~ s(x1, x2, k = 10, bs = \"tp\", fx = FALSE)\n\nEstimated degrees of freedom:\n6.39  total = 7.39 \n\nREML score: 168.061     \n\nplot(imds$points)\nordisurf(imds, ssit$pH.peat, add = T)\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\ny ~ s(x1, x2, k = 10, bs = \"tp\", fx = FALSE)\n\nEstimated degrees of freedom:\n7.06  total = 8.06 \n\nREML score: 37.68641     \n\nordisurf(imds, ssit$Waterlev.av, add = T, col = \"blue\")\n\n\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\ny ~ s(x1, x2, k = 10, bs = \"tp\", fx = FALSE)\n\nEstimated degrees of freedom:\n6.01  total = 7.01 \n\nREML score: 167.6801     \n\nConstrained ordination\n\n\n# 5 Umweltvariablen gewählt, durch die die Ordination constrained werden soll\nssit\nsummary(ssit)\ns5 <- c(\"pH.peat\", \"P.peat\", \"Waterlev.av\", \"CEC.peat\", \"Acidity.peat\")\nssit5 <- ssit[s5]\n\ndata(sveg)\nsummary(sveg)\n\n\n\n\n\n# RDA = constrained PCA\nrda <- rda(sveg~., ssit5)\nplot(rda)\n\n# CCA = constrained CA\ncca <- cca(sveg~., ssit5)\nplot(cca)\n\n# Unconstrained and constrained variance\ntot <- cca$tot.chi\nconstr <- cca$CCA$tot.chi\nconstr / tot\n\n\n\nRedundancy analysis (RDA)\nMehr Details zu RDA aus Borcard et al. (Numerical ecology with R)\n\n\n# Datensatz Doubs\n# Doubs Datensatz in den workspace laden\nload(\"Doubs.RData\")  \n\n\n\n\n\nsummary(spe)\nsummary(env)\nsummary(spa)\n\n\n\n\n\n# Entfernen der Untersuchungsfläche ohne Arten\nspe <- spe[-8, ]\nenv <- env[-8, ]\nspa <- spa[-8, ]\n\n# Karten für 4 Fischarten\npar(mfrow = c(2, 2))\nplot(spa, asp = 1, col = \"brown\", cex = spe$Satr, xlab = \"x (km)\", ylab = \"y (km)\", main = \"Brown trout\")\nlines(spa, col = \"light blue\")\nplot(spa, asp = 1, col = \"brown\", cex = spe$Thth, xlab = \"x (km)\", ylab = \"y (km)\", main = \"Grayling\")\nlines(spa, col = \"light blue\")\nplot(spa, asp = 1, col = \"brown\", cex = spe$Alal, xlab = \"x (km)\", ylab = \"y (km)\", main = \"Bleak\")\nlines(spa, col = \"light blue\")\nplot(spa, asp = 1, col = \"brown\", cex = spe$Titi, xlab = \"x (km)\", ylab = \"y (km)\", main = \"Tench\")\nlines(spa, col = \"light blue\")\n\n\n\n# Set aside the variable 'dfs' (distance from the source) for \n# later use\ndfs <- env[, 1]\n# Remove the 'dfs' variable from the env data frame\nenv2 <- env[, -1]\n\n# Recode the slope variable (slo) into a factor (qualitative) \n# variable to show how these are handled in the ordinations\nslo2 <- rep(\".very_steep\", nrow(env))\nslo2[env$slo <= quantile(env$slo)[4]] <- \".steep\"\nslo2[env$slo <= quantile(env$slo)[3]] <- \".moderate\"\nslo2[env$slo <= quantile(env$slo)[2]] <- \".low\"\nslo2 <- factor(slo2, levels = c(\".low\", \".moderate\", \".steep\", \".very_steep\"))\ntable(slo2)\n\n\nslo2\n       .low   .moderate      .steep .very_steep \n          8           8           6           7 \n\n# Create an env3 data frame with slope as a qualitative variable\nenv3 <- env2\nenv3$slo <- slo2\n\n# Create two subsets of explanatory variables\n# Physiography (upstream-downstream gradient)\nenvtopo <- env2[, c(1 : 3)]\nnames(envtopo)\n\n\n[1] \"ele\" \"slo\" \"dis\"\n\n# Water quality\nenvchem <- env2[, c(4 : 10)]\nnames(envchem)\n\n\n[1] \"pH\"  \"har\" \"pho\" \"nit\" \"amm\" \"oxy\" \"bod\"\n\n# Hellinger-transform the species dataset\nlibrary(vegan)\nspe.hel <- decostand(spe, \"hellinger\")\n\n\n\n\n\nspe.hel\n\n\n\n\n\n# Redundancy analysis (RDA)\n## RDA of the Hellinger-transformed fish species data, constrained\n## by all the environmental variables contained in env3\nspe.rda <- rda(spe.hel ~ ., env3) # Observe the shortcut formula\n\n\n\n\n\nspe.rda\nsummary(spe.rda)  # Scaling 2 (default)\n\n\n\n\n\n# Canonical coefficients from the rda object\ncoef(spe.rda)\n\n\n\n\n\n# Unadjusted R^2 und Adjusted R^2\n(R2 <- RsquareAdj(spe.rda))\n\n\n$r.squared\n[1] 0.7270922\n\n$adj.r.squared\n[1] 0.5224114\n\n## Triplots of the rda results (lc scores)\n## Site scores as linear combinations of the environmental variables\n# dev.new(title = \"RDA scaling 1 and 2 + lc\", width = 12, height = 6, noRStudioGD = TRUE)\npar(mfrow = c(1, 2))\n# Scaling 1\nplot(spe.rda,scaling = 1, display = c(\"sp\", \"lc\", \"cn\"), main = \"Triplot RDA spe.hel ~ env3 - scaling 1 - lc scores\")\nspe.sc1 <- scores(spe.rda, choices = 1:2, scaling = 1, display = \"sp\")\narrows(0, 0, spe.sc1[, 1] * 0.92, spe.sc1[, 2] * 0.92, length = 0, lty = 1, col = \"red\")\ntext(-0.75, 0.7, \"a\", cex = 1.5)\n# Scaling 2\nplot(spe.rda, display = c(\"sp\", \"lc\", \"cn\"), main = \"Triplot RDA spe.hel ~ env3 - scaling 2 - lc scores\")\nspe.sc2 <- scores(spe.rda, choices = 1:2, display = \"sp\")\narrows(0, 0, spe.sc2[, 1] * 0.92, spe.sc2[, 2] * 0.92,length = 0, lty = 1, col = \"red\")\ntext(-0.82, 0.55, \"b\", cex = 1.5)\n\n\n\n## Triplots of the rda results (wa scores)\n## Site scores as weighted averages (vegan's default)\n# Scaling 1 :  distance triplot\n#dev.new(title = \"RDA plot\", width = 12, height = 6, noRStudioGD = TRUE)\npar(mfrow = c(1, 2))\nplot(spe.rda, scaling = 1, main = \"Triplot RDA spe.hel ~ env3 - scaling 1 - wa scores\")\narrows(0, 0, spe.sc1[, 1] * 0.92, spe.sc1[, 2] * 0.92, length = 0, lty = 1, col = \"red\")\n# Scaling 2 (default) :  correlation triplot\nplot(spe.rda, main = \"Triplot RDA spe.hel ~ env3 - scaling 2 - wa scores\")\narrows(0, 0, spe.sc2[, 1] * 0.92, spe.sc2[, 2] * 0.92, length = 0, lty = 1, col = \"red\")\n\n\n\n# Select species with goodness-of-fit at least 0.6 in the \n# ordination plane formed by axes 1 and 2\nspe.good <- goodness(spe.rda)\nsel.sp <- which(spe.good[, 2] >= 0.6)\nsel.sp\n\n\nSatr Phph Chna Baba Albi Rham Legi Cyca Abbr Gyce Ruru Blbj Alal Anan \n   2    3    7   11   12   16   17   19   21   23   24   25   26   27 \n\n# Triplots with homemade function triplot.rda(), scalings 1 and 2\nsource(\"triplot.rda.R\")\n#dev.new(title = \"RDA plot with triplot.rda\", width = 12, height = 6, noRStudioGD = TRUE)\npar(mfrow = c(1, 2))\ntriplot.rda(spe.rda, site.sc = \"lc\", scaling = 1, cex.char2 = 0.7, pos.env = 3, \n            pos.centr = 1, mult.arrow = 1.1, mar.percent = 0.05, select.spe = sel.sp)\n\n\n\n-----------------------------------------------------------------------\nSite constraints (lc) selected. To obtain site scores that are weighted\nsums of species scores (default in vegan), argument site.sc must be set\nto wa.\n-----------------------------------------------------------------------\n\ntext(-0.92, 0.72, \"a\", cex = 2)\ntriplot.rda(spe.rda, site.sc = \"lc\", scaling = 2, cex.char2 = 0.7, pos.env = 3, \n            pos.centr = 1, mult.arrow = 1.1, mar.percent = 0.05, select.spe = sel.sp)\n\n\n\n-----------------------------------------------------------------------\nSite constraints (lc) selected. To obtain site scores that are weighted\nsums of species scores (default in vegan), argument site.sc must be set\nto wa.\n-----------------------------------------------------------------------\n\ntext(-2.82, 2, \"b\", cex = 2)\n\n\n\n# Global test of the RDA result\nanova(spe.rda, permutations = how(nperm = 999))\n\n\nPermutation test for rda under reduced model\nPermutation: free\nNumber of permutations: 999\n\nModel: rda(formula = spe.hel ~ ele + slo + dis + pH + har + pho + nit + amm + oxy + bod, data = env3)\n         Df Variance      F Pr(>F)    \nModel    12  0.36537 3.5523  0.001 ***\nResidual 16  0.13714                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Tests of all canonical axes\nanova(spe.rda, by = \"axis\", permutations = how(nperm = 999))\n\n\nPermutation test for rda under reduced model\nForward tests for axes\nPermutation: free\nNumber of permutations: 999\n\nModel: rda(formula = spe.hel ~ ele + slo + dis + pH + har + pho + nit + amm + oxy + bod, data = env3)\n         Df Variance       F Pr(>F)    \nRDA1      1 0.228083 26.6105  0.001 ***\nRDA2      1 0.053698  6.2649  0.006 ** \nRDA3      1 0.032119  3.7473  0.346    \nRDA4      1 0.023206  2.7074  0.767    \nRDA5      1 0.008699  1.0149  1.000    \nRDA6      1 0.007218  0.8421  1.000    \nRDA7      1 0.004869  0.5681  1.000    \nRDA8      1 0.002924  0.3412  1.000    \nRDA9      1 0.002141  0.2498  1.000    \nRDA10     1 0.001160  0.1353  1.000    \nRDA11     1 0.000914  0.1066  1.000    \nRDA12     1 0.000341  0.0397  1.000    \nResidual 16 0.137139                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n## Partial RDA: effect of water chemistry, holding physiography\n## constant\n\n# Simple syntax; X and W may be in separate tables of quantitative \n# variables\n(spechem.physio <- rda(spe.hel, envchem, envtopo))\n\n\nCall: rda(X = spe.hel, Y = envchem, Z = envtopo)\n\n              Inertia Proportion Rank\nTotal          0.5025     1.0000     \nConditional    0.2087     0.4152    3\nConstrained    0.1602     0.3189    7\nUnconstrained  0.1336     0.2659   18\nInertia is variance \n\nEigenvalues for constrained axes:\n   RDA1    RDA2    RDA3    RDA4    RDA5    RDA6    RDA7 \n0.09136 0.04590 0.00928 0.00625 0.00387 0.00214 0.00142 \n\nEigenvalues for unconstrained axes:\n    PC1     PC2     PC3     PC4     PC5     PC6     PC7     PC8 \n0.04643 0.02071 0.01746 0.01326 0.00975 0.00588 0.00512 0.00400 \n(Showing 8 of 18 unconstrained eigenvalues)\n\n\n\nsummary(spechem.physio)\n\n\n\n\n\n# Formula interface; X and W variables must be in the same \n# data frame\n(spechem.physio2 <- rda(spe.hel ~ pH + har + pho + nit + amm + oxy + bod \n        + Condition(ele + slo + dis), data = env2))\n\n\nCall: rda(formula = spe.hel ~ pH + har + pho + nit + amm + oxy\n+ bod + Condition(ele + slo + dis), data = env2)\n\n              Inertia Proportion Rank\nTotal          0.5025     1.0000     \nConditional    0.2087     0.4152    3\nConstrained    0.1602     0.3189    7\nUnconstrained  0.1336     0.2659   18\nInertia is variance \n\nEigenvalues for constrained axes:\n   RDA1    RDA2    RDA3    RDA4    RDA5    RDA6    RDA7 \n0.09136 0.04590 0.00928 0.00625 0.00387 0.00214 0.00142 \n\nEigenvalues for unconstrained axes:\n    PC1     PC2     PC3     PC4     PC5     PC6     PC7     PC8 \n0.04643 0.02071 0.01746 0.01326 0.00975 0.00588 0.00512 0.00400 \n(Showing 8 of 18 unconstrained eigenvalues)\n\n# Test of the partial RDA, using the results with the formula \n# interface to allow the tests of the axes to be run\nanova(spechem.physio2, permutations = how(nperm = 999))\n\n\nPermutation test for rda under reduced model\nPermutation: free\nNumber of permutations: 999\n\nModel: rda(formula = spe.hel ~ pH + har + pho + nit + amm + oxy + bod + Condition(ele + slo + dis), data = env2)\n         Df Variance      F Pr(>F)    \nModel     7  0.16023 3.0836  0.001 ***\nResidual 18  0.13362                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(spechem.physio2, permutations = how(nperm = 999), by = \"axis\")\n\n\nPermutation test for rda under reduced model\nForward tests for axes\nPermutation: free\nNumber of permutations: 999\n\nModel: rda(formula = spe.hel ~ pH + har + pho + nit + amm + oxy + bod + Condition(ele + slo + dis), data = env2)\n         Df Variance       F Pr(>F)    \nRDA1      1 0.091363 12.3078  0.001 ***\nRDA2      1 0.045904  6.1839  0.012 *  \nRDA3      1 0.009277  1.2497  0.968    \nRDA4      1 0.006250  0.8420  0.992    \nRDA5      1 0.003868  0.5210  0.998    \nRDA6      1 0.002145  0.2890  1.000    \nRDA7      1 0.001424  0.1919  0.993    \nResidual 18 0.133617                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Partial RDA triplots (with fitted site scores) \n# with function triplot.rda\n# Scaling 1\n#dev.new(title = \"Partial RDA\",width = 12, height = 6, noRStudioGD = TRUE)\npar(mfrow = c(1, 2))\ntriplot.rda(spechem.physio, site.sc = \"lc\", scaling = 1, \n            cex.char2 = 0.8, pos.env = 3, mar.percent = 0)\n\n\n\n-----------------------------------------------------------------------\nSite constraints (lc) selected. To obtain site scores that are weighted\nsums of species scores (default in vegan), argument site.sc must be set\nto wa.\n-----------------------------------------------------------------------\nNo factor, hence levels cannot be plotted with symbols; 'plot.centr' is set to FALSE\n\ntext(-0.58, 0.64, \"a\", cex = 2)\n\n# Scaling 2\ntriplot.rda(spechem.physio, site.sc = \"lc\", scaling = 2, cex.char2 = 0.8, \n            pos.env = 3, mult.spe = 1.1, mar.percent = 0.04)\n\n\n\n-----------------------------------------------------------------------\nSite constraints (lc) selected. To obtain site scores that are weighted\nsums of species scores (default in vegan), argument site.sc must be set\nto wa.\n-----------------------------------------------------------------------\nNo factor, hence levels cannot be plotted with symbols; 'plot.centr' is set to FALSE\n\ntext(-3.34, 3.64, \"b\", cex = 2)\n\n\n\n\nVariation partioning\n\n\n## Variation partitioning with two sets of explanatory variables\n\n# Explanation of fraction labels (two, three and four explanatory \n# matrices) with optional colours\npar(mfrow = c(1, 3), mar = c(1, 1, 1, 1))\nshowvarparts(2, bg = c(\"red\", \"blue\"))\nshowvarparts(3, bg = c(\"red\", \"blue\", \"yellow\"))\nshowvarparts(4, bg = c(\"red\", \"blue\", \"yellow\", \"green\"))\n\n\n\n## 1. Variation partitioning with all explanatory variables\n##    (except dfs)\n(spe.part.all <- varpart(spe.hel, envchem, envtopo))\n\n\n\nPartition of variance in RDA \n\nCall: varpart(Y = spe.hel, X = envchem, envtopo)\n\nExplanatory tables:\nX1:  envchem\nX2:  envtopo \n\nNo. of explanatory tables: 2 \nTotal variation (SS): 14.07 \n            Variance: 0.50251 \nNo. of observations: 29 \n\nPartition table:\n                     Df R.squared Adj.R.squared Testable\n[a+b] = X1            7   0.60579       0.47439     TRUE\n[b+c] = X2            3   0.41524       0.34507     TRUE\n[a+b+c] = X1+X2      10   0.73410       0.58638     TRUE\nIndividual fractions                                    \n[a] = X1|X2           7                 0.24131     TRUE\n[b]                   0                 0.23308    FALSE\n[c] = X2|X1           3                 0.11199     TRUE\n[d] = Residuals                         0.41362    FALSE\n---\nUse function 'rda' to test significance of fractions of interest\n\n# Plot of the partitioning results\npar(mfrow = c(1, 1))\nplot(spe.part.all, digits = 2, bg = c(\"red\", \"blue\"),\n     Xnames = c(\"Chemistry\", \"Physiography\"), \n     id.size = 0.7)\n\n\n\n\n\n\n\n",
    "preview": "statistik/Statistik7_01_Demo/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik7_02_Assigment/",
    "title": "Übung Statistik 7",
    "description": {},
    "author": [],
    "date": "2021-11-29",
    "categories": [
      "Statistik7"
    ],
    "contents": "\n\n\n\nÜbung 7.1: RDA (naturwissenschaftlich)\nFunktion triplot.rda.R\nMoordatensatz in library(dave) :\nsveg (Vegetationsdaten)\nssit (Umweltdaten)\nFührt eine RDA mit allen in der Vorlesung gezeigten Schritten durch und interpretiert die Ergebnisse.\nVon den Umweltvariablen entfallen x.axis & y.axis\nFür die partielle RDA und die Varianzpartitionierung bildet zwei Gruppen:\nPhysiographie (Waterlev.max, Waterlev.av, Waterlev.min, log.peat.lev, log slope.deg)\nChemie (alle übrigen)\n\n\n\n",
    "preview": {},
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik7_03_Solution/",
    "title": "Musterloesung Übung 7",
    "description": {},
    "author": [],
    "date": "2021-11-29",
    "categories": [
      "Statistik7"
    ],
    "contents": "\n\n\n\nMusterloesung Aufgabe 7.1: RDA\nR-Skript als Download\nLoesungstext\nÜbungsaufgabe (hier so ausführlich formuliert, wie dies auch in der Klausur der Fall sein wird)\nLadet die library dave, welche den Moordatensatz enthält. sveg beinhaltet presenceabsence-Daten aller untersuchten Arten in den Plots; ssit beinhaltet 18 metrische Umweltdaten sowie Koordinaten der Plots\nFührt eine RDA und eine Varianzpartizionierung in die Variablengruppen Physiographie (Waterlev.max, Waterlev.av, Waterlev.min, log.peat.lev, log slope.deg) und Chemie (alle übrigen) durch.\nFormuliert abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (ausformulierte schriftliche Zusammenfassung, mit je einem Absatz von ca. 60-100 Worten, resp. 3-8 Sätzen für den Methoden- und Ergebnisteil). D. h. alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden.\nWährend im Text normalerweise die Variablen ausgeschrieben werden solltet, genügt es hier (da ihr die entsprechenden Infos nicht bekommen habt und nur raten könntet), wenn ihr die Abkürzungen aus dem dataframe nehmt.\nMoordatensatz laden\n\n\nif(!require(dave)){install.packages(\"dave\")}\nlibrary(dave)\ndata(sveg)\ndata(ssit)\n\n\n\n\n\nsummary(sveg)\nsummary(ssit)\nstr(ssit)\n\n\n\n\n\n# x.axis and y.axis vom data frame data frame ssit entfernen\nenv2 <- ssit[, -c(19, 20)]\n\n\n\nBetrachtung der Daten zeigt, dass die Koordinaten in Spalten 19 und 20 sind, die daraufhin entfernt werden.\n\n\n# Generiere zwei subset der erklärenden Variablen\n# Physiografie (upstream-downstream-Gradient)\nenvtopo <- env2[, c(11 : 15)]\nnames(envtopo)\n\n\n[1] \"Waterlev.max\"  \"Waterlev.av\"   \"Waterlev.min\"  \"log.peat.lev\" \n[5] \"log.slope.deg\"\n\n# Chemie\nenvchem <- env2[, c(1:10, 16:18)]\nnames(envchem)\n\n\n [1] \"pH.peat\"        \"log.ash.perc\"   \"Ca_peat\"       \n [4] \"Mg_peat\"        \"Na_peat\"        \"K_peat\"        \n [7] \"Acidity.peat\"   \"CEC.peat\"       \"Base.sat.perc\" \n[10] \"P.peat\"         \"pH.water\"       \"log.cond.water\"\n[13] \"log.Ca.water\"  \n\n# Hellinger-transform the species dataset\nlibrary(vegan)\nspe.hel <- decostand(sveg, \"hellinger\")\n\n\n\nVorstehend wurden die Variablen in die zwei Gruppen Chemistry und Physiography aufgteilt. Die Hellilnger-Transformation wird gemeinhin empfohlen (wobei dahingestellt sei, ob sie auch bei presence-absence-Daten nötig ist). Die weiteren Analysen führen wir mit der default-Einstellung „Scaling 2“ durch. (Je nach Bedarf bzw. persönlichen Vorlieben könnte auch Scaling 1 genommen werden).\nRedundancy analysis (RDA)\nRDA of the Hellinger-transformed mire species data, constrained by all the environmental variables contained in env2\n\n\n## RDA der Hellinger-transformireten Moorarten-Daten, constrained\n## mit allen Umweltvarialben die in env2 enthalten sind\n(spe.rda <- rda(spe.hel ~ ., env2)) # Observe the shortcut formula\n\n\nCall: rda(formula = spe.hel ~ pH.peat + log.ash.perc + Ca_peat\n+ Mg_peat + Na_peat + K_peat + Acidity.peat + CEC.peat +\nBase.sat.perc + P.peat + Waterlev.max + Waterlev.av +\nWaterlev.min + log.peat.lev + log.slope.deg + pH.water +\nlog.cond.water + log.Ca.water, data = env2)\n\n              Inertia Proportion Rank\nTotal          0.4979     1.0000     \nConstrained    0.2773     0.5569   18\nUnconstrained  0.2206     0.4431   44\nInertia is variance \n\nEigenvalues for constrained axes:\n   RDA1    RDA2    RDA3    RDA4    RDA5    RDA6    RDA7    RDA8 \n0.13693 0.03784 0.01860 0.01110 0.00950 0.00882 0.00735 0.00670 \n   RDA9   RDA10   RDA11   RDA12   RDA13   RDA14   RDA15   RDA16 \n0.00603 0.00582 0.00498 0.00478 0.00411 0.00394 0.00310 0.00294 \n  RDA17   RDA18 \n0.00271 0.00205 \n\nEigenvalues for unconstrained axes:\n     PC1      PC2      PC3      PC4      PC5      PC6      PC7 \n0.018768 0.015312 0.013231 0.012074 0.011420 0.009385 0.008904 \n     PC8 \n0.008639 \n(Showing 8 of 44 unconstrained eigenvalues)\n\n\n\nsummary(spe.rda)  # Skalierung 2 (default)\n\n\n\n\n\n# Canonical coefficients from the rda object\ncoef(spe.rda)\n\n\n                        RDA1          RDA2         RDA3         RDA4\npH.peat         4.531329e-02  0.0828973389  0.010965288 -0.155085533\nlog.ash.perc   -1.949986e-02 -0.0359844539 -0.701312936  0.034317746\nCa_peat        -1.337537e-03 -0.0288554798  0.027228621  0.068880266\nMg_peat        -3.936852e-02  0.0901067458 -0.141325150 -0.070256979\nNa_peat        -9.247087e-02  0.4384377252  0.088851211 -0.248295480\nK_peat          6.296120e-02 -0.0699716499  0.015460922  0.314006668\nAcidity.peat    4.708024e-05 -0.0277547066  0.005448542  0.043747599\nCEC.peat        3.744129e-03  0.0297812515 -0.010532610 -0.040816301\nBase.sat.perc   1.129368e-03 -0.0041436746 -0.013166371 -0.005538586\nP.peat         -1.097201e-02 -0.0352965867 -0.063285184 -0.019908698\nWaterlev.max   -3.179331e-03 -0.0006509661 -0.015533249  0.038929542\nWaterlev.av     8.236051e-04 -0.0049269233  0.027915286 -0.018711058\nWaterlev.min    3.830259e-04 -0.0009284990  0.002283015  0.002325086\nlog.peat.lev   -1.168763e-01  0.1415162776  0.002413566 -0.271470076\nlog.slope.deg  -3.383155e-02  0.0016520826 -0.236646952  0.076539930\npH.water        6.367244e-02  0.0538977579  0.079825940  0.179498186\nlog.cond.water  6.110612e-03 -0.2600161375 -0.162560478  0.093945551\nlog.Ca.water    1.317034e-02 -0.0622061756 -0.023932814 -0.597437862\n                        RDA5          RDA6         RDA7         RDA8\npH.peat        -0.1892255621 -0.2118068056  0.071909611 -0.027538260\nlog.ash.perc    0.1802037523 -0.2669540104  0.724618282 -0.633888225\nCa_peat        -0.0007103952  0.0253977768  0.029045044 -0.021223056\nMg_peat         0.0994092273 -0.1176642458  0.100095923  0.381181043\nNa_peat         2.2386515374  0.7455515343  0.664234477 -0.718624356\nK_peat          0.1287939324 -0.2046202165 -0.441055492 -0.417918725\nAcidity.peat    0.0519802264  0.0270485440  0.071957387 -0.032035431\nCEC.peat       -0.0472321525 -0.0329326428 -0.053476411  0.032372963\nBase.sat.perc   0.0276382747  0.0003004136  0.012777988  0.002256490\nP.peat         -0.0401765601  0.0112976551  0.068766100  0.003460905\nWaterlev.max   -0.0456458872 -0.1345249731  0.097859198 -0.022480057\nWaterlev.av     0.0355444546  0.0722625146 -0.090790927  0.036951069\nWaterlev.min   -0.0105108162 -0.0136267137  0.017986436 -0.006832735\nlog.peat.lev   -0.5267908795 -0.2162043424 -0.274818126 -0.338891940\nlog.slope.deg  -0.2184244227  0.1500482029 -0.105292557  0.095365402\npH.water       -0.0425049325  0.1782004196 -0.059654515 -0.114988275\nlog.cond.water  0.0168002458  0.1815625052 -0.007997259 -0.464849052\nlog.Ca.water   -0.1033058867 -0.3899181259  0.078901455  0.315891985\n                       RDA9        RDA10       RDA11        RDA12\npH.peat        -0.012382751 -0.017468114 -0.06519173 -0.027412762\nlog.ash.perc   -0.965668438 -0.028793591  0.44461671  0.129536979\nCa_peat        -0.012619772 -0.107438326 -0.04460841 -0.103406142\nMg_peat        -0.158294076 -0.280166029  0.05634171 -0.070201766\nNa_peat         1.104751868  1.544769984 -1.39741894 -0.039845605\nK_peat         -0.534198927 -0.076296838 -0.22435445 -0.163742387\nAcidity.peat   -0.068974997 -0.087677482 -0.06530877 -0.046256867\nCEC.peat        0.047560024  0.083210188  0.06665024  0.077515801\nBase.sat.perc  -0.020829815  0.009830788  0.00910173  0.022643234\nP.peat          0.012695344 -0.003138906  0.03352924 -0.008483557\nWaterlev.max    0.012606335 -0.048317756  0.09623737 -0.013544370\nWaterlev.av     0.004208039  0.047229561 -0.08062624 -0.005265601\nWaterlev.min   -0.001054475 -0.005577274  0.01298239  0.007069788\nlog.peat.lev    0.003928806 -0.238217788  0.30310954  0.563613618\nlog.slope.deg  -0.057527637  0.291653459 -0.22134679  0.391384381\npH.water        0.212751287  0.111459569 -0.01131132 -0.090296584\nlog.cond.water  0.668937274 -0.008842423  0.03594579 -0.809188635\nlog.Ca.water   -1.090714519 -0.887533762 -0.45040221  0.927233456\n                      RDA13        RDA14        RDA15         RDA16\npH.peat        -0.104975398 -0.067972158  0.018701068  0.1485174317\nlog.ash.perc    0.377398995 -0.194930772  0.919823359 -0.0460514789\nCa_peat         0.114429353  0.021190482 -0.045772935 -0.0586146947\nMg_peat         0.268732885 -0.350138790  0.113874369  0.0939318308\nNa_peat         1.780098125  0.278280645 -0.213777421 -0.8329460427\nK_peat         -0.123997869 -0.105394480 -0.062226421 -0.0750622607\nAcidity.peat    0.033805349 -0.096815006  0.023817495 -0.0702792017\nCEC.peat       -0.068579244  0.054680669 -0.005738998  0.0663748635\nBase.sat.perc  -0.034283054 -0.039890903  0.034786341 -0.0054775951\nP.peat          0.043199360  0.071393270  0.052202136  0.0478902318\nWaterlev.max   -0.032439161  0.061094560 -0.047338261  0.0032500492\nWaterlev.av     0.023482438 -0.037716665  0.061946296 -0.0002491098\nWaterlev.min    0.002347459  0.007026893 -0.017849338  0.0015009609\nlog.peat.lev    0.160866568 -0.263156404  0.415682834 -0.5691321204\nlog.slope.deg   0.236877948 -0.219914297 -0.271490962 -0.4115760623\npH.water        0.120070232 -0.141903633 -0.018249431 -0.0414434431\nlog.cond.water  0.224126901 -0.817975382 -0.634193576  0.1319661957\nlog.Ca.water   -0.402746243  1.358028534  0.192611956 -0.2582206194\n                     RDA17         RDA18\npH.peat        -0.13349865  0.1701622100\nlog.ash.perc    1.35532652  0.4171590020\nCa_peat        -0.14093897  0.1568432425\nMg_peat        -0.04980116 -0.2684650074\nNa_peat         1.09568980 -0.3478060087\nK_peat          0.05144200  0.1752018988\nAcidity.peat   -0.09633424  0.0918662915\nCEC.peat        0.11471933 -0.0870338687\nBase.sat.perc   0.00801054 -0.0140300438\nP.peat         -0.02965954  0.0140083088\nWaterlev.max   -0.07021013 -0.0017944793\nWaterlev.av     0.05976381 -0.0001508213\nWaterlev.min   -0.01493811  0.0034494643\nlog.peat.lev   -0.16806725 -0.1448115821\nlog.slope.deg   0.06629741 -0.0655661508\npH.water        0.04361964 -0.1695726179\nlog.cond.water  0.28691611  0.3588429780\nlog.Ca.water    0.02520368 -0.2342020703\n\n# Unadjusted R^2 retrieved from the rda object\n(R2 <- RsquareAdj(spe.rda)$r.squared)\n\n\n[1] 0.5569395\n\n# Adjusted R^2 retrieved from the rda object\n(R2adj <- RsquareAdj(spe.rda)$adj.r.squared)\n\n\n[1] 0.3756874\n\nMan erhält R²adj. = 0.376 Jetzt kann man den Triplot erstellen\n\n\n## Triplots of the rda results (lc scores)\n## Site scores as linear combinations of the environmental variables\ndev.new(title = \"RDA scaling 1 and 2 + lc\", width = 15, height = 6, noRStudioGD = TRUE)\npar(mfrow = c(1, 2))\n\n# 1 und 2 Achse\nplot(spe.rda, display = c(\"sp\", \"lc\", \"cn\"), \n     main = \"Triplot RDA spe.hel ~ env2 - scaling 2 - lc scores\")\nspe.sc2 <- scores(spe.rda, choices = 1:2, display = \"sp\")\narrows(0, 0, spe.sc2[, 1] * 0.92, spe.sc2[, 2] * 0.92,length = 0,\n       lty = 1,col = \"red\")\ntext(-0.82, 0.55, \"b\", cex = 1.5)\n\n# 1 und 3 Achse\nplot(spe.rda, display = c(\"sp\", \"lc\", \"cn\"), choices = c(1,3),\n     main = \"Triplot RDA spe.hel ~ env2 - scaling 2 - lc scores\")\nspe.sc2 <- scores(spe.rda, choices = c(1,3), display = \"sp\")\narrows(0, 0, spe.sc2[, 1] * 0.92, spe.sc2[, 2] * 0.92,length = 0,\n       lty = 1,col = \"red\")\ntext(-0.82, 0.55, \"b\", cex = 1.5)\n\n\n## Triplots of the rda results (wa scores)\n## Site scores as weighted averages (vegan's default)\n# Scaling 1 :  distance triplot\ndev.new(title = \"RDA scaling 2 + wa\",width = 7, height = 6, noRStudioGD = TRUE)\n\n# Scaling 2 (default) :  correlation triplot\nplot(spe.rda, main = \"Triplot RDA spe.hel ~ env3 - scaling 2 - wa scores\")\narrows(0, 0, spe.sc2[, 1] * 0.92, spe.sc2[, 2] * 0.92, length = 0, lty = 1, col = \"red\")\n\n\n\nAuswahl der höchstkorrelierten Arten (Grenzwert kann subjektiv nach Bedarf gesetzt werden, hier 0.5).\n\n\n# Select species with goodness-of-fit at least 0.6 in the \n# ordination plane formed by axes 1 and 2\nspe.good <- goodness(spe.rda)\nsel.sp <- which(spe.good[, 2] >= 0.6)\nsel.sp\n\n# Triplots with homemade function triplot.rda()\nsource(\"triplot.rda.R\")\n\ndev.new(title = \"RDA plot with triplot.rda\", width = 7, height = 6, noRStudioGD = TRUE)\n\ntriplot.rda(spe.rda, site.sc = \"lc\", cex.char2 = 0.7, pos.env = 3, \n            pos.centr = 1, mult.arrow = 1.1, mar.percent = 0.05, select.spe = sel.sp)\n\n\n# Global test of the RDA result\nanova(spe.rda, permutations = how(nperm = 999))\n# Tests of all canonical axes\nanova(spe.rda, permutations = how(nperm = 999))\nanova(spe.rda, by = \"axis\", permutations = how(nperm = 999))\n\n\n\nDie ersten drei RDA-Achsen sind also signifikant. Man könnte also auch noch eine Visualisierung von RDA 3 vs. RDA 1 machen.\nPartielle RDA\nSimple syntax; X and W may be in separate tables of quantitative\nvariables\n\n\nspechem.physio <- rda(spe.hel, envchem, envtopo)\nsummary(spechem.physio)\n\n# Formula interface; X and W variables must be in the same \n# data frame\n(spechem.physio2 <- \n    rda(spe.hel ~ pH.peat + log.ash.perc + Ca_peat + Mg_peat + Na_peat\n       + K_peat + Acidity.peat + CEC.peat + Base.sat.perc + P.peat\n       + pH.water + log.cond.water + log.Ca.water\n       + Condition(Waterlev.max + Waterlev.av + Waterlev.min + log.peat.lev\n       + log.slope.deg), data = env2))\n\n# Test of the partial RDA, using the results with the formula \n# interface to allow the tests of the axes to be run\nanova(spechem.physio2, permutations = how(nperm = 999))\nanova(spechem.physio2, permutations = how(nperm = 999), by = \"axis\")\n\n# Partial RDA triplots (with fitted site scores) \n# with function triplot.rda\ndev.new(title = \"Partial RDA\", width = 7, height = 6, noRStudioGD = TRUE)\n\ntriplot.rda(spechem.physio, site.sc = \"lc\", scaling = 2, \n            cex.char2 = 0.8, pos.env = 3, mult.spe = 1.1, mar.percent = 0.04)\ntext(-3.34, 3.64, \"b\", cex = 2)\n\n\n\nVarianzpartitionierung\n\n\n## 1. Variation partitioning with all explanatory variables\n(spe.part.all <- varpart(spe.hel, envchem, envtopo))\n\n\n\nPartition of variance in RDA \n\nCall: varpart(Y = spe.hel, X = envchem, envtopo)\n\nExplanatory tables:\nX1:  envchem\nX2:  envtopo \n\nNo. of explanatory tables: 2 \nTotal variation (SS): 30.873 \n            Variance: 0.49795 \nNo. of observations: 63 \n\nPartition table:\n                     Df R.squared Adj.R.squared Testable\n[a+b] = X1           13   0.47805       0.33958     TRUE\n[b+c] = X2            5   0.24779       0.18181     TRUE\n[a+b+c] = X1+X2      18   0.55694       0.37569     TRUE\nIndividual fractions                                    \n[a] = X1|X2          13                 0.19388     TRUE\n[b]                   0                 0.14570    FALSE\n[c] = X2|X1           5                 0.03611     TRUE\n[d] = Residuals                         0.62431    FALSE\n---\nUse function 'rda' to test significance of fractions of interest\n\n# Plot of the partitioning results\ndev.new(title = \"Variation partitioning\", width = 7, height = 7, noRStudioGD = TRUE)\n\nplot(spe.part.all, digits = 2, bg = c(\"red\", \"blue\"),\n     Xnames = c(\"Chemistry\", \"Physiography\"), id.size = 0.7)\n\n\n\nDie durch die erhobenen Umweltvariablen insgesamt erklärte Varianz (37.6%, s.o.) entfällt zu 19.4% auf chemische Variablen, 3.6% auf physiographische Variablen und zu 14.6% auf gemeinsame Erklärung.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik8_01_Demo/",
    "title": "Demo Statistik 8",
    "description": {},
    "author": [
      {
        "name": "Jürgen Dengler",
        "url": {}
      }
    ],
    "date": "2021-11-23",
    "categories": [
      "Statistik8"
    ],
    "contents": "\n\nContents\nCluster-Analysen\nk-means clustering\nAgglomarative Clusteranalyse\nDendogramme berechnen und ploten\nCophenetic correlations\nOptimale Anzahl Cluster\nFinal dendrogram with the selected clusters\nMiscellaneous graphical outputs\n\n\n\n\n\nCluster-Analysen\nDemoscript als Download\nDatensatz Doubs.RData\nFunktion drawmap.R drawmap.R\nFunktion hcoplot.R hcoplot.R\nk-means clustering\n\n\n# das Moordatenset aus Wildi...\nif(!require(dave)){install.packages(\"dave\")}\nlibrary(dave)\npca <- rda(sveg^0.25, scale = TRUE)\nca <- cca(sveg^0.5)\n\nkmeans.1 <- kmeans(sveg, 4)\n\n\n\n\n\nkmeans.1\n\n\n\n\n\nplot(ca, type = \"n\")\npoints(ca, display = \"sites\", col = kmeans.1[[1]])\n\n\n\nkmeans.2 <- kmeans(sveg, 3)\nplot(pca, type = \"n\")\npoints(pca, display = \"sites\", pch=19, col = kmeans.2[[1]])\n\n\n\nplot(pca, choices = c(1, 3), type = \"n\")\npoints(pca, choices = c(1, 3), display = \"sites\", pch = 19, col=kmeans.2[[1]])\n\n\n\n# k-means partitioning, 2 to 10 groups\nKM.cascade <- cascadeKM(sveg,  inf.gr = 2, sup.gr = 10, iter = 100, criterion = \"ssi\")\nsummary(KM.cascade)\n\n\n          Length Class  Mode     \npartition 567    -none- numeric  \nresults    18    -none- numeric  \ncriterion   1    -none- character\nsize       90    -none- numeric  \n\nKM.cascade$results\n\n\n      2 groups     3 groups   4 groups     5 groups    6 groups\nSSE 1840.13571 1629.4399038 1488.29615 1378.3369048 1286.500541\nssi    0.26103    0.2710839    0.34537    0.3101318    0.385401\n        7 groups     8 groups     9 groups    10 groups\nSSE 1214.3219697 1156.7314935 1101.5523810 1053.1476190\nssi    0.4477016    0.4276022    0.4529737    0.5061619\n\nKM.cascade$partition\n\n\n    2 groups 3 groups 4 groups 5 groups 6 groups 7 groups 8 groups\n501        2        2        2        5        6        5        3\n502        2        2        4        2        1        2        8\n503        2        2        2        5        6        5        3\n504        2        2        2        5        6        5        3\n505        2        2        4        2        1        2        8\n506        2        2        2        5        1        2        8\n507        2        2        2        5        6        5        3\n508        2        2        2        5        6        5        3\n509        2        2        2        5        6        5        3\n510        2        2        4        2        5        3        1\n511        2        2        2        5        6        5        3\n512        2        2        4        2        1        2        8\n513        2        2        4        2        5        3        1\n514        2        2        4        2        1        2        8\n515        2        2        4        2        1        2        8\n516        2        2        4        2        1        2        8\n517        2        2        4        2        5        3        1\n518        1        1        1        3        4        7        7\n519        2        2        4        2        1        2        8\n520        2        2        4        2        5        3        1\n521        2        2        2        5        6        5        3\n522        2        2        4        2        1        2        8\n523        1        1        1        3        4        7        7\n524        2        2        2        5        6        5        3\n525        2        2        2        5        6        5        3\n526        1        3        3        3        4        7        7\n527        2        2        4        2        5        3        1\n528        2        2        4        2        5        3        1\n529        2        2        4        2        5        3        1\n530        2        2        4        2        5        3        1\n531        1        1        1        1        2        4        5\n532        2        2        4        2        5        3        1\n533        2        2        4        2        5        3        1\n534        2        1        1        1        2        4        5\n535        1        1        1        1        2        4        5\n536        2        2        4        2        5        3        1\n537        2        2        4        2        5        3        1\n538        1        1        1        3        4        7        7\n539        1        3        3        4        3        1        6\n540        2        2        2        5        6        5        3\n541        1        3        3        4        3        1        2\n542        1        3        3        4        3        1        6\n543        1        3        3        4        3        1        2\n544        2        1        1        1        2        4        5\n545        1        1        1        3        4        7        7\n546        1        1        1        1        2        4        5\n547        2        1        1        1        2        4        5\n548        1        3        3        4        3        1        2\n549        1        1        1        1        2        4        5\n550        1        1        1        1        2        4        5\n551        1        3        3        3        4        6        4\n552        1        3        3        4        3        1        2\n553        1        3        3        4        3        1        4\n554        1        3        3        3        4        6        4\n555        1        3        3        3        4        6        4\n556        1        3        3        4        3        1        2\n557        1        3        3        3        4        6        4\n558        1        3        3        3        4        6        4\n559        1        3        3        3        4        7        7\n560        1        3        3        3        4        7        7\n561        1        1        1        3        4        7        7\n562        1        3        3        4        3        1        6\n563        1        3        3        3        4        6        4\n    9 groups 10 groups\n501        5         5\n502        4         7\n503        5         5\n504        5         5\n505        4         7\n506        4         7\n507        5         5\n508        5         5\n509        5         5\n510        6         9\n511        5         8\n512        4         7\n513        7         3\n514        4         7\n515        4         7\n516        4         7\n517        6         9\n518        2         8\n519        4         7\n520        6         9\n521        6         9\n522        4         7\n523        2         2\n524        6         9\n525        6         9\n526        2         2\n527        7         3\n528        7         3\n529        7         3\n530        6         9\n531        9         1\n532        7         3\n533        6         9\n534        9         1\n535        9         1\n536        7         3\n537        7         3\n538        2         8\n539        1        10\n540        5         5\n541        3         6\n542        1        10\n543        3         6\n544        9         1\n545        2         2\n546        9         1\n547        7         3\n548        3         6\n549        9         1\n550        9         1\n551        8         4\n552        3         6\n553        8         4\n554        8         4\n555        8         4\n556        3         6\n557        8         4\n558        8         4\n559        2         2\n560        2         2\n561        2         2\n562        1        10\n563        8         4\n\n# k-means visualisation\nplot(KM.cascade, sortg = TRUE)\n\n\n\n\nAgglomarative Clusteranalyse\nmit Daten und Skripten aus Borcard et al. (2018)\n\n\nload(\"Doubs.RData\")  \n\n\n\n\n\n# Remove empty site 8\nspe <- spe[-8, ]\nenv <- env[-8, ]\nspa <- spa[-8, ]\nlatlong <- latlong[-8, ]\n\n\n\nDendogramme berechnen und ploten\n\n\n## Hierarchical agglomerative clustering of the species abundance \n\n# Compute matrix of chord distance among sites\nspe.norm <- decostand(spe, \"normalize\")\nspe.ch <- vegdist(spe.norm, \"euc\")\n\n# Attach site names to object of class 'dist'\nattr(spe.ch, \"Labels\") <- rownames(spe)\n\npar(mfrow = c(1, 1))\n\n# Compute single linkage agglomerative clustering\nspe.ch.single <- hclust(spe.ch, method = \"single\")\n# Plot a dendrogram using the default options\nplot(spe.ch.single, labels = rownames(spe), main = \"Chord - Single linkage\")\n\n\n\n# Compute complete-linkage agglomerative clustering\nspe.ch.complete <- hclust(spe.ch, method = \"complete\")\nplot(spe.ch.complete, labels = rownames(spe), main = \"Chord - Complete linkage\")\n\n\n\n# Compute UPGMA agglomerative clustering\nspe.ch.UPGMA <- hclust(spe.ch, method = \"average\")\nplot(spe.ch.UPGMA, labels = rownames(spe), main = \"Chord - UPGMA\")\n\n\n\n# Compute centroid clustering\nspe.ch.centroid <- hclust(spe.ch, method = \"centroid\")\nplot(spe.ch.centroid, labels = rownames(spe),  main = \"Chord - Centroid\")\n\n\n\n# Compute Ward's minimum variance clustering\nspe.ch.ward <-hclust(spe.ch, method = \"ward.D2\")\nplot(spe.ch.ward, labels = rownames(spe),  main = \"Chord - Ward\")\n\n\n\n# Compute beta-flexible clustering using cluster::agnes()\n# beta = -0.1\nspe.ch.beta1 <- agnes(spe.ch, method = \"flexible\", par.method = 0.55)\n# beta = -0.25\nspe.ch.beta2 <- agnes(spe.ch, method = \"flexible\", par.method = 0.625)\n# beta = -0.5\nspe.ch.beta3 <- agnes(spe.ch, method = \"flexible\", par.method = 0.75)\n# Change the class of agnes objects\nclass(spe.ch.beta1)\n\n\n[1] \"agnes\" \"twins\"\n\nspe.ch.beta1 <- as.hclust(spe.ch.beta1)\nclass(spe.ch.beta1)\n\n\n[1] \"hclust\"\n\nspe.ch.beta2 <- as.hclust(spe.ch.beta2)\nspe.ch.beta3 <- as.hclust(spe.ch.beta3)\n\npar(mfrow = c(2, 2))\nplot(spe.ch.beta1, labels = rownames(spe), main = \"Chord - Beta-flexible (beta=-0.1)\")\nplot(spe.ch.beta2, labels = rownames(spe), main = \"Chord - Beta-flexible (beta=-0.25)\")\nplot(spe.ch.beta3,  labels = rownames(spe),  main = \"Chord - Beta-flexible (beta=-0.5)\")\n\n# Compute Ward's minimum variance clustering\nspe.ch.ward <- hclust(spe.ch, method = \"ward.D2\")\nplot(spe.ch.ward, labels = rownames(spe), main = \"Chord - Ward\")\n\n\n\n\nCophenetic correlations\n\n\n# Single linkage clustering\nspe.ch.single.coph <- cophenetic(spe.ch.single)\ncor(spe.ch, spe.ch.single.coph)\n\n\n[1] 0.5015116\n\n# Complete linkage clustering\nspe.ch.comp.coph <- cophenetic(spe.ch.complete)\ncor(spe.ch, spe.ch.comp.coph)\n\n\n[1] 0.7567998\n\n# Average clustering\nspe.ch.UPGMA.coph <- cophenetic(spe.ch.UPGMA)\ncor(spe.ch, spe.ch.UPGMA.coph)\n\n\n[1] 0.8537529\n\n# Ward clustering\nspe.ch.ward.coph <- cophenetic(spe.ch.ward)\ncor(spe.ch, spe.ch.ward.coph)\n\n\n[1] 0.7821555\n\n# Shepard-like diagrams\npar(mfrow = c(2, 2))\nplot(spe.ch, spe.ch.single.coph,\n  xlab = \"Chord distance\", ylab = \"Cophenetic distance\",\n  asp = 1, xlim = c(0, sqrt(2)), ylim = c(0, sqrt(2)),\n  main = c(\"Single linkage\", paste(\"Cophenetic correlation =\",\n                                   round(cor(spe.ch, spe.ch.single.coph), 3))))\nabline(0, 1)\nlines(lowess(spe.ch, spe.ch.single.coph), col = \"red\")\n\nplot(spe.ch, spe.ch.comp.coph,\n  xlab = \"Chord distance\", ylab = \"Cophenetic distance\",\n  asp = 1, xlim = c(0, sqrt(2)), ylim = c(0, sqrt(2)),\n  main = c(\"Complete linkage\", paste(\"Cophenetic correlation =\",\n                                     round(cor(spe.ch, spe.ch.comp.coph), 3))))\nabline(0, 1)\nlines(lowess(spe.ch, spe.ch.comp.coph), col = \"red\")\n\nplot(spe.ch, spe.ch.UPGMA.coph,\n  xlab = \"Chord distance\", ylab = \"Cophenetic distance\",\n  asp = 1, xlim = c(0, sqrt(2)), ylim = c(0, sqrt(2)),\n  main = c(\"UPGMA\", paste(\"Cophenetic correlation =\",\n                          round( cor(spe.ch, spe.ch.UPGMA.coph), 3))))\nabline(0, 1)\nlines(lowess(spe.ch, spe.ch.UPGMA.coph), col = \"red\")\n\nplot(spe.ch, spe.ch.ward.coph,\n  xlab = \"Chord distance\", ylab = \"Cophenetic distance\",\n  asp = 1, xlim = c(0, sqrt(2)), ylim = c(0, max(spe.ch.ward$height)),\n  main = c(\"Ward\", paste(\"Cophenetic correlation =\", \n                         round(cor(spe.ch, spe.ch.ward.coph), 3))))\nabline(0, 1)\nlines(lowess(spe.ch, spe.ch.ward.coph), col = \"red\")\n\n\n\n\nOptimale Anzahl Cluster\n\n\n## Select a dendrogram (Ward/chord) and apply three criteria\n## to choose the optimal number of clusters\n\n# Choose and rename the dendrogram (\"hclust\" object)\nhc <- spe.ch.ward\n# hc <- spe.ch.beta2\n# hc <- spe.ch.complete\n\npar(mfrow = c(1, 2))\n\n# Average silhouette widths (Rousseeuw quality index)\nSi <- numeric(nrow(spe))\nfor (k in 2:(nrow(spe) - 1))\n{\n  sil <- silhouette(cutree(hc, k = k), spe.ch)\n  Si[k] <- summary(sil)$avg.width\n}\n\nk.best <- which.max(Si)\nplot(1:nrow(spe), Si, type = \"h\",\n  main = \"Silhouette-optimal number of clusters\",\n  xlab = \"k (number of clusters)\", ylab = \"Average silhouette width\")\naxis(1, k.best,paste(\"optimum\", k.best, sep = \"\\n\"), col = \"red\", \n     font = 2, col.axis = \"red\")\npoints(k.best,max(Si), pch = 16, col = \"red\",cex = 1.5)\n\n# Optimal number of clusters according to matrix correlation \n# statistic (Pearson)\n\n# Homemade function grpdist from Borcard et al. (2018)\ngrpdist <- function(X)\n{\n  require(cluster)\n  veg <- as.data.frame(as.factor(X))\n  distgr <- daisy(veg, \"gower\")\n  distgr\n} \n\nkt <- data.frame(k = 1:nrow(spe), r = 0)\nfor (i in 2:(nrow(spe) - 1)) \n{\n  gr <- cutree(hc, i)\n  distgr <- grpdist(gr)\n  mt <- cor(spe.ch, distgr, method = \"pearson\")\n  kt[i, 2] <- mt\n}\n\nk.best <- which.max(kt$r)\nplot(kt$k,kt$r, type = \"h\",\n  main = \"Matrix correlation-optimal number of clusters\",\n  xlab = \"k (number of clusters)\", ylab = \"Pearson's correlation\")\naxis(1, k.best, paste(\"optimum\", k.best, sep = \"\\n\"),\n  col = \"red\", font = 2, col.axis = \"red\")\npoints(k.best, max(kt$r), pch = 16, col = \"red\", cex = 1.5)\n\n\n\n# Optimal number of clusters according as per indicator species\n# analysis (IndVal, Dufrene-Legendre; package: labdsv)\nIndVal <- numeric(nrow(spe))\nng <- numeric(nrow(spe))\nfor (k in 2:(nrow(spe) - 1))\n{\n  iva <- indval(spe, cutree(hc, k = k), numitr = 1000)\n  gr <- factor(iva$maxcls[iva$pval <= 0.05])\n  ng[k] <- length(levels(gr)) / k\n  iv <- iva$indcls[iva$pval <= 0.05]\n  IndVal[k] <- sum(iv)\n}\n\nk.best <- which.max(IndVal[ng == 1]) + 1\ncol3 <- rep(1, nrow(spe))\ncol3[ng == 1] <- 3\n\npar(mfrow = c(1, 2))\nplot(1:nrow(spe), IndVal, type = \"h\",\n  main = \"IndVal-optimal number of clusters\",\n  xlab = \"k (number of clusters)\", ylab = \"IndVal sum\", col = col3)\naxis(1,k.best,paste(\"optimum\", k.best, sep = \"\\n\"),\n  col = \"red\", font = 2, col.axis = \"red\")\n\npoints(which.max(IndVal),max(IndVal),pch = 16,col = \"red\",cex = 1.5)\ntext(28, 15.7, \"a\", cex = 1.8)\n\nplot(1:nrow(spe),ng,\n  type = \"h\",\n  xlab = \"k (number of clusters)\",\n  ylab = \"Ratio\",\n  main = \"Proportion of clusters with significant indicator species\",\n  col = col3)\naxis(1,k.best,paste(\"optimum\", k.best, sep = \"\\n\"),\n     col = \"red\", font = 2, col.axis = \"red\")\npoints(k.best,max(ng), pch = 16, col = \"red\", cex = 1.5)\ntext(28, 0.98, \"b\", cex = 1.8)\n\n\n\n\nFinal dendrogram with the selected clusters\n\n\n# Choose the number of clusters\nk <- 4\n# Silhouette plot of the final partition\nspech.ward.g <- cutree(spe.ch.ward, k = k)\nsil <- silhouette(spech.ward.g, spe.ch)\nrownames(sil) <- row.names(spe)\n\nplot(sil, main = \"Silhouette plot - Chord - Ward\", cex.names = 0.8, col = 2:(k + 1), nmax = 100)\n\n\n\n# Reorder clusters\nif(!require(gclus)){install.packages(\"gclus\")}\nlibrary(\"gclus\")\nspe.chwo <- reorder.hclust(spe.ch.ward, spe.ch)\n\n# Plot reordered dendrogram with group labels\npar(mfrow = c(1, 1))\nplot(spe.chwo,hang = -1, xlab = \"4 groups\", ylab = \"Height\", sub = \"\",\n  main = \"Chord - Ward (reordered)\", labels = cutree(spe.chwo, k = k))\nrect.hclust(spe.chwo, k = k)\n\n\n\n# Plot the final dendrogram with group colors (RGBCMY...)\n# Fast method using the additional hcoplot() function:\n# Usage:\n# hcoplot(tree = hclust.object,\n#   diss = dissimilarity.matrix,\n#   lab = object labels (default NULL),\n#   k = nb.clusters,\n#   title = paste(\"Reordered dendrogram from\",deparse(tree$call),\n#   sep=\"\\n\"))\nsource(\"hcoplot.R\")\nhcoplot(spe.ch.ward, spe.ch, lab = rownames(spe), k = 4)\n\n\n\n# Plot the Ward clusters on a map of the Doubs River\n# (see Chapter 2)\nsource(\"drawmap.R\")\ndrawmap(xy = spa, clusters = spech.ward.g, main = \"Four Ward clusters along the Doubs River\")\n\n\n\n\nMiscellaneous graphical outputs\n\n\n# konvertieren von \"hclust\" Objekt in ein Dendogram Objekt\ndend <- as.dendrogram(spe.ch.ward)\n\n# Heat map of the dissimilarity matrix ordered with the dendrogram\nheatmap(as.matrix(spe.ch), Rowv = dend, symm = TRUE, margin = c(3, 3))\n\n\n\n# Ordered community table\n# Species are ordered by their weighted averages on site scores.\n# Dots represent absences.\nlibrary(vegan)\nor <- vegemite(spe, spe.chwo)\n\n\n                                    \n      32222222222  111111     1111  \n      098762105439598765064732213481\n Icme 5432121.......................\n Abbr 54332431.....1................\n Blbj 54542432.1...1................\n Anan 54432222.....111..............\n Gyce 5555443212...11...............\n Scer 522112221...21................\n Cyca 53421321.....1111.............\n Rham 55432333.....221..............\n Legi 35432322.1...1111.............\n Alal 55555555352..322..............\n Chna 12111322.1...211..............\n Titi 53453444...1321111.21.........\n Ruru 55554555121455221..1..........\n Albi 53111123.....2341.............\n Baba 35342544.....23322.........1..\n Eslu 453423321...41111..12.1....1..\n Gogo 5544355421..242122111......1..\n Pefl 54211432....41321..12.........\n Pato 2211.222.....3344.............\n Sqce 3443242312152132232211..11.1..\n Lele 332213221...52235321.1........\n Babl .1111112...32534554555534124..\n Teso .1...........11254........23..\n Phph .1....11...13334344454544455..\n Cogo ..............1123......2123..\n Satr .1..........2.12341345555355.3\n Thth .1............11.2......2134..\n30 sites, 27 species\n\n\n\n\n",
    "preview": "statistik/Statistik8_01_Demo/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "statistik/Statistik8_02_Assigment/",
    "title": "Übung Statistik 8",
    "description": {},
    "author": [],
    "date": "2021-11-11",
    "categories": [
      "Statistik8"
    ],
    "contents": "\nUebung 8.1: Clusteranalyse (sozioökonomisch)\nDatensatz crime2.csv\nRaten von 7 Kriminalitätsformen pro 100000 Einwohner und Jahr für die Bundesstaaten der USA\n(a) Führt eine k-means- und eine agglomerative Clusteranalyse eurer Wahl durch.\n(b) Überlegt in beiden Fällen, wie viele Cluster sinnvoll sind (k-means z. B.visuelle Betrachtung einer PCA, agglomerative Clusteranalyse z. B. SilhouettePlot).\n(c) Abschliessend entscheidet euch für eine Clusterung und vergleicht die erhaltenen Cluster bezüglich der Kriminalitätsformen mittels ANOVA und interpretiert die Cluster entsprechend.\nHinweis:\nWegen der sehr ungleichen Varianzen muss auf jeden Fall eine Standardisierung stattfinden, damit Distanzen zwischen den verschiedenen Kriminalitätsraten sinnvoll berechnet werden können\n\n\n\n",
    "preview": {},
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {}
  },
  {
    "path": "statistik/Statistik8_03_Solution/",
    "title": "Musterloesung Übung 8",
    "description": {},
    "author": [],
    "date": "2021-11-25",
    "categories": [
      "Statistik8"
    ],
    "contents": "\n\n\n\nMusterloesung Aufgabe 8.1: Clusteranalysen\nR-Skript als Download\nLoesungstext\nÜbungsaufgabe\n(hier so ausführlich formuliert, wie dies auch in der Klausur der Fall sein wird)\nLadet den Datensatz crime2.csv. Dieser enthält Raten von 7 Kriminatlitätsformen pro 100000 Einwohner und Jahr für die Bundesstaaten der USA.\nFührt eine k-means- und eine agglomerative Clusteranalyse eurer Wahl durch. Bitte beachet, dass wegen der sehr ungleichen Varianzen in jedem Fall eine Standardisierung stattfinden muss, damit die Distanzen zwischen den verschiedenen Kriminalitätsraten sinnvoll berechnet werden können.\nÜberlegt in beiden Fällen, wie viele Cluster sinnvoll sind (k-means: z. B. visuelle Betrachtung einer PCA, agglomertive Clusteranalyse: z. B. Silhoutte-Plot).\nEntscheidet euch dann für eine der beiden Clusterungen und vergleicht dann die erhaltenen Cluster bezüglich der Kriminalitätsformen und interpretiert die Cluster entsprechend.\nBitte erklärt und begründet die einzelnen Schritte, die ihr unternehmt, um zu diesem Ergebnis zu kommen. Dazu erstellt bitte ein Word-Dokument, in das ihr Schritt für Schritt den verwendeten R-Code, die dazu gehörigen Ausgaben von R, eure Interpretation derselben und die sich ergebenden Schlussfolgerungen für das weitere Vorgehen dokumentieren.\nFormuliert abschliessend einen Methoden- und Ergebnisteil (ggf. incl. adäquaten Abbildungen) zu dieser Untersuchung in der Form einer wissenschaftlichen Arbeit (ausformulierte schriftliche Zusammenfassung, mit je einem Absatz von ca. 60-100 Worten, resp. 3-8 Sätzen für den Methoden- und Ergebnisteil). D. h. alle wichtigen Informationen sollten enthalten sein, unnötige Redundanz dagegen vermieden werden.\nAbzugeben sind am Ende (a) Ein lauffähiges R-Skript; (b) begründeter Lösungsweg (Kombination aus R-Code, R Output und dessen Interpretation) und (c) ausformulierter Methoden- und Ergebnisteil (für eine wiss. Arbeit).\nUebung 8.1 - Clusteranalysen – Loesung\n\n\ncrime <- read.csv(\"crime2.csv\", sep = \";\")\n\n\n\n\n\ncrime\n\n\n\nIm mitgelieferten R-Skript habe ich die folgenden Analysen zunächst mit untransformierten, dann mit standardisierten Kriminalitätsraten berechnet. Ihr könnt die Ergebnisse vergleichen und seht, dass sie sehr unterschiedlich ausfallen.\n\n\ncrimez <- crime\ncrimez[,c(2:8)] <- lapply(crime[, c(2:8)], scale)\ncrimez\n\n\n    X      Murder        Rape       Robbery     Assault     Burglary\n1  ME -1.38246619 -1.31559240 -1.0464120463 -1.24765744 -0.938630226\n2  NH -1.32457397 -0.85298774 -1.0830960795 -1.31950227 -1.053079880\n3  VT -1.38246619 -0.83227410 -1.1014380961 -1.24047295 -0.590512528\n4  MA -0.91932843 -0.28681488  0.4668043222  0.39758933 -0.299619657\n5  RI -0.94827454 -0.85989229 -0.2118502916 -0.60105391  0.232094361\n6  CT -0.62986734 -0.69418316  0.4576333139 -0.50765562  0.003195053\n7  NY  1.13584533 -0.23157851  3.4106979845  1.11603770  0.058035512\n8  NJ -0.45619068 -0.04515574  1.1638009525 -0.07658660 -0.299619657\n9  PA -0.36935236 -0.60442405  0.0907929821 -0.71600564 -1.100767236\n10 OH -0.36935236  0.32768980 -0.0009171008 -0.29212111 -0.497522184\n11 IN -0.22462181 -0.54918767 -0.4778095321 -0.64416081 -0.738343331\n12 IL  0.61481536 -0.10039211  1.6773774169  1.13759115 -0.039723567\n13 MI  1.30952199  2.31619936  1.4572732179  1.06574631  0.744733437\n14 WI -1.06405898 -0.94965140 -0.6337166731 -0.81658842 -0.986317582\n15 MN -1.23773564 -0.14181940 -0.3677574326 -0.91717119 -0.459372299\n16 IA -1.44035840 -1.47439698 -0.9180179302 -0.69445219 -0.573821954\n17 MO  0.70165369 -0.32133762  0.2558711314  0.67778419 -0.144635750\n18 ND -1.67192728 -1.53653790 -1.2390032205 -1.75057130 -1.935295964\n19 SD -0.80354400 -1.11536053 -1.1564641459 -1.35542469 -1.532337807\n20 NE -1.06405898 -0.63894678 -0.8354788556 -0.65852977 -1.069770455\n21 KS -0.68775956 -0.06586938 -0.5695196150 -0.16998488 -0.020648625\n22 DE -0.54302901  1.59122191 -0.1659952501 -0.24901420 -0.368766323\n23 MD  0.64376147  0.67291716  1.4847862428  1.43933946  0.236863097\n24 VA  0.09378539 -0.50776039 -0.3310733994 -0.78066600 -0.914786548\n25 WV -0.25356792 -1.03250597 -0.9271889385 -1.26921089 -1.363047694\n26 NC  0.38324649 -0.51466494 -0.4961515487  0.56283245  0.067572983\n27 SC  0.52797704  0.51411257 -0.3952704575  1.79137916  0.341775280\n28 GA  1.28057588  0.69363080  0.6593954963  0.31137552  0.611208841\n29 FL  1.42530643  1.30123094  2.0625597653  2.36613786  2.442403307\n30 KY -0.02199904 -0.74251499 -0.5420065902 -0.38551939 -0.888558502\n31 TN  1.04900701  0.90767176  0.6043694466 -0.01192624  0.306009763\n32 AL  0.96216868 -0.37657400 -0.2760473496  0.95079457 -0.089795291\n33 MS  1.28057588 -0.55609222 -0.7070847395 -0.74474358 -0.287697818\n34 AR  0.38324649 -0.34205126 -0.5695196150  0.01681169 -0.397378737\n35 LA  1.74371363  0.43125801  0.7511055793  1.48244636  0.630283783\n36 OK  0.38324649  0.17578977 -0.3219023911  0.06710308  1.407587684\n37 TX  1.94633640  1.22528092  0.8978417120  0.56283245  2.032292046\n38 MT -1.12195120 -1.14297872 -1.1197801127 -1.13270570 -0.986317582\n39 ID -1.03511287 -0.95655595 -1.1106091044 -0.70163668 -0.461756667\n40 WY -0.42724457 -0.82536956 -1.1014380961 -0.23464524 -0.905249077\n41 CO  0.06483929  0.58315804  0.0265959241  0.38322036  1.419509523\n42 NM  1.36741421  0.90076721 -0.1109692004  1.88477745  1.545881016\n43 AZ  0.73059980  0.63148987  0.2467001231  1.15914460  1.696096187\n44 UT -1.03511287 -0.59061496 -0.7621107892 -0.68726771 -0.671581033\n45 NV  1.68582141  2.14358568  1.3288791018  0.56283245  0.971248378\n46 WA -0.51408290  1.34956277 -0.0651141589 -0.22746075  1.584030901\n47 OR -0.05094515  1.19075819  0.5860274300  0.07428756  1.836773887\n48 CA  1.30952199  0.76267627  1.8424555662  1.76264123  1.190610215\n49 AK  0.52797704  2.68214035 -0.4961515487  0.90050319 -0.082642188\n50 HI -0.57197512 -0.19705577 -0.3310733994 -1.24047295  0.339390912\n          Theft     Vehicle\n1  -0.759700660 -1.04035426\n2  -0.944578268 -0.73523707\n3  -0.294181505 -0.95930750\n4  -0.969849308  2.49709812\n5  -0.465758565  1.53883946\n6  -0.213048167  0.30883580\n7   0.007740919  1.21465245\n8  -0.127924664  1.87732884\n9  -1.681428588 -0.13453761\n10 -0.457778237 -0.02965358\n11 -0.778321427 -0.25849147\n12  0.026361685  1.17174535\n13  0.611585766  1.99174778\n14 -0.154525758 -0.61128321\n15 -0.177136689 -0.44918971\n16 -0.155855813 -1.06895899\n17 -0.556202287  0.27069615\n18 -1.156056970 -1.25012232\n19 -1.302362990 -1.35023890\n20 -0.320782600 -1.02128443\n21  0.119465516 -0.59221339\n22  0.228530004 -0.52546900\n23  0.079563874  0.77604649\n24 -0.526941083 -0.77814417\n25 -2.075124788 -1.01651698\n26 -0.658616501 -0.83058619\n27 -0.096003350 -0.50163172\n28  0.087544202  0.22778905\n29  1.934990222  1.02872166\n30 -1.567043881 -0.90209803\n31 -1.053642756  0.77127904\n32 -0.816893014 -0.54930628\n33 -1.427388135 -1.10709864\n34 -0.815562959 -0.89256312\n35  0.663457900  0.28499852\n36  0.297692850  1.27186192\n37  1.421589096  1.58174656\n38  0.526462263 -0.79721400\n39 -0.157185868 -0.95930750\n40  0.212569347 -1.01651698\n41  1.746122450  0.49476659\n42  1.055824046 -0.18697963\n43  1.887108252  0.17534703\n44  1.537303858 -0.75907435\n45  0.759221841  0.45662694\n46  1.794004420 -0.32046839\n47  1.655678729  0.09430028\n48  0.619566094  1.81058445\n49  1.319174882  1.05732640\n50  1.118336618 -0.25849147\n\n„scale“ führt eine Standardisierung (z-Transformation) durch, so dass alle Variablen anschiessen einen Mittelwert von 0 und eine SD von 1 haben, ausgenommen natürlich die 1. Spalte mit den Kürzeln der Bundesstaaten. Anschliessend wird das SSI-Kriterium getestet und zwar für Partitionierungen von 2 bis 6 Gruppen (wie viele Gruppen man maximal haben will, muss man pragmatisch nach der jeweiligen Fragestelltung entscheiden).\n\n\nlibrary(vegan)\ncrimez.KM.cascade <- cascadeKM(crimez[,c(2:8)],\n                        inf.gr = 2, sup.gr = 6, iter = 100, criterion = \"ssi\")\nsummary(crimez.KM.cascade)\n\n\n          Length Class  Mode     \npartition 250    -none- numeric  \nresults    10    -none- numeric  \ncriterion   1    -none- character\nsize       30    -none- numeric  \n\ncrimez.KM.cascade$results\n\n\n      2 groups   3 groups   4 groups   5 groups  6 groups\nSSE 174.959159 144.699605 124.437221 108.119280 95.316398\nssi   1.226057   1.304674   1.555594   1.539051  1.351146\n\ncrimez.KM.cascade$partition\n\n\n   2 groups 3 groups 4 groups 5 groups 6 groups\n1         1        2        3        1        6\n2         1        2        3        1        6\n3         1        2        3        1        6\n4         2        1        1        4        1\n5         1        1        2        4        1\n6         1        1        2        4        2\n7         2        1        1        2        3\n8         2        1        1        4        1\n9         1        2        2        5        2\n10        1        1        2        5        2\n11        1        2        2        5        2\n12        2        1        1        2        3\n13        2        3        4        2        5\n14        1        2        3        1        6\n15        1        2        3        1        6\n16        1        2        3        1        6\n17        2        1        2        5        3\n18        1        2        3        1        6\n19        1        2        3        1        6\n20        1        2        3        1        6\n21        1        2        2        5        2\n22        1        1        2        5        2\n23        2        1        1        2        3\n24        1        2        2        5        2\n25        1        2        3        1        6\n26        1        1        2        5        2\n27        2        1        2        5        3\n28        2        1        4        2        3\n29        2        3        4        2        5\n30        1        2        2        5        2\n31        2        1        1        5        3\n32        1        1        2        5        2\n33        1        2        2        5        2\n34        1        2        2        5        2\n35        2        3        4        2        3\n36        2        1        4        3        4\n37        2        3        4        2        5\n38        1        2        3        1        6\n39        1        2        3        1        6\n40        1        2        3        1        6\n41        2        3        4        3        4\n42        2        3        4        3        4\n43        2        3        4        3        4\n44        1        2        3        1        6\n45        2        3        4        2        5\n46        2        3        4        3        4\n47        2        3        4        3        4\n48        2        3        4        2        5\n49        2        3        4        3        4\n50        1        2        2        1        2\n\n# k-means visualisation\nlibrary(cclust)\nplot(crimez.KM.cascade, sortg = TRUE)\n\n\n\n\nNach SSI ist die 4-Gruppenlösung die beste, mit dieser wird also weitergerechnet.\n\n\n# 4 Kategorien sind nach SSI offensichtlich besonders gut\nmodelz <- kmeans(crimez[,c(2:8)], 4)\nmodelz\n\n\nK-means clustering with 4 clusters of sizes 6, 16, 14, 14\n\nCluster means:\n        Murder       Rape    Robbery    Assault     Burglary\n1  0.344651676  0.1527746  1.4679727  0.6670075 -0.006342418\n2 -0.002098593 -0.2436615 -0.2668763 -0.1457373 -0.279054485\n3 -1.088869933 -0.9575423 -0.9573223 -1.0018455 -0.966220768\n4  0.943560464  1.1705377  0.6331926  0.8825420  1.287858358\n       Theft    Vehicle\n1 -0.3396250  1.3846917\n2 -0.5371659 -0.3276196\n3 -0.3729397 -0.9310433\n4  1.1323972  0.7120264\n\nClustering vector:\n [1] 3 3 3 1 2 2 1 1 2 2 2 1 4 3 3 3 2 3 3 3 2 2 1 2 3 2 2 4 4 2 1 2 2\n[34] 2 4 4 4 3 3 3 4 4 4 3 4 4 4 4 4 2\n\nWithin cluster sum of squares by cluster:\n[1] 16.59050 39.51883 19.37307 48.95481\n (between_SS / total_SS =  63.7 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"    \n[5] \"tot.withinss\" \"betweenss\"    \"size\"         \"iter\"        \n[9] \"ifault\"      \n\n#File für ANOVA (Originaldaten der Vorfälle, nicht die ztransformierten)\ncrime.KM4 <- data.frame(crime,modelz[1])\ncrime.KM4$cluster <- as.factor(crime.KM4$cluster)\ncrime.KM4\n\n\n    X Murder Rape Robbery Assault Burglary Theft Vehicle cluster\n1  ME    2.0 14.8      28     102      803  2347     164       3\n2  NH    2.2 21.5      24      92      755  2208     228       3\n3  VT    2.0 21.8      22     103      949  2697     181       3\n4  MA    3.6 29.7     193     331     1071  2189     906       1\n5  RI    3.5 21.4     119     192     1294  2568     705       2\n6  CT    4.6 23.8     192     205     1198  2758     447       2\n7  NY   10.7 30.5     514     431     1221  2924     637       1\n8  NJ    5.2 33.2     269     265     1071  2822     776       1\n9  PA    5.5 25.1     152     176      735  1654     354       2\n10 OH    5.5 38.6     142     235      988  2574     376       2\n11 IN    6.0 25.9      90     186      887  2333     328       2\n12 IL    8.9 32.4     325     434     1180  2938     628       1\n13 MI   11.3 67.4     301     424     1509  3378     800       4\n14 WI    3.1 20.1      73     162      783  2802     254       3\n15 MN    2.5 31.8     102     148     1004  2785     288       3\n16 IA    1.8 12.5      42     179      956  2801     158       3\n17 MO    9.2 29.2     170     370     1136  2500     439       2\n18 ND    1.0 11.6       7      32      385  2049     120       3\n19 SD    4.0 17.7      16      87      554  1939      99       3\n20 NE    3.1 24.6      51     184      748  2677     168       3\n21 KS    4.4 32.9      80     252     1188  3008     258       2\n22 DE    4.9 56.9     124     241     1042  3090     272       2\n23 MD    9.0 43.6     304     476     1296  2978     545       1\n24 VA    7.1 26.5     106     167      813  2522     219       2\n25 WV    5.9 18.9      41      99      625  1358     169       3\n26 NC    8.1 26.4      88     354     1225  2423     208       2\n27 SC    8.6 41.3      99     525     1340  2846     277       2\n28 GA   11.2 43.9     214     319     1453  2984     430       4\n29 FL   11.7 52.7     367     605     2221  4373     598       4\n30 KY    6.7 23.1      83     222      824  1740     193       2\n31 TN   10.4 47.0     208     274     1325  2126     544       1\n32 AL   10.1 28.4     112     408     1159  2304     267       2\n33 MS   11.2 25.8      65     172     1076  1845     150       2\n34 AR    8.1 28.9      80     278     1030  2305     195       2\n35 LA   12.8 40.1     224     482     1461  3417     442       4\n36 OK    8.1 36.4     107     285     1787  3142     649       4\n37 TX   13.5 51.6     240     354     2049  3987     714       4\n38 MT    2.9 17.3      20     118      783  3314     215       3\n39 ID    3.2 20.0      21     178     1003  2800     181       3\n40 WY    5.3 21.9      22     243      817  3078     169       3\n41 CO    7.0 42.3     145     329     1792  4231     486       4\n42 NM   11.5 46.9     130     538     1845  3712     343       4\n43 AZ    9.3 43.0     169     437     1908  4337     419       4\n44 UT    3.2 25.3      59     180      915  4074     223       3\n45 NV   12.6 64.9     287     354     1604  3489     478       4\n46 WA    5.0 53.4     135     244     1861  4267     315       4\n47 OR    6.6 51.1     206     286     1967  4163     402       4\n48 CA   11.3 44.9     343     521     1696  3384     762       4\n49 AK    8.6 72.7      88     401     1162  3910     604       4\n50 HI    4.8 31.0     106     103     1339  3759     328       2\n\nstr(crime.KM4)\n\n\n'data.frame':   50 obs. of  9 variables:\n $ X       : chr  \"ME\" \"NH\" \"VT\" \"MA\" ...\n $ Murder  : num  2 2.2 2 3.6 3.5 4.6 10.7 5.2 5.5 5.5 ...\n $ Rape    : num  14.8 21.5 21.8 29.7 21.4 23.8 30.5 33.2 25.1 38.6 ...\n $ Robbery : int  28 24 22 193 119 192 514 269 152 142 ...\n $ Assault : int  102 92 103 331 192 205 431 265 176 235 ...\n $ Burglary: int  803 755 949 1071 1294 1198 1221 1071 735 988 ...\n $ Theft   : int  2347 2208 2697 2189 2568 2758 2924 2822 1654 2574 ...\n $ Vehicle : int  164 228 181 906 705 447 637 776 354 376 ...\n $ cluster : Factor w/ 4 levels \"1\",\"2\",\"3\",\"4\": 3 3 3 1 2 2 1 1 2 2 ...\n\nVon den agglomerativen Clusterverfahren habe ich mich für Ward’s minimum variance clustering entschieden, da dieses allgemein als besonders geeignet gilt.\nVor der Berechnung von crime.norm und crime.ch muss man die Spalte mit den Bundesstaatenkürzeln entfern.\n\n\n#Agglomerative Clusteranalyse\ncrime2 <- crime[,-1]\ncrime.norm <- decostand(crime2, \"normalize\")\ncrime.ch <- vegdist(crime.norm, \"euc\")\n# Attach site names to object of class 'dist'\nattr(crime.ch, \"Labels\") <- crime[,1]\n\n#Ward's minimum variance clustering\ncrime.ch.ward <- hclust(crime.ch, method = \"ward.D2\")\npar(mfrow = c(1, 1))\nplot(crime.ch.ward, labels = crime[,1], main = \"Chord - Ward\")\n\n# Choose and rename the dendrogram (\"hclust\" object)\nhc <- crime.ch.ward\n# hc <- spe.ch.beta2\n# hc <- spe.ch.complete\ndev.new(title = \"Optimal number of clusters\", width = 12, height = 8, noRStudioGD = TRUE)\ndev.off()\npar(mfrow = c(1, 2))\n\n\n# Average silhouette widths (Rousseeuw quality index)\nlibrary(cluster)\nSi <- numeric(nrow(crime))\nfor (k in 2:(nrow(crime) - 1))\n{\n sil <- silhouette(cutree(hc, k = k), crime.ch)\n Si[k] <- summary(sil)$avg.width\n}\nk.best <- which.max(Si)\nplot( 1:nrow(crime), Si, type = \"h\",\n main = \"Silhouette-optimal number of clusters\",\n xlab = \"k (number of clusters)\", ylab = \"Average silhouette width\")\n\naxis(1, k.best, paste(\"optimum\", k.best, sep = \"\\n\"), col = \"red\",\n font = 2, col.axis = \"red\")\npoints(k.best, max(Si), pch = 16, col = \"red\", cex = 1.5)\n\n\n\nDemnach wären beim Ward’s-Clustering nur zwei Gruppen die optimale Lösung.\nFür die Vergleiche der Bundesstaatengruppen habe ich mich im Folgenden für die k-means Clusterung mit 4 Gruppen entschieden.\nDamit die Boxplots und die ANOVA direkt interpretierbar sind, werden für diese, anders als für die Clusterung, die untransformierten Incidenz-Werte verwendet (also crime statt crimez). Die Spalte mit der Clusterzugehörigkeit im Fall von k-means mit 4 Clustern hängt man als Spalte an (Achtung: muss als Faktor definiert werden!).\nAnschliessend kann man die 7 ANOVAs rechnen, die Posthoc-Vergleiche durchführen und die zugehörigen Boxplots mit Buchstaben für die homogenen Gruppen erzeugen. Sinnvollerweise gruppiert man die Abbildungen gleich, z. B. je 2 x 2. Das Skript ist hier simple für jede Verbrechensart wiederholt. Erfahrenere R-Nutzer können das Ganze hier natürlich durch eine Schleife abkürzen.\n\n\nlibrary(multcomp)\nif(!require(multcomp)){install.packages(\"multcomp\")}\nlibrary(multcomp)\npar(mfrow = c(3,3))\n\nANOVA.Murder <- aov(Murder~cluster, data = crime.KM4)\nsummary(ANOVA.Murder)\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncluster      3  355.4  118.46   23.75 1.96e-09 ***\nResiduals   46  229.4    4.99                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nletters <- cld(glht(ANOVA.Murder, linfct = mcp(cluster = \"Tukey\")))\nboxplot(Murder~cluster, xlab = \"Cluster\", ylab = \"Murder\", data = crime.KM4)\nmtext(letters$mcletters$Letters, at = 1:6)\n\nANOVA.Rape <- aov(Rape~cluster,data = crime.KM4)\nsummary(ANOVA.Rape)\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncluster      3   6945  2315.0   31.95 2.58e-11 ***\nResiduals   46   3333    72.5                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nletters <- cld(glht(ANOVA.Rape, linfct = mcp(cluster = \"Tukey\")))\nboxplot(Rape~cluster, xlab = \"Cluster\", ylab = \"Rape\", data = crime.KM4)\nmtext(letters$mcletters$Letters, at = 1:6)\n\nANOVA.Robbery <- aov(Robbery~cluster, data = crime.KM4)\nsummary(ANOVA.Robbery)\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncluster      3 386563  128854   30.24 5.96e-11 ***\nResiduals   46 196025    4261                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nletters <- cld(glht(ANOVA.Robbery, linfct = mcp(cluster = \"Tukey\")))\nboxplot(Robbery~cluster, xlab = \"Cluster\", ylab = \"Robbery\", data = crime.KM4)\nmtext(letters$mcletters$Letters, at = 1:6)\n\nANOVA.Assault <- aov(Assault~cluster, data = crime.KM4)\nsummary(ANOVA.Assault)\n\n\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ncluster      3 541786  180595   20.39 1.51e-08 ***\nResiduals   46 407517    8859                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nletters <- cld(glht(ANOVA.Assault, linfct = mcp(cluster = \"Tukey\")))\nboxplot(Assault~cluster, xlab = \"Cluster\", ylab = \"Assault\",  data = crime.KM4)\nmtext(letters$mcletters$Letters, at = 1:6)\n\nANOVA.Burglary <- aov(Burglary~cluster, data = crime.KM4)\nsummary (ANOVA.Burglary)\n\n\n            Df  Sum Sq Mean Sq F value  Pr(>F)    \ncluster      3 6602474 2200825   50.21 1.5e-14 ***\nResiduals   46 2016382   43834                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nletters <- cld(glht(ANOVA.Burglary, linfct=mcp(cluster = \"Tukey\")))\nboxplot(Burglary~cluster, data = crime.KM4, xlab = \"Cluster\", ylab = \"Burglary\")\nmtext(letters$mcletters$Letters, at=1:6)\n\nANOVA.Theft <- aov(Theft~cluster, data = crime.KM4)\nsummary(ANOVA.Theft)\n\n\n            Df   Sum Sq Mean Sq F value   Pr(>F)    \ncluster      3 14249791 4749930   16.25 2.44e-07 ***\nResiduals   46 13448760  292364                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nletters <- cld(glht(ANOVA.Theft, linfct = mcp(cluster = \"Tukey\")))\nboxplot(Theft~cluster, xlab = \"Cluster\", ylab = \"Theft\", data = crime.KM4)\nmtext(letters$mcletters$Letters, at = 1:6)\n\nANOVA.Vehicle <- aov(Vehicle~cluster, data = crime.KM4)\nsummary(ANOVA.Vehicle)\n\n\n            Df  Sum Sq Mean Sq F value   Pr(>F)    \ncluster      3 1427939  475980   30.08 6.46e-11 ***\nResiduals   46  727932   15825                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nletters <- cld(glht(ANOVA.Vehicle, linfct = mcp(cluster = \"Tukey\")))\nboxplot(Vehicle~cluster, data = crime.KM4, xlab = \"Cluster\", ylab = \"Vehicle\")\nmtext(letters$mcletters$Letters, at = 1:6)\n\n\n\n\nDie Boxplots erlauben jetzt auch eine Beurteilung der Modelldiagnostik: sind die Residuen hinreichen normalverteilt (symmetrisch) und sind die Varianzen zwischen den Kategorien einigermassen ähnlich. Mit der Symmetrie/Normalverteilung sieht es OK aus. Die Varianzhomogenität ist nicht optimal – meist deutlich grössere Varianz bei höheren Mittelwerten. Eine log-Transformation hätte das verbessert und könnte hier gut begründet werden. Da die p-Werte sehr niedrig waren und die Varianzheterogenität noch nicht extrem war, habe ich aber von einer Transformation abgesehen, da jede Transformation die Interpretation der Ergebnisse erschwert. Jetzt muss man nur noch herausfinden, welche Bundesstaaten überhaupt zu welchem der vier Cluster gehören, sonst ist das ganze schöne Ergebnis nutzlos. Z. B. kann man in R auf den Dataframe clicken und ihn nach cluster sortieren.\n\n\n\n",
    "preview": "statistik/Statistik8_03_Solution/distill-preview.png",
    "last_modified": "2021-12-16T14:51:08+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  }
]
