[
  {
    "path": "rauman/RaumAn1_Uebung_A/",
    "title": "Übungen A: Einführung",
    "description": {},
    "author": [
      {
        "name": "Patrick Laube",
        "url": {}
      },
      {
        "name": "Nils Ratnaweera",
        "url": {}
      },
      {
        "name": "Nikolaos Bakogiannis",
        "url": {}
      }
    ],
    "date": "2021-11-29",
    "categories": [
      "RaumAn1"
    ],
    "contents": "\n\nContents\nAufgabe 1: Vektor Daten runterladen und importieren\nAufgabe 2: Daten Visualisieren\nInput: Koodinatensysteme\nAufgabe 3: Koordinatensyteme transformieren\nAufgabe 4: Chloroplethen Karte\n\nEs gibt bereits eine Vielzahl von Packages um in R mit räumlichen Daten zu arbeiten, die ihrerseits wiederum auf weiteren Packages basieren (Stichwort dependencies). Für Vektordaten dominierte lange das Package sp, welches nun durch sf abgelöst wurde. Wir werden wenn immer möglich mit sf arbeiten und nur in Ausnahmefällen auf andere Packages zurück greifen.\nFür die kommenden Übungen könnt ihr folgende Packages installieren bzw. laden:\n\n\nlibrary(sf)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n\n\nAufgabe 1: Vektor Daten runterladen und importieren\nLade zunächst die Datensätze unter folgenden Links herunter:\n\nkantone.gpkg (Quelle: Swisstopo)\ngemeinden.gpkg (Quelle: Swisstopo)\n\nEs handelt sich um Geodatensätze im Format Geopackage (“*.gpkg”), eine alternatives Datenformat zum bekannteren Format “Shapefiles”. Importiere die Datensätze wie folgt:\n\n\nkantone <- read_sf(\"kantone.gpkg\")\ngemeinden <- read_sf(\"gemeinden.gpkg\") \n\n\n\nSchau Dir die importierten Datensätze an. Am meisten Informationen zu sf Objekten bekommst du, wenn du dir den Datensatz in der Konsole anschaust (in dem du den Variabel-Name in der Konsole eintippst). Mit dem RStudio Viewer werden sf Objekte nur sehr langsam geladen und die Metadaten werden nicht angezeigt.\nAufgabe 2: Daten Visualisieren\nVektordaten (sf Objekte) lassen sich teilweise sehr schön in die bekannten Tidyverse workflows integrieren. Das merkt man schnell, wenn man die Daten visualisieren möchte. In InfoVis 1 & 2 haben wir intensiv mit ggplot2 gearbeitet und dort die Layers geom_point() und geom_line() kennen gelernt. Zusätzlich beinhaltet ggplot die Möglichkeit, mit geom_sf() Vektordaten direkt und sehr einfach zu plotten. Führe die angegebenen R-Befehle aus und studiere die entstehenden Plots. Welche Unterschiede findest Du? Wie erklärst Du diese Unterschiede?\n\n\nggplot(gemeinden) + \n  geom_sf()\n\n\n\nggplot(kantone) + \n  geom_sf()\n\n\n\n\nInput: Koodinatensysteme\nIn der obigen visualierung fällt folgendes auf:\ndie X/Y Achsen weisen zwei ganz unterschiedlichen Zahlenbereiche auf (vergleiche die Achsenbeschriftungen)\nder Umriss der Schweiz sieht in den beiden Datensätzen unterschiedlich aus (kantone ist gegenüber gemeinden gestaucht)\nDies hat natürlich damit zu tun, dass die beiden Datensätze in unterschiedlichen Koordinatensystemen erfasst wurden. Koordinatensysteme werden mit CRS (Coordinate Reference System) abgekürzt. Mit st_crs() könnnen die zugewiesenen Koordinatensysteme abgefragt werden.\n\n\nst_crs(kantone)\n\n\nCoordinate Reference System: NA\n\nst_crs(gemeinden)\n\n\nCoordinate Reference System: NA\n\nLeider sind in unserem Fall keine Koordinatensysteme zugewiesen. Mit etwas Erfahrung kann man das Koordinatensystem aber erraten, so viele kommen nämlich gar nicht in Frage. Am häufigsten trifft man hierzulande eines der drei folgenden Koordinatensysteme an:\nCH1903 LV03: das alte Koordinatensystem der Schweiz\nCH1903+ LV95: das neue Koordinatensystem der Schweiz\nWGS84: ein häufig genutztes weltumspannendes geodätisches Koordinatensystem, sprich die Koordinaten werden in Länge und Breite angegeben (Lat/Lon).\nNun gilt es, anhand der Koordinaten die in der Spalte geometry ersichtlich sind das korrekte Koordinatensystem festzustellen. Wenn man sich auf epsg.io/map die Schweiz anschaut, kann man die Koordinaten in verschiedenen Koordinatensystem betrachten.\nBedienungshinweise:\n\nKoordinanten (des Fadenkreuzes) werden im ausgewählten Koordinatensystem dargestellt\n\nDas Koordinatensystem, in welchem die Koordinaten dargestellt werden sollen, kann mit “Change” angepasst werden\n\nFür Enthusiasten: Schau Dir die Schweiz in verschiedenen Koordinatensystemen an, in dem Du auf “Reproject Map” klickst\n\nWenn man diese Koordinaten mit den Koordinaten unserer Datensätze vergleicht, dann ist schnell klar, dass es sich beim Datensatz kantone um das Koordinatensystem WGS84 handelt und bei gemeinden das Koordinatensystem CH1903+ LV95. Diese Koordinatensyteme weisen wir nun mit st_set_crs() und dem entsprechenden EPSG-Code (siehe die jeweiligen Links) zu.\n\n\nkantone <- st_set_crs(kantone, 4326)\ngemeinden <- st_set_crs(gemeinden, 2056)\n\n# zuweisen mit st_set_crs(), abfragen mit st_crs()\nst_crs(kantone)\n\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\nAuch wenn das CRS der Datensätze bekannt ist, nutzt ggplot immer noch EPSG 4326 um die Achsen zu beschriften. Wenn das stört, kann man coord_sf(datum = 2056) in einem weiteren Layer spezifizieren. Oder aber man blendet die Achsenbeschriftung mit theme_void() komplett aus. Versuche beide Varianten.\n\n\n\nAufgabe 3: Koordinatensyteme transformieren\nIn der vorherigen Übung haben wir das bestehende Koordinatensystem zugewiesen. Dabei haben wir die bestehenden Koordinaten (in der Spalte geom) nicht manipuliert. Ganz anders ist eine Transformation der Daten von einem Koordinatensystem in das andere. Bei einer Transformation werden die Koordinaten in das neue Koordinatensystem umgerechnet und somit manipuliert. Aus praktischen Gründen wollen  wir all unsere Daten ins neue Schweizer Koordinatensystem CH1903+ LV95 transfomieren. Transformiere den Datensatz kantone mit st_transform()in CH1903+ LV95, nutze dafür den korrekten EPSG-Code.\nVor der Transformation (betrachte die Attribute Bounding box sowie Geodetic CRS):\n\n\nkantone\n\n\nSimple feature collection with 51 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 5.955902 ymin: 45.81796 xmax: 10.49217 ymax: 47.80845\nGeodetic CRS:  WGS 84\n# A tibble: 51 × 7\n   NAME       KANTONSNUM SEE_FLAECH KANTONSFLA KT_TEIL EINWOHNERZ\n * <chr>           <dbl>      <dbl>      <dbl> <chr>        <dbl>\n 1 Graubünden         18         NA     710530 0           199021\n 2 Bern                2      11897     595951 1          1039474\n 3 Valais             23       1060     522463 0           345525\n 4 Vaud               22      39097     321202 1           805098\n 5 Ticino             21       7147     281215 0           351491\n 6 St. Gallen         17       7720     202820 1           510734\n 7 Zürich              1       6811     172894 0          1539275\n 8 Fribourg           10       7818     167142 1           321783\n 9 Luzern              3       6438     149352 0           413120\n10 Aargau             19        870     140380 1           685845\n# … with 41 more rows, and 1 more variable: geom <POLYGON [°]>\n\n\n\n\nNach der Transformation (betrachte die Attribute Bounding box sowie Projected CRS):\n\n\nkantone\n\n\nSimple feature collection with 51 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2485410 ymin: 1075268 xmax: 2833858 ymax: 1295934\nProjected CRS: CH1903+ / LV95\n# A tibble: 51 × 7\n   NAME       KANTONSNUM SEE_FLAECH KANTONSFLA KT_TEIL EINWOHNERZ\n * <chr>           <dbl>      <dbl>      <dbl> <chr>        <dbl>\n 1 Graubünden         18         NA     710530 0           199021\n 2 Bern                2      11897     595951 1          1039474\n 3 Valais             23       1060     522463 0           345525\n 4 Vaud               22      39097     321202 1           805098\n 5 Ticino             21       7147     281215 0           351491\n 6 St. Gallen         17       7720     202820 1           510734\n 7 Zürich              1       6811     172894 0          1539275\n 8 Fribourg           10       7818     167142 1           321783\n 9 Luzern              3       6438     149352 0           413120\n10 Aargau             19        870     140380 1           685845\n# … with 41 more rows, and 1 more variable: geom <POLYGON [m]>\n\nAufgabe 4: Chloroplethen Karte\nNun wollen wir die Gemeinden respektive die Kantone nach ihrer Einwohnerzahl einfärben. Dafür verwenden wir wie gewohnt die Methode aes(fill = ...) von ggplot.\nTips:\num die scientific notation (z.B. 3e+03) zu verhindern, könnt ihr den Befehl options(scipen = 999) ausführen\num die Darstellung der Gemeinde- (bzw. Kantons-) Grenzen zu verhindern, könnt ihr im entsprechenden Layer color = NA setzen. Alternativ könnt ihr die Linienbreite mit size = verändern.\n\n\n\nFigure 1: Der Vergleich dieser beiden Darstellungen veranschaulicht die MAUP Problematik sehr deutlich\n\n\n\n\n\n\n",
    "preview": "rauman/RaumAn1_Uebung_A/distill-preview.png",
    "last_modified": "2021-12-02T08:40:09+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "rauman/RaumAn1_Uebung_B/",
    "title": "Übung B Spatial Joins",
    "description": {},
    "author": [
      {
        "name": "Patrick Laube",
        "url": {}
      },
      {
        "name": "Nils Ratnaweera",
        "url": {}
      },
      {
        "name": "Nikolaos Bakogiannis",
        "url": {}
      }
    ],
    "date": "2021-11-26",
    "categories": [
      "RaumAn1"
    ],
    "contents": "\n\nContents\nAufgabe 1: Geopackage “Layers”\nAufgabe 2: Datensätze erkunden\nAufgabe 3: Spatial Join mit Punkten\nAufgabe 4: Spaital Join mit Flächen\n\n\n\n\nFür die kommende Übung arbeiten wir mit nachstehendem Datensatz. Lade diesen Herunter und importiere ihn in R.\n\ngruental.gpkg\n\nZudem brauchen wir die folgenden libraries:\n\n\nlibrary(dplyr)\nlibrary(sf)\nlibrary(ggplot2)\n\n\n\nAufgabe 1: Geopackage “Layers”\nAllenfalls ist euch beim Importieren des Geopackage gruental.pgkg folgende Warnmeldung aufgefallen:\nWarning message:\nIn evalq((function (..., call. = TRUE, immediate. = FALSE, noBreaks. = FALSE,  :\n  automatically selected the first layer in a data source containing more than one.\nDiese Warnmeldung weist darauf hin, dass das Geopackage gruental.gpkg mehrere Layers (rep. Datensätze) enthält und nur der erste Layer importiert wurde. Bringe mit dem Befehl st_layers die Layer Namen in Erfahrung und nutze diese im Anschluss in st_read (als Argument layer =) um die layers einzeln zu importieren und in variablen zu speichern (zB in als Variable wiesen und baeume).\nAufgabe 2: Datensätze erkunden\nNimm dir etwas Zeit und erkunde die beiden Datensätze. Nutze dafür auch die Visualisierungsmöglichkeiten von ggplot (insbesondere geom_sf).\n\n\n\nFigure 1: Beispielsweise kannst du die Daten in dieser Weise visualisieren.\n\n\n\nAufgabe 3: Spatial Join mit Punkten\nWir wollen nun für jeden Baum wissen, ob er sich in einer Wiese befindet oder nicht. Dazu nutzen wir die GIS-Technik Spatial Join, die in der Vorlesung beschrieben wurde. In sf können wir Spatial Joins mit der Funktion st_join durchführen, dabei gibt es nur left sowie inner-Joins (vgl. PrePro 1 & 2). So müssen die Punkte “Links”, also an erste Stelle aufgeführt werden, da wir ja Attribute an die Punkte anheften wollen.\nBeachte, dass der Output eine neue Spalte flaechen_typ aufweist. Diese ist leer (NA) wenn sich der entsprechende Baum nicht in einer Wiese befindet. Wie viele Bäume befinden sich in einer Wiese, wie viele nicht?\n\n\n\nAufgabe 4: Spaital Join mit Flächen\nAnalog der Vorlesung wollen wir nun in Erfahrung bringen, wie hoch der Wiesen-Anteil im Umkreis von 20m um jeden Baum ist. Dazu sind folgende Schritte nötig:\nAls erster Schritt müssen wir jeden Baum mit einem 20m Puffer verstehen. Nutze dazu st_buffer um speichere den Output als baeume_20m. Schau dir baeume_20m nun genau an. Um welchen Geometrietyp handelt es sich dabei nun?\nBerechnen nun die Schnittmenge aus baeume_20m und wiesen mit der Funktion st_intersection und speichere den Output als baeume_wiesen. Exploriere nun baeume_wiesen, auch mit ggplot(). Was ist passiert? Überprüfe die Anzahl Zeilen pro Datensatz. Haben die sich verändert? Wenn ja, warum?\nBerechnen nun die Flächengrösse pro Geometrie mit der Funktion st_area(). Speichere den Output in einer neuen Spalte von baeume_wiesen (z.B. mit dem Namen wiesen_flaeche). Tipp: Konvertiere den Output aus st_area einen nummerischen Vektor mit as.numeric().\nBerechne nun aus wiesen_flaeche den wiesen_anteil. Tipp: 100% ist die Kreisfläche aus \\(r^2\\times \\pi\\), wobei in unserem Fall \\(r = 20\\) entspricht.\nUm die berechneten Werte in den Datensatz baeume zu überführen braucht es noch folgende Schritte:\nKonvertiere baeume_wiesen in eine data.frame mit st_drop_geometry und speichere diese als baeume_wiesen_df\nNutze die Spalte baum_id in baeume_wiesen_df um den berechneten wiesen_anteil in den Datenatz baeume zu überführen. Tipp: Nutze dafür einen left_join\nErsetze alle NA Werte in der Spalte wiesen_anteil mit 0.\n\n\n\n\n\n\nFigure 2: Nach dieser Übung kannst du das Resultat optional in dieser Weise visualisieren.\n\n\n\n\n\n\n",
    "preview": "rauman/RaumAn1_Uebung_B/distill-preview.png",
    "last_modified": "2021-12-02T08:40:09+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "rauman/RaumAn2_Uebung_A/",
    "title": "Übung A: G-Function",
    "description": "Analyse von Punktverteilungen",
    "author": [
      {
        "name": "Patrick Laube",
        "url": {}
      },
      {
        "name": "Nils Ratnaweera",
        "url": {}
      },
      {
        "name": "Nikolaos Bakogiannis",
        "url": {}
      }
    ],
    "date": "2021-11-30",
    "categories": [
      "RaumAn2"
    ],
    "contents": "\n\nContents\nAufgabe 1\nAufgabe 2\nAufgabe 3\n\n\nAufgabe 1\nFür die heutige Übung benötigen wir nachstehende Datensätze. Lade diese herunter und importiere sie in R. Prüfe, ob das CRS korrekt gesetzt wurde, setze es wenn nötig. Mache dich mit den Daten vertraut (visualieren, durchscrollen usw).\n\n\n\n\nrotmilan.gpkg\nschweiz.gpkg\nluftqualitaet.gpkg\n\nDer Datensatz rotmilan.gpkg stammt aus einem grösseren Forschungsprojekt der Vogelwarte Sempach Mechanismen der Populationsdynamik beim Rotmilan. Der Datensatz wurde über die Plattform movebank zur Verfügung gestellt. Es handelt sich dabei um ein einzelnes Individuum, welches seit 2017 mit einem Sender versehen ist und über ganz Mitteleuropa zieht. Wir arbeiten in dieser Übung nur mit denjenigen Datenpunkten, die in der Schweiz erfasst wurden. Wer den ganzen Datensatz analysieren möchte, kann sich diesen über den Movebank-Link runterladen.\n\n\n\n\n\n\nFigure 1: Eine solche Visualisierung zeigt dir beispielsweise die räumliche Ausdehnung der Datenpunkte\n\n\n\nAufgabe 2\nAls erstes berechnen wir die G-Function für die Rotmilanpositionen:\nSchritt 1:\nMit st_distance() können Distanzen zwischen zwei sf Datensätze berechnet werden. Wird nur ein Datensatz angegeben, wird eine Kreuzmatrix erstellt wo die Distanzen zwischen allen Features zu allen anderen Features dargestellt werden. Wir nützen diese Funktion zur Berechnung der nächsten Nachbarn.\n\n\nrotmilan_distanzmatrix <- st_distance(rotmilan)\n\nnrow(rotmilan_distanzmatrix)\n\n\n[1] 2305\n\nncol(rotmilan_distanzmatrix)\n\n\n[1] 2305\n\n# zeige die ersten 6 Zeilen und Spalten der Matrix\n# jeder Wert ist 2x vorhanden (vergleiche Wert [2,1] mit [1,2])\n# die Diagonale ist die Distanz zu sich selber (gleich 0)\nrotmilan_distanzmatrix[1:6,1:6] \n\n\nUnits: [m]\n         [,1]      [,2]      [,3]     [,4]     [,5]     [,6]\n[1,]     0.00 14362.044 20272.492 35596.07 52519.10 64156.67\n[2,] 14362.04     0.000  8149.486 29752.74 44809.10 53775.25\n[3,] 20272.49  8149.486     0.000 22580.04 36848.93 45662.55\n[4,] 35596.07 29752.737 22580.037     0.00 17223.26 31439.57\n[5,] 52519.10 44809.096 36848.926 17223.26     0.00 16499.19\n[6,] 64156.67 53775.250 45662.554 31439.57 16499.19     0.00\n\nSchritt 2\nNun wollen wir wissen, wie gross die kürzeste Distanz von jedem Punkt zu seinem nächsten Nachbarn beträgt, also die kürzeste Distanz pro Zeile. Bevor wir diese ermitteln müssen wir die diagonalen Werte noch entfernen, denn diese stellen ja jeweils die Distanz zu sich selber dar und sind immer 0. Danach kann mit apply() eine Funktion (FUN = min) über die Zeilen (MARGIN = 1) einer Matrix (X = rotmilan_distanzmatrix) gerechnet werden. Zusätzlich müssen wir noch na.rm = TRUE setzen, damit NA Werte von der Berechnung ausgeschlossen werden. Das Resultat ist ein Vektor mit gleich vielen Werten wie Zeilen in der Matrix.\n\n\ndiag(rotmilan_distanzmatrix) <- NA # entfernt alle diagonalen Werte\n\nrotmilan_distanzmatrix[1:6,1:6] \n\n\nUnits: [m]\n         [,1]      [,2]      [,3]     [,4]     [,5]     [,6]\n[1,]       NA 14362.044 20272.492 35596.07 52519.10 64156.67\n[2,] 14362.04        NA  8149.486 29752.74 44809.10 53775.25\n[3,] 20272.49  8149.486        NA 22580.04 36848.93 45662.55\n[4,] 35596.07 29752.737 22580.037       NA 17223.26 31439.57\n[5,] 52519.10 44809.096 36848.926 17223.26       NA 16499.19\n[6,] 64156.67 53775.250 45662.554 31439.57 16499.19       NA\n\nrotmilan_mindist <- apply(rotmilan_distanzmatrix,1,min, na.rm = TRUE)\n\n\n\nSchritt 3\nNun müssen wir die Distanzen nach ihrer Grösse sortieren\n\n\nrotmilan_mindist <- sort(rotmilan_mindist) \n\n\n\nSchritt 4\nJetzt berechnen wir die kummulierte Häufigkeit von jeder Distanz berechnen. Die kummulierte Häufikgeit vom ersten Wert ist 1 (der Index des ersten Wertes) dividiert durch die Anzahl Werte insgesamt. Mit seq_along erhalten wir die Indizes aller Werte, mit lenth die Anzahl Werte insgesamt.\n\n\nkumm_haeufgikeit <- seq_along(rotmilan_mindist) / length(rotmilan_mindist)\n\n\n\nSchritt 5\nNun wollen wir die kumulierte Häufigkeit der Werte in einer Verteilungsfunktion (engl: Empirical Cumulative Distribution Function, ECDF) darstellen. Dafür müssen wir die beiden Vektoren zuerst noch in einen Dataframe packen, damit ggplot damit klar kommt.\n\n\nrotmilan_mindist_df <- data.frame(distanzen = rotmilan_mindist,\n                                  kumm_haeufgikeit = kumm_haeufgikeit)\n\n\n\np <- ggplot() + \n  geom_line(data = rotmilan_mindist_df, aes(distanzen, kumm_haeufgikeit)) +\n  labs(x = \"Distanz (Meter)\", y = \"Häufigkeit (kummuliert)\")\n\np\n\n\n\n\nLesehilfe:\n\n\n\nAufgabe 3\nFühre nun die gleichen Schritte mit luftqualitaet durch und vergleiche die ECDF-Plots.\n\n\n\n\n\n\n",
    "preview": "rauman/RaumAn2_Uebung_A/distill-preview.png",
    "last_modified": "2021-12-02T08:40:09+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "rauman/RaumAn2_Uebung_B/",
    "title": "Übung B: Räumliche Interpolation",
    "description": "Räumliche Interpolationen",
    "author": [
      {
        "name": "Patrick Laube",
        "url": {}
      },
      {
        "name": "Nils Ratnaweera",
        "url": {}
      },
      {
        "name": "Nikolaos Bakogiannis",
        "url": {}
      }
    ],
    "date": "2021-11-30",
    "categories": [
      "RaumAn2"
    ],
    "contents": "\n\n\n\nIn dieser Übung geht es darum, zwei verschiedene Interpolationsverfahren in R umzusetzen. Im ersten Interpolationsverfahren verwenden wir die inverse distance weighted interpolation, später verwenden wir die nearest neighbour methode. Dazu braucht ihr die folgenden Packages:\n\n\nlibrary(sf)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nlibrary(gstat) # <- ggf. installieren!\n\n\n\nWeiter benötigt ihr die nachstehenden Datensätze:\n\nschweiz.gpkg\nluftqualitaet.gpkg\n\nDie Library gstat bietet verschiedene Möglichkeiten, Datenpunkte zu interpolieren, unter anderem auch die inverse distance weighted Methode. Leider ist das Package noch nicht so benutzerfreundlich wie sf: Das Package wird aber aktuell überarbeitet und in mittlerer Zukunft sollte es ebenso einfach zugänglich sein. Damit Ihr Euch nicht mit den Eigenheiten dieser Library umschlagen müsst, haben wir eine Function vorbereitet, die Euch die Verwendung der IDW-Interpolation erleichtern soll.\nWir nehmen Euch damit etwas Komplexität weg und liefern Euch ein pfannenfertiges Werkzeug. Das hat auch Nachteile und wir ermutigen alle, die dafür Kapazität haben, unsere Function eingehend zu studieren und allenfalls ganz auf die Function zu verzichten und stattdessen direkt gstat zu verwenden. Wenn ihr mit unserer Function arbeiten möchtet, müsst ihr den unten stehenden Code in euer Skript kopieren und ausführen.\n\n\nmy_idw <- function(groundtruth,column,cellsize, nmax = Inf, maxdist = Inf, idp = 2, extent = NULL){\n  library(gstat)\n  library(sf)\n  \n  if(is.null(extent)){\n    extent <- groundtruth\n  }\n  \n  samples <- st_make_grid(extent,cellsize,what = \"centers\")\n  my_formula <- formula(paste(column,\"~1\"))\n  idw_sf <- gstat::idw(formula = my_formula,groundtruth, newdata = samples, nmin = 1, nmax = nmax, maxdist = maxdist, idp = idp)\n  \n  idw_matrix <- cbind(as.data.frame(st_coordinates(idw_sf)),pred = st_drop_geometry(idw_sf)[,1])\n  idw_matrix\n}\n\n\n\nNun könnt Ihr mit my_idw() den Datensatz luftqualitaet folgendermassen interpolieren.\n\n\nmy_idw(groundtruth = luftqualitaet,column = \"value\",cellsize = 10000, extent = schweiz)\n\n\n\nFolgende Parameter stehen Euch zur Verfügung:\nNotwendige Parameter:\ngroundtruth: Punktdatensatz mit den Messwerten (sf-Objekt)\ncolumn: Name der Spalte mit den Messwerten (in Anführungs- und Schlusszeichen)\ncellsize: Zellgrösse des output Rasters\n\nOptionale Parameter\nnmax: Maximale Anzahl Punkte, die für die Interpolation berücksichtigt werden sollen. Default: Inf (alle Werte im gegebenen Suchradius)\nmaxdist: Suchradius, welcher für die Interpolation verwendet werden soll. Default Inf (alle Werte bis nmax)\nidp: Inverse Distance Power: die Potenz, mit der der Nenner gesteigert werden soll. Default: 2. Werte werden im Kehrwert des Quadrates gewichtet: \\(\\frac{1}{dist^{idp}}\\).\nextent: Gebiet, für welches die Interpolation durchgeführt werden soll. Wenn nichts angegeben wird (Default NULL), wird die Ausdehnung von groundtruth verwendet.\n\nOuput\nder Output der Funktion ist eine data.frame mit 3 Spalten:\nX, Y Koordinaten der interpolierten Werte\npred: der Interpolierte Wert\n\n\nBeim Output handelt sich hier um einen Raster-ähnlichen Datentyp (siehe Vorlesung Spatial DataScience 1). Diesen können wir mit geom_raster mit ggplot visualisieren. Dafür müsst ihr in aes die X und Y Koordinaten angeben, und der interpolierte Wert mit fill einfärben.\nAufgabe 1: Raeumliche Interpolation mit IDW\nRechnet so den IDW für die Luftqualitätsmessungen mit verschiedenen Parametern und visualisiert jeweils die Resultate. Experimentiert mit nmax sowie maxdist. Was stellt ihr fest?\nTips:\nWas für Distanzen bei maxdist Sinn machen, könnt ihr dem Output aus der G-Funktion (vorherige Übung) entnehmen\nWählt am Anfang eine etwas Konvervative (grosse) cellsize und verringert diesen nur wenn euer Rechner damit gut klar kommt\nDa der Output aus der Interpolation im gleichen Koordinatenbezugssystem sind wie schweiz.gpkg kann man diese beiden Datensätze im gleichen ggplot darstellen. Dafür müsst ihr die aesthetics (aes()) für jeden Layer einzeln setzen, und nicht auf der Ebene von ggplot().\n\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n[inverse distance weighted interpolation]\n\n\nFigure 1: Stickstoffdioxid (NO2) in μg/m3, Interpoliert über die ganze Schweiz mit der Inverse Distance Weighted Methode. Die verschiedenen Plots zeigen die Veränderung der Interpolation bei steigendem IDP-Wert\n\n\n\nAufgabe 2: Interpolation mit Nearest Neighbour\nEine weitere einfache Möglichkeit zur Interpolation bietet die Erstellung eines Voronoi-Diagrammes, auch als Thiessen-Polygone oder Dirichlet-Zerlegung bekannt. sf liefert dazu die Funktion st_voronoi(), die einen Punktdatensatz annimmt und eben um die Punkte die Thiessenpolygone konstruiert. Dazu braucht es lediglich einen kleinen Vorverarbeitungsschritt: sf möchte für jedes Feature, also für jede Zeile in unserem Datensatz, ein Voronoidiagramm. Das macht bei uns wenig Sinn, weil jede Zeile nur aus einem Punkt besteht. Deshalb müssen wir vorher luftqualitaet mit st_union() von einem POINT in ein MULTIPOINT Objekt konvertieren, in welchem alle Punkte in einer Zeile zusammengefasst sind.\n\n\nluftqualitaet_union <- st_union(luftqualitaet)\n\nthiessenpolygone <- st_voronoi(luftqualitaet_union)\n\n\n\n\n\n\nst_voronoi hat die Thiessenpolygone etwas weiter gezogen als wir sie wollen. Dies ist allerdings eine schöne Illustration der Randeffekte von Thiessenpolygonen, die zum Rand hin (wo es immer weniger Punkte hat) sehr gross werden können. Wir können die Polygone auf die Ausdehnung der Schweiz mit st_intersection() clippen. Auch hier braucht es zwei kleine Vorverarbeitungsschritte:\nwie vorher müssen wir die einzelnen Kantons-Polygone miteinander verschmelzen. Dies erreichen wir mit st_union(). Wir speichern den Output als schweiz, was als Resultat ein einzelnes Polygon der Schweizergrenze retourniert.\nfür die Thiessen-Polygone machen wir genau das Umgekehrte: st_voronoi() liefert ein einzelnes Feature mit allen Polygonen, welches sich nicht gerne clippen lässt. Mit st_cast() wird die GEOMETRYCOLLECTION in Einzelpolygone aufgeteilt.\n\n\nthiessenpolygone <- st_cast(thiessenpolygone)\n\nthiessenpolygone_clip <- st_intersection(thiessenpolygone,schweiz)\n\n\n\n\n\n\nJetzt müssen wir nur noch den jeweiligen Wert für jedes Polygon ermitteln. Dies erreichen wir wieder durch st_join. Auch hier ist noch ein kleiner Vorverarbeitungsschritt nötig: Wir konvertieren das sfc Objekt (nur Geometrien) in ein sf Objekt (Geometrien mit Attributtabelle).\n\n\nthiessenpolygone_clip <- st_as_sf(thiessenpolygone_clip)\nthiessenpolygone_clip <- st_join(thiessenpolygone_clip,luftqualitaet)\n\n\n\n\n\nggplot() + \n  geom_sf(data = schweiz) +\n  geom_sf(data = thiessenpolygone_clip, aes(fill = value)) +\n  geom_sf(data = luftqualitaet) +\n  scale_fill_gradientn(colours = rev(RColorBrewer::brewer.pal(11,\"RdYlBu\"))) +\n  theme_void() +\n  theme(legend.position = \"bottom\", legend.title = element_blank(),\n      legend.key.width = unit(0.10, 'npc'),\n      legend.key.height = unit(0.02, 'npc'))\n\n\n\n\nFigure 2: Stickstoffdioxid (NO2) in μg/m3, Interpoliert über die ganze Schweiz nach der Nearest Neighbour Methode.\n\n\n\n\n\n\n",
    "preview": "rauman/RaumAn2_Uebung_B/distill-preview.png",
    "last_modified": "2021-12-02T08:40:09+00:00",
    "input_file": {},
    "preview_width": 2362,
    "preview_height": 2125
  },
  {
    "path": "rauman/RaumAn2_Uebung_C/",
    "title": "Übung C: Dichteschätzung",
    "description": {},
    "author": [
      {
        "name": "Patrick Laube",
        "url": {}
      },
      {
        "name": "Nils Ratnaweera",
        "url": {}
      },
      {
        "name": "Nikolaos Bakogiannis",
        "url": {}
      }
    ],
    "date": "2021-11-30",
    "categories": [
      "RaumAn2"
    ],
    "contents": "\nNun wollen wir für die bereits verwendeten Datensätze luftqualitaet.gpkg und rotmilan.gpkg Dichteschätzungen durchführen. Ladet dafür die notwendigen Package und ladet bei Bedarf die Datensätze herunter.\n\n\nlibrary(sf)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n\nlibrary(MASS) # <- ggf. installieren!\n\n\n\n\nschweiz.gpkg\nluftqualitaet.gpkg\nrotmilan.gpkg\n\nAufgabe 1: Rotmilan Bewegungsdaten visualisieren\nDie erste Frage, die bei solchen Bewegungsstudien typischerweise gestellt wird, lautet: Wo hält sich das Tier hauptsächlich auf? Um diese Frage zu beantworten, kann man als erstes einfach die Datenpunkte in einer einfachen Karte visualisieren. Erstellt zur Beantwortung dieser Frage nachstehende Karte.\n\n\n\nAufgabe 2: Kernel Density Estimation berechnen\nIn einer ersten Annäherung funktioniert dies, doch wir sehen hier ein klassisches Problem des “Overplotting”. Das heisst, dass wir durch die Überlagerung vieler Punkte in den dichten Regionen nicht abschätzen können, wie viele Punkte dort effektiv liegen und ggf. übereinander liegen. Es gibt hier verschiedene Möglichkeiten, die Punktdichte klarer zu visualisieren. Eine unter Biologen sehr beliebte Methode ist die Dichteverteilung mit einer Kernel Density Estimation (KDE). Dies v.a. darum, weil mit KDE das Habitat (Streifgebiet) eines Tieres abgeschätzt werden kann. Homeranges werden oft mit KDE95 und Core Areas mit KDE50 definiert (Fleming C., Calabrese J., 2016).\nÄhnlich wie beim IDW sind auch die verfügbaren KDE-Funktionen in R etwas kompliziert in der Handhabung. Damit wir dieses Verfahren aber dennoch auf unsere Rotmilan-Daten anwenden können, haben wir eine eigene KDE-Funktion erstellt, die wir Euch zur Verfügung stellen.\nHier gilt das gleiche wie schon bei der Funktion my_idw(): Wir ermutigen alle, die dafür Kapazität haben, unsere Function eingehend zu studieren und allenfalls ganz auf die Funktion zu verzichten und stattdessen direkt MASS zu verwenden. Wenn ihr mit unserer Funktion arbeiten möchtet, müsst ihr den unten stehenden Code in euer Skript kopieren und ausführen.\n\n\nmy_kde <- function(points,cellsize, bandwith, extent = NULL){\n  library(MASS)\n  library(sf)\n  library(tidyr)\n  if(is.null(extent)){\n    extent_vec <- st_bbox(points)[c(1,3,2,4)]\n  } else{\n    extent_vec <- st_bbox(extent)[c(1,3,2,4)]\n  }\n  \n  n_y <- ceiling((extent_vec[4]-extent_vec[3])/cellsize)\n  n_x <- ceiling((extent_vec[2]-extent_vec[1])/cellsize)\n  \n  extent_vec[2] <- extent_vec[1]+(n_x*cellsize)-cellsize\n  extent_vec[4] <- extent_vec[3]+(n_y*cellsize)-cellsize\n\n  coords <- st_coordinates(points)\n  mat <- kde2d(coords[,1],coords[,2],h = bandwith,n = c(n_x,n_y),lims = extent_vec)\n\n  mydf <- as.data.frame(mat[[3]])\n  \n  colnames(mydf) <- mat[[2]]\n  mydf$X <- mat[[1]]\n  \n  pivot_longer(mydf, -X,names_to = \"Y\",names_transform = list(Y = as.numeric))\n\n}\n\n\n\nDie Parameter der Funktion sollten relativ klar sein:\npoints: Ein Punktdatensatz aus der Class sf\ncellsize: Die Zellgrösse des output-Rasters\nbandwith: Der Suchradius für die Dichteberechnung\nextent (optional): Der Perimeter, in dem die Dichteverteilung berechnet werden soll. Wenn kein Perimeter angegeben wird, wird die “bounding box” von points genutzt.\nWenn wir nun mit my_kde() die Dichteverteilung berechnen, erhalten wir ein data.frame mit X und Y Koordinaten sowie eine Spalte value zurück. Nutzt diese drei Spalten mit geom_raster() um eure Daten mit ggplot zu visualisieren (aes(x = X, y = Y, fill = value).\n\n\nrotmilan_kde <- my_kde(points = rotmilan,cellsize = 1000, bandwith = 10000, extent = schweiz)\n\nrotmilan_kde\n\n\n# A tibble: 77,129 × 3\n          X        Y value\n      <dbl>    <dbl> <dbl>\n 1 2485410. 1075268.     0\n 2 2485410. 1076268.     0\n 3 2485410. 1077268.     0\n 4 2485410. 1078268.     0\n 5 2485410. 1079268.     0\n 6 2485410. 1080268.     0\n 7 2485410. 1081268.     0\n 8 2485410. 1082268.     0\n 9 2485410. 1083268.     0\n10 2485410. 1084268.     0\n# … with 77,119 more rows\n\n\n\n\nDie Kernel Density Estimation ist nun sehr stark von den tiefen Werten dominiert, da die Dichte in den meisten Zellen unseres Untersuchungsgebiets nahe bei Null liegt. Wie erwähnt sind Wissenschaftler häufig nur an den höchsten 95% der Werte interessiert. Folge folgende Schritte um das Resultat etwas besser zu verantschaulichen:\nBerechne die 95. Perzentile aller Werte mit der Funktion quantile und benne diesen q25\nErstelle eine neue Spalte in rotmilan_kde, wo alle Werte tiefer als q25 NA entsprechen\n(Optional): Transformiere die Werte mit log10, um einen differenzierteren Farbverlauf zu erhalten\nWir können die tiefen Werte ausblenden, indem wir nur die höchsten 5% der Werte darstellen. Dafür berechnen wir mit raster::quantile die 95. Perzentile aller Werte und nutzen diesen Wert als “Grenzwert” für die Darstellung.\nZusätzlich hilft eine logarithmische Transformation der Werte, die Farbskala etwas sichtbarer zu machen.\n\n\n\nAufgabe 3: Dichteverteilung mit Thiessen Polygonen\nThiessen Polygone bieten eine spannende Alternative um Unterschiede in der Dichteverteilung von Punktdatensätzen zu visualisieren. Wir wollen dies nun ausprobieren und konstruieren zum Schluss die Thiessenpolygone für die Rotmilan-Daten für das Untersuchungsgebiet Schweiz. Nutze die Anleitung für das Erstellen von Thiessenpolygonen aus der Übung B um Thiessenpolygone für die Rotmilanpositionen zu erstellen.\n\n\n\n\n\n\nFigure 1: Wenn wir jetzt die Thiessenpolygone (ohne Punkte) darstellen, wird deutlicher, wie die Dichteverteilung im Innern des Clusters aussieht.\n\n\n\n\n\n\n",
    "preview": "rauman/RaumAn2_Uebung_C/distill-preview.png",
    "last_modified": "2021-12-02T08:40:09+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  }
]
